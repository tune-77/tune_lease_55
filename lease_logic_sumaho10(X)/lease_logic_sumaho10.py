"""
æ¸©æ°´å¼ãƒªãƒ¼ã‚¹å¯©æŸ»AI - lease_logic_sumaho10
sumaho9 ã«å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ï¼ˆæ¥­ç¨®åˆ¥ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ï¼‰ã‚’èåˆã€‚ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã¯ãƒªãƒã‚¸ãƒˆãƒªãƒ«ãƒ¼ãƒˆã§ sumaho8/9 ã¨å…±é€šã€‚
èµ·å‹•: streamlit run lease_logic_sumaho10/lease_logic_sumaho10.py ï¼ˆãƒªãƒã‚¸ãƒˆãƒªãƒ«ãƒ¼ãƒˆã§å®Ÿè¡Œï¼‰
"""
import sys
import os
_SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
_REPO_ROOT = os.path.dirname(_SCRIPT_DIR)
if _REPO_ROOT not in sys.path:
    sys.path.insert(0, _REPO_ROOT)
if _SCRIPT_DIR not in sys.path:
    sys.path.insert(0, _SCRIPT_DIR)

import streamlit as st
try:
    from streamlit_extras.metric_cards import style_metric_cards
except ImportError:
    style_metric_cards = None  # pip install streamlit-extras ã§ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’ã‚«ãƒ¼ãƒ‰é¢¨ã«
import math
import json
import random
import re
import ollama
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import time
import concurrent.futures
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import numpy as np
import seaborn as sns
import datetime
from coeff_definitions import (
    COEFFS,
    BAYESIAN_PRIOR_EXTRA,
    STRENGTH_TAG_WEIGHTS,
    DEFAULT_STRENGTH_WEIGHT,
)
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler

from charts import (
    CHART_STYLE,
    LOWER_IS_BETTER_NAMES,
    _equity_ratio_display,
    plot_balance_sheet_plotly,
    plot_benchmark_comparison,
    plot_break_even_point,
    plot_break_even_point_plotly,
    plot_contract_prob_factors_plotly,
    plot_gauge,
    plot_gauge_plotly,
    plot_indicators_bar,
    plot_indicators_gap_analysis,
    plot_indicators_gap_analysis_plotly,
    plot_past_scores_histogram_plotly,
    plot_positioning_scatter,
    plot_radar_chart,
    plot_radar_chart_plotly,
    plot_scoring_top5_factors_plotly,
    plot_score_models_comparison_plotly,
    plot_3d_analysis,
    plot_waterfall,
    plot_waterfall_plotly,
)
from data_cases import (
    CASES_FILE,
    CASE_NEWS_FILE,
    CONSULTATION_MEMORY_FILE,
    COEFF_OVERRIDES_FILE,
    DEFAULT_WEIGHT_QUAL,
    DEFAULT_WEIGHT_QUANT,
    append_case_news,
    append_consultation_memory,
    find_similar_past_cases,
    get_effective_coeffs,
    get_score_weights,
    load_all_cases,
    load_case_news,
    load_consultation_memory,
    load_coeff_overrides,
    load_past_cases,
    save_all_cases,
    save_case_log,
    save_coeff_overrides,
)
from analysis_regression import (
    BENCH_BASES,
    COEFF_EXTRA_KEYS,
    COEFF_LABELS,
    COEFF_MAIN_KEYS,
    INDUSTRY_BASES,
    INDUSTRY_MODEL_KEYS,
    INDICATOR_MAIN_KEYS,
    INDICATOR_MODEL_KEYS,
    PRIOR_COEFF_MODEL_KEYS,
    QUALITATIVE_ANALYSIS_MIN_CASES,
    build_design_matrix_from_logs,
    optimize_score_weights_from_regression,
    run_contract_driver_analysis,
    run_qualitative_contract_analysis,
    run_quantitative_by_indicator,
    run_quantitative_by_industry,
    run_quantitative_contract_analysis,
    run_regression_and_get_coeffs,
    run_regression_indicator_and_get_coeffs,
)

# ============================================
# AI ã‚¨ãƒ³ã‚¸ãƒ³è¨­å®šï¼ˆOllama / Gemini APIï¼‰
# ãƒ»Ollama: ç’°å¢ƒå¤‰æ•° OLLAMA_MODELã€ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒ¢ãƒ‡ãƒ«é¸æŠ
# ãƒ»Gemini: ç’°å¢ƒå¤‰æ•° GEMINI_API_KEY ã¾ãŸã¯ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§APIã‚­ãƒ¼å…¥åŠ›ã€ãƒ¢ãƒ‡ãƒ«ã¯ gemini-2.0-flash ç­‰
# ============================================
OLLAMA_MODEL = os.environ.get("OLLAMA_MODEL", "lease-anna")
GEMINI_API_KEY_ENV = os.environ.get("GEMINI_API_KEY", "")
GEMINI_MODEL_DEFAULT = "gemini-2.0-flash"  # ã¾ãŸã¯ gemini-1.5-pro, gemini-1.5-flash

def _get_gemini_key_from_secrets() -> str:
    """secrets.toml ãŒç„¡ãã¦ã‚‚ä¾‹å¤–ã«ã—ãªã„ã€‚ã‚­ãƒ¼ãŒã‚ã‚Œã°è¿”ã™ã€‚"""
    try:
        if hasattr(st, "secrets") and st.secrets.get("GEMINI_API_KEY"):
            return st.secrets.get("GEMINI_API_KEY", "") or ""
    except Exception:
        pass
    return ""

# ç›¸è«‡ãƒ¢ãƒ¼ãƒ‰: ã‚¹ãƒ¬ãƒƒãƒ‰â†’ãƒ¡ã‚¤ãƒ³ã§çµæœã‚’æ¸¡ã™ç”¨ï¼ˆsession_state ã¯ã‚¹ãƒ¬ãƒƒãƒ‰ã‹ã‚‰æ›´æ–°ã•ã‚Œãªã„ãŸã‚ï¼‰
_chat_result_holder = {"result": None, "done": False}

def get_ollama_model() -> str:
    """
    å®Ÿéš›ã«ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«åã‚’å–å¾—ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼ã€‚
    - st.session_state['ollama_model'] ãŒã‚ã‚Œã°ãã‚Œã‚’å„ªå…ˆ
    - ãªã‘ã‚Œã°ç’°å¢ƒå¤‰æ•°ãƒ™ãƒ¼ã‚¹ã® OLLAMA_MODEL ã‚’è¿”ã™
    """
    model = st.session_state.get("ollama_model", "").strip() if "ollama_model" in st.session_state else ""
    return model or OLLAMA_MODEL
def red_label(placeholder, text):
    # display: block ã«ã—ã¦ã€ä¸€ã¤ä¸€ã¤ã®ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã‚»ãƒƒãƒˆã®ç¯„å›²ã‚’æ˜ç¢ºã«ã—ã¾ã™
    placeholder.markdown(f'''
        <div style="
            text-align: right; 
            color: #FF0000; 
            font-size: 20px; 
            font-weight: bold;
            margin-bottom: -40px;
            padding-right: 5px;
            line-height: 1;
        ">
            {text}
        </div>
    ''', unsafe_allow_html=True)


def _slider_and_number(field_name, key_prefix, default, min_val, max_val, step_slider, step_num=None, fmt="{:,}", unit="åƒå††", label_slider="å£²ä¸Šé«˜èª¿æ•´", max_val_number=None):
    """ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã¨æ•°å€¤å…¥åŠ›ã®ä¸¡æ–¹ã«å¯¾å¿œã€‚å¾Œã‹ã‚‰å‹•ã‹ã—ãŸæ–¹ã‚’æ¡ç”¨å€¤ã¨ã™ã‚‹ï¼ˆon_change ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯æ–¹å¼ï¼‰ã€‚"""
    if step_num is None:
        step_num = step_slider
    num_max = max_val_number if max_val_number is not None else max_val

    if field_name not in st.session_state:
        st.session_state[field_name] = default
    cur = st.session_state[field_name]

    # å¤–éƒ¨ï¼ˆã‚±ãƒ¼ã‚¹èª­ã¿è¾¼ã¿ç­‰ï¼‰ã‹ã‚‰ã®å¤‰æ›´ã‚’æ¤œçŸ¥ã—ã¦ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã‚­ãƒ¼ã‚’å†åŒæœŸã™ã‚‹ãŸã‚ã®ãƒãƒ¼ã‚«ãƒ¼
    prev_key = f"_san_prev_{key_prefix}"
    num_key = f"num_{key_prefix}"
    slide_key = f"slide_{key_prefix}"
    externally_changed = st.session_state.get(prev_key) != cur

    if num_key not in st.session_state or externally_changed:
        st.session_state[num_key] = max(min_val, min(cur, num_max))
    if slide_key not in st.session_state or externally_changed:
        st.session_state[slide_key] = max(min_val, min(cur, max_val))

    def _on_num_change():
        val = st.session_state[num_key]
        st.session_state[field_name] = val
        st.session_state[slide_key] = max(min_val, min(val, max_val))
        st.session_state[prev_key] = val

    def _on_slide_change():
        val = st.session_state[slide_key]
        st.session_state[field_name] = val
        st.session_state[num_key] = val
        st.session_state[prev_key] = val

    c_l, c_r = st.columns([0.7, 0.3])
    with c_r:
        st.number_input("ç›´æ¥å…¥åŠ›", min_value=min_val, max_value=num_max,
                        step=step_num, key=num_key,
                        label_visibility="collapsed",
                        on_change=_on_num_change)
    with c_l:
        st.slider(label_slider, min_value=min_val, max_value=max_val,
                  step=step_slider, key=slide_key,
                  label_visibility="collapsed",
                  on_change=_on_slide_change)

    adopted = st.session_state[field_name]
    st.session_state[prev_key] = adopted
    st.caption(f"**æ¡ç”¨å€¤: {fmt.format(adopted)} {unit}**")
    return adopted


def _reset_shinsa_inputs():
    """å…¨å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã«ãƒªã‚»ãƒƒãƒˆã™ã‚‹ã€‚ã€Œæ–°ã—ãå…¥åŠ›ã™ã‚‹ã€ãƒœã‚¿ãƒ³ç”¨ã€‚"""
    field_defaults = {
        "nenshu": 10000,
        "item9_gross": 10000,
        "rieki": 10000,
        "item4_ord_profit": 10000,
        "item5_net_income": 10000,
        "item10_dep": 10000,
        "item11_dep_exp": 10000,
        "item8_rent": 10000,
        "item12_rent_exp": 10000,
        "item6_machine": 10000,
        "item7_other": 10000,
        "net_assets": 10000,
        "total_assets": 10000,
        "bank_credit": 10000,
        "lease_credit": 10000,
        "contracts": 1,
        "acquisition_cost": 1000,
        "lease_term": 60,
        "acceptance_year": 2026,
    }
    # field_name â† ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã«ãƒªã‚»ãƒƒãƒˆ
    for k, v in field_defaults.items():
        st.session_state[k] = v
    # ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã‚­ãƒ¼ï¼ˆnum_* / slide_* / _san_prev_*ï¼‰ã‚’å‰Šé™¤ã—ã¦å†åˆæœŸåŒ–ã•ã›ã‚‹
    widget_prefixes = [
        "nenshuu", "sourieki", "rieki", "item4_ord_profit", "item5_net_income",
        "item10_dep", "item11_dep_exp", "item8_rent", "item12_rent_exp",
        "item6_machine", "item7_other", "net_assets", "total_assets",
        "bank_credit", "lease_credit", "contracts", "acquisition_cost",
    ]
    for pfx in widget_prefixes:
        for pre in ("num_", "slide_", "_san_prev_"):
            st.session_state.pop(f"{pre}{pfx}", None)
    # å®šæ€§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ
    for k in list(st.session_state.keys()):
        if k.startswith("qual_corr_"):
            st.session_state[k] = 0
    # æœ€å¾Œã®åˆ¤å®šçµæœãƒ»é€ä¿¡å…¥åŠ›ã‚’ã‚¯ãƒªã‚¢
    for k in ("last_submitted_inputs", "last_result", "current_case_id",
               "selected_asset_index", "news_results", "selected_news_content"):
        st.session_state.pop(k, None)


# ä»¥ä¸‹ã¯ãƒšãƒ¼ã‚¸å…±é€šCSSï¼ˆã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ãƒ»ã‚°ãƒ©ãƒ•ãƒ»ã‚¿ãƒ–ãƒ»ã‚¹ãƒãƒ›å‘ã‘ãªã©ï¼‰
st.markdown("""
    <style>
    /* ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼å…¨ä½“ã®å¹…ã‚’ã‚¹ãƒãƒ›ã§ç¢ºä¿ï¼ˆæœ€å°å¹…ãƒ»ã‚¿ãƒƒãƒ—ã—ã‚„ã™ãï¼‰ */
    div[data-baseweb="slider"] {
        min-width: min(100%, 320px) !important;
        width: 100% !important;
    }
    @media (max-width: 640px) {
        div[data-baseweb="slider"] { min-width: 100% !important; }
        .stSlider > div { width: 100% !important; }
    }
    /* ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã®ã¤ã¾ã¿ï¼ˆä¸¸ã„éƒ¨åˆ†ï¼‰ã‚’å¤§ããã™ã‚‹ */
    div[data-baseweb="slider"] div[role="slider"] {
        width: 30px !important;
        height: 30px !important;
        background-color: #FF0000 !important;
        border: 2px solid white !important;
    }
    /* ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã®æ£’ï¼ˆãƒ¬ãƒ¼ãƒ«ï¼‰ã‚’å¤ªãã™ã‚‹ */
    div[data-baseweb="slider"] > div {
        height: 15px !important;
    }
    /* ãƒ©ãƒ™ãƒ«ï¼ˆå£²ä¸Šé«˜ï¼‰ã®æ–‡å­—ã‚’å¤§ããã™ã‚‹ */
    .stSlider label p {
        font-size: 24px !important;
        font-weight: bold !important;
    }
    /* ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã®ä¸Šãƒ»æ¨ªã«è¡¨ç¤ºã•ã‚Œã‚‹æ•°å€¤ï¼ˆç¾åœ¨å€¤ï¼‰ã‚’å¤§ããè¦‹ã‚„ã™ã */
    .stSlider {
        font-size: 1.5rem !important;
    }
    .stSlider [data-baseweb="slider"] {
        font-size: 1.5rem !important;
    }
    /* ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼å€¤è¡¨ç¤ºã‚¨ãƒªã‚¢ï¼ˆBase Web ã®å‡ºåŠ›éƒ¨åˆ†ï¼‰ */
    .stSlider > div > div:last-child,
    div[data-baseweb="slider"] ~ div {
        font-size: 1.8rem !important;
        font-weight: 600 !important;
    }
    /* ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã‚’å‹•ã‹ã—ã¦ã„ã‚‹æ™‚ã«å‡ºã‚‹æ•°å€¤ï¼ˆãƒ„ãƒ¼ãƒ«ãƒãƒƒãƒ—ãƒ»ã¤ã¾ã¿ä¸Šã®è¡¨ç¤ºï¼‰ã‚‚å¤§ãã */
    [data-baseweb="tooltip"],
    .stSlider [data-baseweb="tooltip"],
    div[data-baseweb="slider"] [role="slider"] + div,
    div[data-baseweb="slider"] div[style*="position"] {
        font-size: 2rem !important;
        font-weight: 700 !important;
    }
    /* ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ãƒœã‚¿ãƒ³ï¼ˆã¤ã¾ã¿ï¼‰ã®ä¸Šã«è¡¨ç¤ºã•ã‚Œã‚‹æ•°å­—ã‚’ç‰¹ã«å¤§ãã */
    [data-baseweb="tooltip"] span,
    [data-baseweb="tooltip"] div,
    .stSlider [data-baseweb="tooltip"] span,
    .stSlider [data-baseweb="tooltip"] div,
    div[data-baseweb="slider"] ~ [data-baseweb="tooltip"],
    [data-baseweb="popover"] span,
    [data-baseweb="popover"] div {
        font-size: 2.4rem !important;
        font-weight: 700 !important;
    }
    .stSlider span,
    .stSlider div[data-baseweb="slider"] span {
        font-size: 1.8rem !important;
        font-weight: 600 !important;
    }

    /* ã‚°ãƒ©ãƒ•ãƒ»å›³ã‚’ã‚«ãƒ¼ãƒ‰é¢¨ã«ï¼ˆè§’ä¸¸ãƒ»è»½ã„ã‚·ãƒ£ãƒ‰ã‚¦ï¼‰ */
    .stImage img, [data-testid="stImage"] img {
        border-radius: 10px !important;
        box-shadow: 0 2px 12px rgba(15,23,42,0.08) !important;
    }
    /* Plotly ãƒãƒ£ãƒ¼ãƒˆã‚‚è§’ä¸¸ */
    .js-plotly-plot .plotly, [data-testid="stPlotlyChart"] div {
        border-radius: 10px !important;
    }
    /* PC: ã‚°ãƒ©ãƒ•ã¯ã‚³ãƒ³ãƒ†ãƒŠå¹…ã„ã£ã±ã„ã«è¡¨ç¤ºï¼ˆå…¨éƒ¨è¦‹ãˆã‚‹ã‚ˆã†ã«ï¼‰ */
    @media (min-width: 769px) {
        [data-testid="stPlotlyChart"] { max-width: 100% !important; width: 100% !important; margin-left: 0 !important; }
    }
    /* å³ç«¯ãŒåˆ‡ã‚Œãªã„ã‚ˆã†ã«: ãƒ¡ã‚¤ãƒ³é ˜åŸŸã‚’ãƒ•ãƒ«å¹…ãƒ»ã¯ã¿å‡ºã—è¡¨ç¤ºè¨±å¯ */
    section[data-testid="stSidebar"] + div,
    section.main,
    [data-testid="stAppViewContainer"],
    [data-testid="stAppViewContainer"] > div:first-child,
    .block-container {
        max-width: 100% !important;
        width: 100% !important;
        overflow-x: visible !important;
        box-sizing: border-box !important;
    }
    .block-container {
        padding-right: 1.5rem !important;
    }
    /* ã‚¹ãƒãƒ›ãƒ»ã‚¿ãƒ–ãƒ¬ãƒƒãƒˆ: ä½™ç™½ç¸®å°ã§ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å‰Šæ¸›ãƒ»ãƒ¢ãƒ€ãƒ³UI */
    .block-container {
        padding-top: 1rem !important;
        padding-bottom: 1rem !important;
        padding-left: 1rem !important;
        padding-right: 1.5rem !important;
    }
    @media (max-width: 768px) {
        .block-container { padding-top: 0.6rem !important; padding-bottom: 0.6rem !important; padding-left: 0.6rem !important; padding-right: 0.6rem !important; }
        [data-testid="stVerticalBlock"] > div { gap: 0.5rem !important; }
        .stExpander { margin-bottom: 0.25rem !important; }
    }
    /* å·¦ãƒ»å³ã‚«ãƒ©ãƒ ï¼ˆå¯©æŸ»å…¥åŠ›ï½œAIç›¸è«‡ï¼‰: å³ã®AIã‚ªãƒ•ã‚£ã‚µãƒ¼ç›¸è«‡ãŒåˆ‡ã‚Œãªã„ã‚ˆã†ã« */
    [data-testid="stHorizontalBlock"] {
        overflow-x: visible !important;
        max-width: 100% !important;
    }
    [data-testid="stHorizontalBlock"] > div:first-child {
        min-width: 0 !important;
    }
    [data-testid="stHorizontalBlock"] > div {
        overflow-x: visible !important;
        overflow-y: visible !important;
    }
    /* å³ã‚«ãƒ©ãƒ ï¼ˆAIç›¸è«‡ï¼‰ã¯æœ€ä½å¹…ã‚’ç¢ºä¿ã—ã€åˆ‡ã‚Œãªã„ã‚ˆã†ã« */
    [data-testid="stHorizontalBlock"] > div:last-child {
        min-width: 320px !important;
        flex: 1 1 auto !important;
    }
    [data-testid="stHorizontalBlock"] > div:last-child [data-testid="stVerticalBlock"],
    [data-testid="stHorizontalBlock"] > div:last-child .stChatMessage,
    [data-testid="stHorizontalBlock"] > div:last-child .stMarkdown {
        max-width: 100% !important;
        overflow-wrap: break-word !important;
        word-break: break-word !important;
    }
    /* å³ã‚«ãƒ©ãƒ å†…ã®ã‚³ãƒ¡ãƒ³ãƒˆæ¬„ï¼ˆç›¸è«‡å†…å®¹ text_areaï¼‰ãŒå³ã§åˆ‡ã‚Œãªã„ã‚ˆã†ã« */
    [data-testid="stHorizontalBlock"] > div:last-child [data-testid="stTextArea"],
    [data-testid="stHorizontalBlock"] > div:last-child [data-testid="stTextArea"] textarea,
    [data-testid="stHorizontalBlock"] > div:last-child [data-testid="stTextArea"] > div {
        max-width: 100% !important;
        width: 100% !important;
        min-width: 0 !important;
        box-sizing: border-box !important;
    }
    [data-testid="stHorizontalBlock"] > div:last-child [data-testid="stHorizontalBlock"] {
        max-width: 100% !important;
    }
    [data-testid="stHorizontalBlock"] > div:last-child iframe {
        max-width: 100% !important;
    }
    /* ç›¸è«‡ã‚¿ãƒ–å†…ã®ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢å…¨èˆ¬ï¼ˆã‚­ãƒ¼æŒ‡å®šã§ããªã„ãŸã‚ãƒ©ãƒƒãƒ‘ãƒ¼ã§åˆ¶ç´„ï¼‰ */
    [data-testid="stTextArea"] {
        max-width: 100% !important;
    }
    [data-testid="stTextArea"] > div,
    [data-testid="stTextArea"] textarea {
        max-width: 100% !important;
        box-sizing: border-box !important;
    }
    /* å³ã‚«ãƒ©ãƒ ãƒ»ç›¸è«‡å†…å®¹ã®æ¬„ã«è‰²ã‚’ã¤ã‘ã‚‹ï¼ˆãƒ€ãƒƒã‚·ãƒ¥ã‚³ãƒ¼ãƒ‰é¢¨ï¼‰ */
    [data-testid="stHorizontalBlock"] > div:last-child [data-testid="stTextArea"] {
        background: linear-gradient(135deg, #f0f9ff 0%, #e0f2fe 100%) !important;
        padding: 0.75rem !important;
        border-radius: 10px !important;
        border-left: 4px solid #1e3a5f !important;
        box-shadow: 0 1px 3px rgba(30, 58, 95, 0.08) !important;
    }
    [data-testid="stHorizontalBlock"] > div:last-child [data-testid="stTextArea"] textarea {
        background: #ffffff !important;
        border: 1px solid #bae6fd !important;
        border-radius: 8px !important;
    }
    /* ãƒˆãƒƒãƒ—ãƒ¡ãƒ‹ãƒ¥ãƒ¼ç”¨: ã‚¿ãƒ–é¢¨ã‚¹ãƒƒã‚­ãƒª */
    [data-testid="stTabs"] > div > div { gap: 0 !important; }
    [data-testid="stTabs"] [role="tablist"] { margin-bottom: 0.5rem !important; }
    /* é›»å…‰æ²ç¤ºæ¿ï¼ˆå®šä¾‹ã®æ„šç—´ï¼‰ */
    .byoki-ticker-wrap { overflow: hidden; background: linear-gradient(90deg, #1e293b 0%, #334155 100%); color: #f8fafc; padding: 8px 0; margin: 0 0 0.5rem 0; border-radius: 6px; font-size: 0.9rem; }
    .byoki-ticker-inner { display: inline-block; white-space: nowrap; animation: byoki-scroll 120s linear infinite; }
    .byoki-ticker-inner span { padding-right: 2em; }
    @keyframes byoki-scroll { 0% { transform: translateX(0); } 100% { transform: translateX(-50%); } }
    /* ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ»ã‚«ãƒ¼ãƒ‰é¢¨ã‚³ãƒ³ãƒ†ãƒŠ */
    .dashboard-card {
        background: #fff;
        border: 1px solid #e2e8f0;
        border-radius: 8px;
        padding: 1rem 1.25rem;
        margin-bottom: 1rem;
        box-shadow: 0 1px 3px rgba(30,58,95,0.06);
    }
    .dashboard-kpi-row { margin-bottom: 1.25rem; }
    .dashboard-section-title { color: #1e3a5f; font-size: 0.95rem; font-weight: 600; margin-bottom: 0.5rem; }
    /* KPIãƒ¡ãƒˆãƒªã‚¯ã‚¹: ã‚«ãƒ¼ãƒ‰å†…ã«è‰²ã‚’ã¤ã‘ã‚‹ + ä½™ç™½ */
    [data-testid="stMetric"],
    [data-testid="metric-container"] {
        margin-right: 0.6rem !important;
        margin-bottom: 0.6rem !important;
        padding: 0.6rem 0.5rem !important;
        min-width: 0 !important;
        background: linear-gradient(145deg, #f0f4f8 0%, #e2e8f0 100%) !important;
        border-radius: 10px !important;
        border-left: 4px solid #1e3a5f !important;
        box-shadow: 0 2px 8px rgba(30, 58, 95, 0.1) !important;
    }
    [data-testid="stMetric"] > div,
    [data-testid="metric-container"] > div {
        gap: 0.35rem !important;
    }
    [data-testid="stMetric"] p,
    [data-testid="metric-container"] p {
        margin-bottom: 0.2rem !important;
        line-height: 1.3 !important;
    }
    /* ãƒ©ãƒ™ãƒ«ã‚’ãƒã‚¤ãƒ“ãƒ¼ç³»ã§çµ±ä¸€ */
    [data-testid="stMetric"] label,
    [data-testid="metric-container"] label {
        color: #334155 !important;
        font-weight: 600 !important;
    }
    /* é …ç›®é¸æŠæ™‚ï¼ˆselectbox / radio / multiselectï¼‰ã®æ–‡å­—ã‚’å°ã•ã */
    [data-testid="stSelectbox"] label,
    [data-testid="stSelectbox"] div,
    [data-testid="stSelectbox"] p,
    [data-testid="stSelectbox"] span,
    [data-testid="stSelectbox"] [role="listbox"],
    [data-testid="stSelectbox"] [role="option"] {
        font-size: 0.85rem !important;
    }
    [data-testid="stRadio"] label,
    [data-testid="stRadio"] div,
    [data-testid="stRadio"] p,
    [data-testid="stRadio"] span {
        font-size: 0.85rem !important;
    }
    [data-testid="stMultiSelect"] label,
    [data-testid="stMultiSelect"] div,
    [data-testid="stMultiSelect"] p,
    [data-testid="stMultiSelect"] span,
    [data-testid="stMultiSelect"] [role="listbox"],
    [data-testid="stMultiSelect"] [role="option"] {
        font-size: 0.85rem !important;
    }
    [data-testid="stNumberInput"] label,
    [data-testid="stNumberInput"] div,
    [data-testid="stNumberInput"] input {
        font-size: 0.85rem !important;
    }
    /* ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼å€¤è¡¨ç¤ºã‚’å¤§ãããƒ»3æ¡ã‚«ãƒ³ãƒç”¨ */
    .stSlider [data-baseweb="slider"] ~ div,
    .stSlider div[data-baseweb="slider"] + div,
    [data-testid="stSlider"] > div > div:last-child {
        font-size: 1.4rem !important;
        font-weight: 700 !important;
    }
    </style>
    """, unsafe_allow_html=True)
	
# ğŸ¨ ç”»é¢ã®ãƒ‡ã‚¶ã‚¤ãƒ³è¨­å®š
st.set_page_config(page_title="æ¸©æ°´å¼ãƒªãƒ¼ã‚¹å¯©æŸ»AI", page_icon="ğŸ¢", layout="wide")

# ==============================================================================
# å…±é€šæ©Ÿèƒ½ & ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ€é©åŒ–ï¼ˆãƒ‡ãƒ¼ã‚¿ã¯ãƒªãƒã‚¸ãƒˆãƒªãƒ«ãƒ¼ãƒˆã§ sumaho8 ã¨å…±é€šï¼‰
# ==============================================================================
BASE_DIR = _REPO_ROOT

# ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
FONT_PATH = os.path.join(BASE_DIR, "NotoSansCJKjp-Regular.otf")
if os.path.exists(FONT_PATH):
    fe = fm.FontEntry(fname=FONT_PATH, name='NotoSansCJKjp')
    fm.fontManager.ttflist.insert(0, fe)
    plt.rcParams['font.family'] = 'NotoSansCJKjp'
    sns.set_theme(style="whitegrid", font="NotoSansCJKjp")
else:
    sns.set_theme(style="whitegrid", font="sans-serif")

# ãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥åŒ–ï¼‰
@st.cache_data(ttl=3600)
def load_json_data(filename):
    path = os.path.join(BASE_DIR, filename)
    if os.path.exists(path):
        with open(path, "r") as f:
            return json.load(f)
    return {}

# å„ç¨®ãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰
jsic_data = load_json_data("industry_trends_jsic.json")
benchmarks_data = load_json_data("industry_benchmarks.json")
hints_data = load_json_data("industry_hints.json")
jgb_rates = load_json_data("jgb_rates.json")
avg_data = load_json_data("industry_averages.json")
knowhow_data = load_json_data("leasing_knowhow.json")
bankruptcy_data = load_json_data("bankruptcy_cases.json") # å€’ç”£äº‹ä¾‹ãƒ‡ãƒ¼ã‚¿
subsidy_schedule_data = load_json_data("subsidy_schedule.json")
useful_life_data = load_json_data("useful_life_equipment.json")
lease_classification_data = load_json_data("lease_classification.json")
# ãƒªãƒ¼ã‚¹ç‰©ä»¶ãƒªã‚¹ãƒˆï¼ˆãƒãƒƒãƒˆãƒ»ç¤¾å†…åŸºæº–ã€‚ç‚¹æ•°ã§åˆ¤å®šã«åæ˜ ï¼‰
_lease_assets_raw = load_json_data("lease_assets.json")
LEASE_ASSETS_LIST = _lease_assets_raw.get("items", [])

# å®šæ€§ã€Œé€†è»¢ã®éµã€å¼·ã¿ã‚¿ã‚°ï¼ˆãƒ¯ãƒ³ãƒ›ãƒƒãƒˆãƒ»RAGç”¨ï¼‰
STRENGTH_TAG_OPTIONS = [
    "æŠ€è¡“åŠ›", "æ¥­ç•Œäººè„ˆ", "ç‰¹è¨±", "ç«‹åœ°", "å¾Œç¶™è€…ã‚ã‚Š",
    "é–¢ä¿‚è€…è³‡ç”£ã‚ã‚Š", "å–å¼•è¡Œã¨ä»˜ãåˆã„é•·ã„", "æ—¢å­˜è¿”æ¸ˆæ‡¸å¿µãªã„",
]

# å®šæ€§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°è¨‚æ­£ï¼ˆPDFã€Œqualitative scoringã€ã«æº–æ‹ ãƒ»å¯©æŸ»å…¥åŠ›ã®è¨‚æ­£æ¬„ã§ä½¿ç”¨ï¼‰
# å„é …ç›®ã¯ options: [(ã‚¹ã‚³ã‚¢å€¤, è¡¨ç¤ºãƒ©ãƒ™ãƒ«), ...] ã‚’æŒ‡å®šï¼ˆ4=æœ€é«˜ã€œ0=æœ€ä½ã®5æ®µéšï¼‰
QUALITATIVE_SCORING_CORRECTION_ITEMS = [
    {
        "id": "company_history",
        "label": "è¨­ç«‹ãƒ»çµŒå–¶å¹´æ•°",
        "weight": 10,
        "options": [
            (4, "20å¹´ä»¥ä¸Š"),
            (3, "10å¹´ã€œ20å¹´"),
            (2, "5å¹´ã€œ10å¹´"),
            (1, "3å¹´ã€œ5å¹´"),
            (0, "3å¹´æœªæº€"),
        ],
    },
    {
        "id": "customer_stability",
        "label": "é¡§å®¢å®‰å®šæ€§",
        "weight": 20,
        "options": [
            (4, "éå¸¸ã«å®‰å®šï¼ˆå¤§å£ãƒ»é•·æœŸï¼‰"),
            (3, "å®‰å®šï¼ˆåˆ†æ•£è‰¯å¥½ï¼‰"),
            (2, "æ™®é€š"),
            (1, "ã‚„ã‚„ä¸å®‰å®šï¼ˆé›†ä¸­ã‚ã‚Šï¼‰"),
            (0, "ä¸å®‰å®šãƒ»ä¾å­˜å¤§"),
        ],
    },
    {
        "id": "repayment_history",
        "label": "è¿”æ¸ˆå±¥æ­´",
        "weight": 25,
        "options": [
            (4, "5å¹´ä»¥ä¸Šå•é¡Œãªã—"),
            (3, "3å¹´ä»¥ä¸Šå•é¡Œãªã—"),
            (2, "é…å»¶å°‘ãªã„"),
            (1, "é…å»¶ãƒ»ãƒªã‚¹ã‚±ã‚ã‚Š"),
            (0, "å•é¡Œã‚ã‚Šãƒ»è¦ç¢ºèª"),
        ],
    },
    {
        "id": "business_future",
        "label": "äº‹æ¥­å°†æ¥æ€§",
        "weight": 15,
        "options": [
            (4, "æœ‰æœ›ï¼ˆæˆé•·ãƒ»ãƒ‹ãƒ¼ã‚ºç¢ºå®Ÿï¼‰"),
            (3, "ã‚„ã‚„æœ‰æœ›"),
            (2, "æ™®é€š"),
            (1, "ã‚„ã‚„æ‡¸å¿µ"),
            (0, "æ‡¸å¿µï¼ˆç¸®å°ãƒ»ç«¶äº‰æ¿€åŒ–ï¼‰"),
        ],
    },
    {
        "id": "equipment_purpose",
        "label": "è¨­å‚™ç›®çš„",
        "weight": 15,
        "options": [
            (4, "åç›Šç›´çµãƒ»å—æ³¨å¿…é ˆ"),
            (3, "ç”Ÿç”£æ€§å‘ä¸Šãƒ»çœåŠ›åŒ–"),
            (2, "æ›´æ–°ãƒ»ç¶­æŒãƒ»æ³•å®šå¯¾å¿œ"),
            (1, "ã‚„ã‚„ä¸æ˜ç¢º"),
            (0, "ä¸æ˜ç¢ºãƒ»è¦èª¬æ˜"),
        ],
    },
    {
        "id": "main_bank",
        "label": "ãƒ¡ã‚¤ãƒ³å–å¼•éŠ€è¡Œ",
        "weight": 15,
        "options": [
            (4, "ãƒ¡ã‚¤ãƒ³å…ˆã§å–å¼•è‰¯å¥½ãƒ»æ”¯æ´è¡¨æ˜"),
            (3, "ãƒ¡ã‚¤ãƒ³å…ˆ"),
            (2, "ã‚µãƒ–æ‰±ã„ãƒ»å–å¼•ã‚ã‚Š"),
            (1, "å–å¼•æµ…ã„ãƒ»ä»–ç¤¾ãƒ¡ã‚¤ãƒ³"),
            (0, "å–å¼•ãªã—ãƒ»ä¸å®‰"),
        ],
    },
]
# æ±ç”¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆé …ç›®ã« options ãŒãªã„å ´åˆç”¨ï¼‰
QUALITATIVE_SCORING_LEVELS = [
    (4, "é«˜ï¼ˆ100ç‚¹ï¼‰"),
    (3, "ã‚„ã‚„é«˜ï¼ˆ75ç‚¹ï¼‰"),
    (2, "æ¨™æº–ï¼ˆ50ç‚¹ï¼‰"),
    (1, "ã‚„ã‚„ä½ï¼ˆ25ç‚¹ï¼‰"),
    (0, "ä½ï¼ˆ0ç‚¹ï¼‰"),
]
QUALITATIVE_SCORING_LEVEL_LABELS = {v[0]: v[1] for v in QUALITATIVE_SCORING_LEVELS}
QUALITATIVE_SCORE_RANKS = [
    {"min": 80, "label": "A", "text": "å„ªè‰¯", "desc": "å®šæ€§é¢ã§å•é¡Œãªã—"},
    {"min": 60, "label": "B", "text": "è‰¯å¥½", "desc": "æ¦‚ã­è‰¯å¥½"},
    {"min": 40, "label": "C", "text": "æ™®é€š", "desc": "è¦ãƒ•ã‚©ãƒ­ãƒ¼"},
    {"min": 20, "label": "D", "text": "è¦æ³¨æ„", "desc": "æ…é‡ã«å¯©æŸ»"},
    {"min": 0, "label": "E", "text": "è¦è­¦æˆ’", "desc": "é‡ç‚¹ç¢ºèª"},
]

# å¯©æŸ»åˆ¤å®šã®å®šæ•°ï¼ˆREVIEW_EVALUATION.md ã«è¨˜è¼‰ã€‚å¤‰æ›´æ™‚ã¯å±¥æ­´ã‚’æ®‹ã™ã“ã¨ï¼‰
APPROVAL_LINE = 71  # ç·åˆã‚¹ã‚³ã‚¢ãŒã“ã®å€¤ä»¥ä¸Šã§ã€Œæ‰¿èªåœå†…ã€
SCORE_PENALTY_IF_LEARNING_REJECT = 0.5  # å­¦ç¿’ãƒ¢ãƒ‡ãƒ«åˆ¤å®šãŒå¦æ±ºã®ã¨ãå…¨ã‚¹ã‚³ã‚¢ã«ä¹—ã˜ã‚‹ä¿‚æ•°
ALERT_BORDERLINE_MIN = 68  # ã“ã®å€¤ä»¥ä¸Š71æœªæº€ã¯ã€Œæ‰¿èªãƒ©ã‚¤ãƒ³ç›´ä¸‹ã€ã§è¦ç¢ºèªã‚¢ãƒ©ãƒ¼ãƒˆã‚’å‡ºã™

def get_review_alert(res):
    """
    åˆ¤å®šçµæœ resï¼ˆlast_resultï¼‰ã‚’å—ã‘å–ã‚Šã€è¦ç¢ºèªã‹ã©ã†ã‹ã¨ç†ç”±ãƒªã‚¹ãƒˆã‚’è¿”ã™ã€‚
    æˆ»ã‚Šå€¤: (needs_review: bool, reasons: list[str])
    """
    if not res:
        return False, []
    reasons = []
    score = res.get("score") or 0
    scr = res.get("scoring_result") or {}
    decision = (scr.get("decision") or "").strip()
    # å­¦ç¿’ãƒ¢ãƒ‡ãƒ«å¦æ±ºæ™‚ã¯ã‚¹ã‚³ã‚¢ãŒ0.5å€ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€å…ƒã‚¹ã‚³ã‚¢ã«æˆ»ã—ã¦åˆ¤å®š
    if decision == "å¦æ±º":
        effective_original = score / SCORE_PENALTY_IF_LEARNING_REJECT
    else:
        effective_original = score
    if ALERT_BORDERLINE_MIN <= effective_original < APPROVAL_LINE:
        reasons.append("ã‚¹ã‚³ã‚¢ãŒæ‰¿èªãƒ©ã‚¤ãƒ³ï¼ˆ71ï¼‰ç›´ä¸‹ã§ã™ã€‚ç›®è¦–ç¢ºèªã‚’æ¨å¥¨ã—ã¾ã™ã€‚")
    if effective_original >= APPROVAL_LINE and decision == "å¦æ±º":
        reasons.append("æœ¬ç¤¾ã‚¹ã‚³ã‚¢ã¯æ‰¿èªåœå†…ã§ã™ãŒã€å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ãŒå¦æ±ºã§ã™ã€‚è¦ç¢ºèªã€‚")
    if effective_original < APPROVAL_LINE and decision == "æ‰¿èª":
        reasons.append("æœ¬ç¤¾ã¯è¦å¯©è­°ã§ã™ãŒã€å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã¯æ‰¿èªã§ã™ã€‚è¦ç¢ºèªã€‚")
    return (len(reasons) > 0, reasons)

# å¿…é ˆé …ç›®ï¼ˆæœªå…¥åŠ›ãƒ»ä¸æ­£æ™‚ã¯åˆ¤å®šé–‹å§‹ã‚’ãƒ–ãƒ­ãƒƒã‚¯ï¼‰
REQUIRED_FIELDS = [
    ("nenshu", "å£²ä¸Šé«˜", lambda v: v is not None and (v or 0) > 0),
    ("total_assets", "ç·è³‡ç”£", lambda v: v is not None and (v or 0) > 0),
]
# æ¨å¥¨é …ç›®: å–¶æ¥­åˆ©ç›Šãƒ»ç´”è³‡ç”£ï¼ˆæœªå…¥åŠ›ã ã¨å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ãƒ»è‡ªå·±è³‡æœ¬æ¯”ç‡ãŒä½¿ãˆãªã„å ´åˆã‚ã‚Šï¼‰ã€‚ãƒ•ã‚©ãƒ¼ãƒ ã§æ˜ç¤ºã®ã¿ã€‚

# éå»æ¡ˆä»¶ãƒ»ä¿‚æ•°ãƒ»ç›¸è«‡ãƒ¡ãƒ¢ãƒ»ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ãƒ‘ã‚¹ã¯ data_cases ã§å®šç¾©ï¼ˆCASES_FILE, COEFF_OVERRIDES_FILE ç­‰ã‚’ import æ¸ˆã¿ï¼‰
DEBATE_FILE = os.path.join(BASE_DIR, "debate_logs.jsonl") # ãƒ‡ã‚£ãƒ™ãƒ¼ãƒˆãƒ­ã‚°
# ãƒãƒƒãƒˆã§å–å¾—ã—ãŸæ¥­ç•Œç›®å®‰ã‚’ä¸­åˆ†é¡ã”ã¨ã«ä¿å­˜ï¼ˆå¹´1å›ãƒ»4æœˆ1æ—¥ã‚’å¢ƒã«æ›´æ–°ï¼‰
WEB_BENCHMARKS_FILE = os.path.join(BASE_DIR, "web_industry_benchmarks.json")
TRENDS_EXTENDED_FILE = os.path.join(BASE_DIR, "industry_trends_extended.json")
ASSETS_BENCHMARKS_FILE = os.path.join(BASE_DIR, "industry_assets_benchmarks.json")
SALES_BAND_FILE = os.path.join(BASE_DIR, "sales_band_benchmarks.json")
# åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”¨ç”»åƒï¼ˆæ‰¿èªãƒ¬ãƒ™ãƒ«ãƒ»æ¥­ç¨®ãƒ»ç‰©ä»¶ã«æ²¿ã£ã¦é¸æŠï¼‰
DASHBOARD_IMAGES_DIR = os.path.join(BASE_DIR, "dashboard_images")
DASHBOARD_IMAGES_ASSETS = os.environ.get("DASHBOARD_IMAGES_ASSETS", "").strip()
# ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ã®å€™è£œï¼ˆç’°å¢ƒå¤‰æ•°æœªè¨­å®šæ™‚ã¯ã“ã®é †ã§è©¦ã™ï¼‰
def _dashboard_image_base_dirs():
    if DASHBOARD_IMAGES_ASSETS and os.path.isdir(DASHBOARD_IMAGES_ASSETS):
        yield DASHBOARD_IMAGES_ASSETS.rstrip(os.sep)
    if os.path.isdir(DASHBOARD_IMAGES_DIR):
        yield DASHBOARD_IMAGES_DIR
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç’°å¢ƒå¤‰æ•° DASHBOARD_IMAGES_FALLBACK ã¾ãŸã¯ clawd ç›´ä¸‹ã® assets
    fallback_env = os.environ.get("DASHBOARD_IMAGES_FALLBACK", "").strip()
    candidates = []
    if fallback_env and os.path.isdir(fallback_env):
        candidates.append(fallback_env)
    candidates.append(os.path.join(os.path.dirname(BASE_DIR), "assets"))
    for candidate in candidates:
        if candidate and os.path.isdir(candidate):
            yield candidate
            break

def get_dashboard_image_path(hantei: str, industry_major: str, industry_sub: str, asset_name: str):
    """
    æ‰¿èªãƒ¬ãƒ™ãƒ«ãƒ»æ¥­ç¨®ãƒ»ç‰©ä»¶ã«æ²¿ã£ãŸãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”¨ç”»åƒãƒ‘ã‚¹ã‚’è¿”ã™ã€‚
    æˆ»ã‚Šå€¤: (path or None, caption)
    """
    is_approved = (hantei or "").strip() == "æ‰¿èªåœå†…"

    def pick_fname(base_dir):
        """ãƒ•ã‚©ãƒ«ãƒ€ã«å¿œã˜ãŸãƒ•ã‚¡ã‚¤ãƒ«åã‚’è¿”ã™ï¼ˆassets ç”¨é•·ã„åå‰ / dashboard_images ç”¨çŸ­ã„åå‰ï¼‰"""
        use_long_names = "cursor" in base_dir or "assets" in base_dir
        if use_long_names:
            if "å»ºè¨­" in (industry_major or "") or "D " in (industry_major or ""):
                f = "IMG_1754-cc58ef0c-3f27-4ebd-b33b-81b57f1fb833.png"
            elif "åŒ»ç™‚" in (industry_major or "") or "ç¦ç¥‰" in (industry_major or "") or "P " in (industry_major or ""):
                f = "IMG_1793-152eae6e-9149-4c8e-91b6-c570711199bf.png"
            elif "é‹è¼¸" in (industry_major or "") or "H " in (industry_major or ""):
                f = "72603010-1AA5-4BEA-824C-DC847E2CF765-7e30894e-bac6-4875-b652-b23064d771b4.png"
            elif "è£½é€ " in (industry_major or "") or "E " in (industry_major or ""):
                f = "______-ce4d90f7-0277-4df5-ac9a-025441cabbc9.png"
            else:
                f = "______-fe3eb438-36a6-4842-9359-254247925b3b.png"
            if is_approved and ("å»ºè¨­" not in (industry_major or "") and "D " not in (industry_major or "") and "åŒ»ç™‚" not in (industry_major or "") and "ç¦ç¥‰" not in (industry_major or "")):
                f = "1849E856-971D-4B79-AD5E-E1074D93B043-55ad16b8-11ff-4717-8e5d-5a920fecae0d.png"
            elif not is_approved and ("å»ºè¨­" in (industry_major or "") or "D " in (industry_major or "")):
                f = "______-ce4d90f7-0277-4df5-ac9a-025441cabbc9.png"
            elif not is_approved:
                f = "______-fe3eb438-36a6-4842-9359-254247925b3b.png"
            return f
        # dashboard_images ç”¨çŸ­ã„åå‰
        if "å»ºè¨­" in (industry_major or "") or "D " in (industry_major or ""):
            f = "construction.png"
        elif "åŒ»ç™‚" in (industry_major or "") or "ç¦ç¥‰" in (industry_major or "") or "P " in (industry_major or ""):
            f = "nurse.png"
        elif "é‹è¼¸" in (industry_major or "") or "H " in (industry_major or ""):
            f = "vehicle.png"
        else:
            f = "default.png"
        if not is_approved:
            f = "review.png" if os.path.isfile(os.path.join(base_dir, "review.png")) else f
        elif is_approved and not os.path.isfile(os.path.join(base_dir, f)):
            f = "approved.png" if os.path.isfile(os.path.join(base_dir, "approved.png")) else "default.png"
        return f

    cap = f"{hantei or 'â€”'} / {industry_sub or 'â€”'}"
    for base in _dashboard_image_base_dirs():
        fname = pick_fname(base)
        path = os.path.join(base, fname)
        if os.path.isfile(path):
            return path, cap
    # ã©ã‚Œã«ã‚‚ç„¡ã‘ã‚Œã°ã€å€™è£œãƒ•ã‚©ãƒ«ãƒ€ã®ã€Œä»»æ„ã®1æšã€ã‚’è¡¨ç¤ºï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
    for base in _dashboard_image_base_dirs():
        try:
            for entry in os.listdir(base):
                if entry.lower().endswith((".png", ".jpg", ".jpeg")):
                    p = os.path.join(base, entry)
                    if os.path.isfile(p):
                        return p, cap
        except Exception:
            pass
    return None, ""

# å®šä¾‹ã®æ„šç—´ãƒªã‚¹ãƒˆï¼ˆé›»å…‰æ²ç¤ºæ¿ç”¨ï¼‰ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼è¿½åŠ åˆ†ã¯ byoki_list.json ã«ä¿å­˜
BYOKI_JSON = os.path.join(BASE_DIR, "byoki_list.json")
TEIREI_BYOKI_DEFAULT = [
    "ã“ã‚“ãªæ•°å­—ã§é€šãã†ãªã‚“ã¦ã€æ­£æ°—ã§ã™ã‹â€¦ï¼Ÿ ã“ã£ã¡ã¯æ¯æ—¥1ä¸‡ä»¶è¿‘ãè¦‹ã¦ã‚‹ã‚“ã§ã™ã‘ã©ã€‚",
    "è‡ªå·±è³‡æœ¬æ¯”ç‡ãŒã“ã®æ°´æº–ã§ãƒªãƒ¼ã‚¹å¯©æŸ»ã«æ¥ã‚‹åº¦èƒ¸ã€ã¡ã‚‡ã£ã¨è¦‹ç¿’ã„ãŸã„ã§ã™ã€‚æœ¬å½“ã«ã€‚",
    "èµ¤å­—ã§ã€Œå¯©æŸ»ãŠé¡˜ã„ã—ã¾ã™ã€ã£ã¦ã€ç§ã®ç›®ãŒæ­»ã‚“ã§ã‚‹ã®æ°—ã¥ã„ã¦ã¾ã™ï¼Ÿ æ°—ã¥ã„ã¦ã¦è¨€ã£ã¦ã¾ã™ï¼Ÿ",
    "æ•°å€¤è¦‹ãŸç¬é–“ã€å¿ƒãŒæŠ˜ã‚Œã‹ã‘ãŸã€‚â€¦ã„ã‚„ã€æŠ˜ã‚ŒãŸã€‚æŠ˜ã‚Œã¦ã‚‹ã€‚",
    "æ¥­ç•Œå¹³å‡ã®è©±ã€èã„ãŸã“ã¨ã‚ã‚Šã¾ã™ï¼Ÿ ãªã„ã§ã™ã‚ˆã­ã€‚ã‚ã£ãŸã‚‰ã“ã®æ•°å­—ã˜ã‚ƒãªã„ã§ã™ã‚ˆã­ã€‚",
    "ä»Šæ—¥ã‚‚æ›¸é¡ã¨æ•°å­—ã®æµ·ã§æ³³ã„ã§ã¾ã™ã€‚æººã‚Œãã†ã§ã™ã€‚",
    "ãƒªãƒ¼ã‚¹å¯©æŸ»ã€æ¥½ã ã£ã¦æ€ã£ã¦ã‚‹äººã„ã¾ã›ã‚“ã‚ˆã­ã€‚ã„ã¾ã›ã‚“ã‚ˆã­â€¦ï¼Ÿ",
]

def load_byoki_list():
    """å®šä¾‹ã®æ„šç—´ãƒªã‚¹ãƒˆã‚’èª­ã¿è¾¼ã‚€ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‹byoki_list.json ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼è¿½åŠ åˆ†ï¼‰"""
    out = list(TEIREI_BYOKI_DEFAULT)
    if not os.path.exists(BYOKI_JSON):
        return out
    try:
        with open(BYOKI_JSON, "r", encoding="utf-8") as f:
            data = json.load(f)
        custom = data.get("items") or data if isinstance(data, list) else data.get("items", [])
        if isinstance(custom, list):
            out.extend([str(x).strip() for x in custom if str(x).strip()])
    except Exception:
        pass
    return out

def save_byoki_append(new_text):
    """æ„šç—´ã‚’1ä»¶è¿½åŠ ã—ã¦ byoki_list.json ã«ä¿å­˜"""
    new_text = (new_text or "").strip()
    if not new_text:
        return False
    try:
        if os.path.exists(BYOKI_JSON):
            with open(BYOKI_JSON, "r", encoding="utf-8") as f:
                data = json.load(f)
            items = data.get("items", [])
        else:
            items = []
        items.append(new_text)
        with open(BYOKI_JSON, "w", encoding="utf-8") as f:
            json.dump({"items": items}, f, ensure_ascii=False, indent=2)
        return True
    except Exception:
        return False


def _get_benchmark_cutoff_date():
    """æ¥­ç•Œç›®å®‰ã‚’ã€å¹´1å›ãƒ»4æœˆ1æ—¥ã€ã§æ›´æ–°ã™ã‚‹ãŸã‚ã®åŸºæº–æ—¥ã€‚ã“ã®æ—¥ä»˜ä»¥é™ã«å–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’æœ‰åŠ¹ã¨ã™ã‚‹ã€‚"""
    today = datetime.date.today()
    april1_this = datetime.date(today.year, 4, 1)
    if today >= april1_this:
        return april1_this
    return datetime.date(today.year - 1, 4, 1)


def _load_web_benchmarks_cache():
    """ä¿å­˜æ¸ˆã¿ã®ãƒãƒƒãƒˆæ¥­ç•Œç›®å®‰ã‚’èª­ã¿è¾¼ã‚€"""
    if not os.path.exists(WEB_BENCHMARKS_FILE):
        return {}
    try:
        with open(WEB_BENCHMARKS_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return {}


# ãƒãƒƒãƒˆæ¤œç´¢ã§å–å¾—ãƒ»ä¿å­˜ã™ã‚‹æ¥­ç•Œç›®å®‰ã®ã‚­ãƒ¼ä¸€è¦§ï¼ˆæŒ‡æ¨™ã® bench ã«ãã®ã¾ã¾æ¸¡ã™ï¼‰
_WEB_BENCH_KEYS = [
    "op_margin", "equity_ratio", "gross_margin", "ord_margin", "net_margin", "dep_ratio",
    "roa", "roe", "asset_turnover", "fixed_ratio", "debt_ratio",
    "fixed_to_equity", "debt_to_equity", "fixed_asset_turnover", "current_asset_ratio", "current_ratio",
]


def _save_web_benchmark(industry_sub: str, data: dict):
    """ä¸­åˆ†é¡ã”ã¨ã®æ¥­ç•Œç›®å®‰ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½è¨˜ãƒ»ä¸Šæ›¸ãã™ã‚‹ã€‚å…¨æŒ‡æ¨™ã‚­ãƒ¼ã‚’ä¿å­˜ã€‚"""
    cache = _load_web_benchmarks_cache()
    entry = {"fetched_at": datetime.date.today().isoformat(), "snippets": data.get("snippets", [])}
    for k in _WEB_BENCH_KEYS:
        v = data.get(k)
        if v is not None:
            entry[k] = v
    cache[industry_sub] = entry
    try:
        with open(WEB_BENCHMARKS_FILE, "w", encoding="utf-8") as f:
            json.dump(cache, f, ensure_ascii=False, indent=2)
    except Exception:
        pass


def _load_json_cache(filepath: str):
    if not os.path.exists(filepath):
        return {}
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return {}


def _save_json_cache(filepath: str, data: dict):
    try:
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception:
        pass


# æ¥­ç•Œãƒˆãƒ¬ãƒ³ãƒ‰æ‹¡å……ãƒ»è³‡ç”£ç›®å®‰ãƒ»å£²ä¸Šè¦æ¨¡å¸¯ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆ4æœˆ1æ—¥åŸºæº–ã§å†åˆ©ç”¨ï¼‰
trends_extended_cache = {}
assets_benchmarks_cache = {}
sales_band_cache = {}


def _ensure_web_caches_loaded():
    global trends_extended_cache, assets_benchmarks_cache, sales_band_cache
    if not trends_extended_cache and os.path.exists(TRENDS_EXTENDED_FILE):
        trends_extended_cache.update(_load_json_cache(TRENDS_EXTENDED_FILE))
    if not assets_benchmarks_cache and os.path.exists(ASSETS_BENCHMARKS_FILE):
        assets_benchmarks_cache.update(_load_json_cache(ASSETS_BENCHMARKS_FILE))
    if not sales_band_cache and os.path.exists(SALES_BAND_FILE):
        sales_band_cache.update(_load_json_cache(SALES_BAND_FILE))


def fetch_industry_trend_extended(industry_sub: str, force_refresh: bool = False):
    """æ¥­ç•Œãƒˆãƒ¬ãƒ³ãƒ‰ã‚’ãƒãƒƒãƒˆã§æ¤œç´¢ã—ã¦æ‹¡å……ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜ã€‚4æœˆ1æ—¥åŸºæº–ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ‰åŠ¹ã€‚"""
    if not industry_sub:
        return ""
    _ensure_web_caches_loaded()
    cutoff = _get_benchmark_cutoff_date()
    cached = trends_extended_cache.get(industry_sub)
    if cached and not force_refresh:
        try:
            if datetime.date.fromisoformat(cached.get("fetched_at", "")) >= cutoff:
                return cached.get("text", "") or ""
        except (ValueError, TypeError):
            pass
    query = f"{industry_sub} æ¥­ç•Œå‹•å‘ 2025 èª²é¡Œ è¦‹é€šã—"
    try:
        try:
            from ddgs import DDGS
        except ImportError:
            from duckduckgo_search import DDGS
        results = list(DDGS().text(query, region="jp-jp", max_results=4))
    except Exception:
        return ""
    text_parts = []
    for r in results[:4]:
        body = (r.get("body") or "").strip()
        if body:
            text_parts.append(body[:400])
    text = "\n".join(text_parts)[:2000] if text_parts else ""
    trends_extended_cache[industry_sub] = {"fetched_at": datetime.date.today().isoformat(), "text": text}
    _save_json_cache(TRENDS_EXTENDED_FILE, trends_extended_cache)
    return text


def fetch_industry_assets_from_web(industry_sub: str, force_refresh: bool = False):
    """æ¥­ç¨®åˆ¥ã®ç·è³‡ç”£ãƒ»æµå‹•æ¯”ç‡ã®ç›®å®‰ã‚’ãƒãƒƒãƒˆæ¤œç´¢ã—ã¦ä¿å­˜ã€‚è¿”å´: {total_assets_ratio, current_ratio} ã®è¾æ›¸çš„åˆ©ç”¨ã€‚"""
    _ensure_web_caches_loaded()
    import re
    out = {"total_assets_note": "", "current_ratio": None}
    if not industry_sub:
        return out
    cached = assets_benchmarks_cache.get(industry_sub)
    if cached and not force_refresh:
        try:
            if datetime.date.fromisoformat(cached.get("fetched_at", "")) >= _get_benchmark_cutoff_date():
                return {k: cached.get(k) for k in ["total_assets_note", "current_ratio"]}
        except (ValueError, TypeError):
            pass
    query = f"{industry_sub} æ¥­ç•Œ ç·è³‡ç”£ æµå‹•æ¯”ç‡ ç›®å®‰ å¹³å‡"
    try:
        try:
            from ddgs import DDGS
        except ImportError:
            from duckduckgo_search import DDGS
        results = list(DDGS().text(query, region="jp-jp", max_results=4))
    except Exception:
        return out
    combined = " ".join([(r.get("body") or "") for r in results])
    m = re.search(r"æµå‹•æ¯”ç‡[^\d]*([0-9]+\.?[0-9]*)\s*%?", combined)
    if m:
        try:
            out["current_ratio"] = float(m.group(1))
        except ValueError:
            pass
    out["total_assets_note"] = combined[:500] if combined else ""
    assets_benchmarks_cache[industry_sub] = {"fetched_at": datetime.date.today().isoformat(), **out}
    _save_json_cache(ASSETS_BENCHMARKS_FILE, assets_benchmarks_cache)
    return out


def fetch_sales_band_benchmarks(force_refresh: bool = False):
    """å£²ä¸Šè¦æ¨¡å¸¯åˆ¥ã®åˆ©ç›Šç‡ç­‰ã‚’ãƒãƒƒãƒˆæ¤œç´¢ã—ã¦ä¿å­˜ã€‚å…¨ä½“ã§1ä»¶ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã€‚"""
    _ensure_web_caches_loaded()
    if sales_band_cache.get("fetched_at") and not force_refresh:
        try:
            if datetime.date.fromisoformat(sales_band_cache["fetched_at"]) >= _get_benchmark_cutoff_date():
                return sales_band_cache.get("text", "")
        except (ValueError, TypeError):
            pass
    query = "ä¸­å°ä¼æ¥­ å£²ä¸Šè¦æ¨¡ åˆ©ç›Šç‡ å¹³å‡ å£²ä¸Šé«˜åˆ¥ çµ±è¨ˆ"
    try:
        try:
            from ddgs import DDGS
        except ImportError:
            from duckduckgo_search import DDGS
        results = list(DDGS().text(query, region="jp-jp", max_results=4))
    except Exception:
        return ""
    text = "\n".join([(r.get("body") or "")[:300] for r in results[:4]])
    sales_band_cache["fetched_at"] = datetime.date.today().isoformat()
    sales_band_cache["text"] = text
    _save_json_cache(SALES_BAND_FILE, sales_band_cache)
    return text


def get_trend_extended(industry_sub: str):
    """æ¥­ç•Œãƒˆãƒ¬ãƒ³ãƒ‰æ‹¡å……ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒã‚ã‚Œã°ãã‚Œã€ãªã‘ã‚Œã°ç©ºï¼‰ã€‚"""
    _ensure_web_caches_loaded()
    c = trends_extended_cache.get(industry_sub)
    return (c.get("text") or "") if c else ""


def get_assets_benchmark(industry_sub: str):
    """æ¥­ç¨®åˆ¥è³‡ç”£ç›®å®‰ã‚’è¿”ã™ã€‚"""
    _ensure_web_caches_loaded()
    c = assets_benchmarks_cache.get(industry_sub)
    return c if c else {}


def get_sales_band_text():
    """å£²ä¸Šè¦æ¨¡å¸¯åˆ¥æŒ‡æ¨™ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™ã€‚"""
    _ensure_web_caches_loaded()
    return sales_band_cache.get("text", "") or ""


def search_subsidies_by_industry(industry_sub: str):
    """æ¥­ç¨®ã«ç´ã¥ãè£œåŠ©é‡‘ä¸€è¦§ã‚’è¿”ã™ã€‚subsidy_schedule.json ã® industries ã§æ¤œç´¢ã€‚"""
    out = []
    for s in (subsidy_schedule_data.get("subsidies") or []):
        if industry_sub in (s.get("industries") or []):
            out.append(s)
    return out


def search_equipment_by_keyword(keyword: str):
    """è€ç”¨å¹´æ•°ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§è¨­å‚™ã‚’æ¤œç´¢ã€‚"""
    if not keyword or not useful_life_data:
        return []
    out = []
    kw = keyword.strip().lower()
    for cat in (useful_life_data.get("categories") or []):
        for item in (cat.get("items") or []):
            name = (item.get("name") or "")
            if kw in name.lower():
                out.append({"category": cat.get("name"), **item})
    return out


def get_lease_classification_text():
    """ãƒªãƒ¼ã‚¹åˆ¤å®šãƒ•ãƒ­ãƒ¼ã¨å¥‘ç´„å½¢æ…‹åˆ¥æ¡ä»¶ã®è¦ç´„ã‚’è¿”ã™ã€‚"""
    if not lease_classification_data:
        return ""
    lines = ["ã€ãƒªãƒ¼ã‚¹åˆ¤å®šã®ç›®å®‰ã€‘"]
    for step in (lease_classification_data.get("classification_flow") or []):
        lines.append(f"Step{step.get('step')}: {step.get('question')} â†’ {step.get('yes_go') or step.get('no_go')}")
    lines.append("")
    for ct in (lease_classification_data.get("contract_types") or []):
        lines.append(f"â–  {ct.get('type')}: {ct.get('summary')}")
        for t in (ct.get("typical_conditions") or [])[:3]:
            lines.append(f"  - {t}")
    return "\n".join(lines)


def scrape_article_text(url):
    """æŒ‡å®šã•ã‚ŒãŸURLã‹ã‚‰è¨˜äº‹æœ¬æ–‡ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã™ã‚‹ï¼ˆç°¡æ˜“ç‰ˆï¼‰ã€‚"""
    try:
        import requests
        from bs4 import BeautifulSoup
    except ImportError:
        st.error("è¨˜äº‹èª­ã¿è¾¼ã¿æ©Ÿèƒ½ã«ã¯è¿½åŠ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦ã§ã™: pip install requests beautifulsoup4")
        return None

    try:
        headers = {
            "User-Agent": (
                "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                "AppleWebKit/537.36 (KHTML, like Gecko) "
                "Chrome/58.0.3029.110 Safari/537.3"
            )
        }
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, "html.parser")

        article_body = soup.find("article") or soup.find("main") or soup.body
        if article_body is None:
            return "æœ¬æ–‡ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ãƒšãƒ¼ã‚¸æ§‹é€ ã‚’è§£æã§ãã¾ã›ã‚“ã€‚"

        paragraphs = article_body.find_all("p")
        if not paragraphs:
            return "æœ¬æ–‡ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚æœ¬æ–‡ã‚‰ã—ãæ®µè½ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"

        text = " ".join(p.get_text() for p in paragraphs)
        return text[:5000] if text else "æœ¬æ–‡ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
    except Exception as e:
        return f"è¨˜äº‹ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}"


def is_japanese_text(text: str, threshold: float = 0.2) -> bool:
    """ãƒ†ã‚­ã‚¹ãƒˆä¸­ã«æ—¥æœ¬èªï¼ˆã²ã‚‰ãŒãªãƒ»ã‚«ã‚¿ã‚«ãƒŠãƒ»æ¼¢å­—ï¼‰ãŒä¸€å®šå‰²åˆä»¥ä¸Šå«ã¾ã‚Œã‚‹ã‹ã‚’åˆ¤å®šã™ã‚‹ã€‚"""
    if not text:
        return False

    jp_count = 0
    total = 0
    for ch in text:
        if ch.isspace():
            continue
        total += 1
        if (
            ("\u3040" <= ch <= "\u30ff")   # ã²ã‚‰ãŒãªãƒ»ã‚«ã‚¿ã‚«ãƒŠ
            or ("\u4e00" <= ch <= "\u9faf") # CJKçµ±åˆæ¼¢å­—
            or ("\uff66" <= ch <= "\uff9d") # åŠè§’ã‚«ãƒŠ
        ):
            jp_count += 1

    if total == 0:
        return False
    return jp_count / total >= threshold


def get_advice_context_extras(selected_sub: str, selected_major: str):
    """AIã‚¢ãƒ‰ãƒã‚¤ã‚¹ç”¨ã«ã€è£œåŠ©é‡‘ãƒ»è€ç”¨å¹´æ•°ãƒ»ãƒªãƒ¼ã‚¹åˆ†é¡ãƒ»æ¥­ç•Œãƒˆãƒ¬ãƒ³ãƒ‰æ‹¡å……ãƒ»è³‡ç”£ç›®å®‰ãƒ»å£²ä¸Šè¦æ¨¡å¸¯ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ã¾ã¨ã‚ã¦è¿”ã™ã€‚"""
    parts = []
    subs = search_subsidies_by_industry(selected_sub)
    if subs:
        parts.append("ã€è©²å½“æ¥­ç¨®ã®è£œåŠ©é‡‘ä¾‹ã€‘")
        for s in subs[:5]:
            line = f"- {s.get('name')}: {s.get('summary')} ç”³è«‹ç›®å®‰: {s.get('application_period')}"
            if s.get("url"):
                line += f" å•ã„åˆã‚ã›å…ˆ: {s.get('url')}"
            parts.append(line)
    lc = get_lease_classification_text()
    if lc:
        parts.append("\n" + lc)
    trend_ex = get_trend_extended(selected_sub)
    if trend_ex:
        parts.append("\nã€æ¥­ç•Œãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆæ‹¡å……ï¼‰ã€‘\n" + trend_ex[:1200])
    ab = get_assets_benchmark(selected_sub)
    if ab.get("current_ratio") is not None:
        parts.append(f"\nã€æ¥­ç•Œã®è³‡ç”£ç›®å®‰ã€‘æµå‹•æ¯”ç‡ç›®å®‰: {ab['current_ratio']}%")
    if ab.get("total_assets_note"):
        parts.append("ç·è³‡ç”£ãƒ»æ¥­ç•Œãƒ¡ãƒ¢: " + ab["total_assets_note"][:300])
    sb = get_sales_band_text()
    if sb:
        parts.append("\nã€å£²ä¸Šè¦æ¨¡å¸¯åˆ¥ã®ç›®å®‰ã€‘\n" + sb[:600])
    # éå»ã®ç«¶åˆãƒ»æˆç´„é‡‘åˆ©ï¼ˆçµ±è¨ˆã‹ã‚‰å–å¾—ã—ã€ç«¶åˆã«å‹ã¤å¯¾ç­–ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦æ¸¡ã™ï¼‰
    stats = get_stats(selected_sub)
    if stats.get("top_competitors_lost"):
        parts.append("\nã€éå»ã«è² ã‘ãŒå¤šã„ç«¶åˆã€‘" + "ã€".join(stats["top_competitors_lost"][:5]))
    if stats.get("avg_winning_rate") is not None and stats["avg_winning_rate"] > 0:
        parts.append(f"\nã€åŒæ¥­ç¨®ã®å¹³å‡æˆç´„é‡‘åˆ©ã€‘{stats['avg_winning_rate']:.2f}%")
    if stats.get("top_competitors_lost") or (stats.get("avg_winning_rate") and stats["avg_winning_rate"] > 0):
        parts.append("\nä¸Šè¨˜ã®ç«¶åˆå‹•å‘ãƒ»æˆç´„é‡‘åˆ©ã‚’è¸ã¾ãˆã€ç«¶åˆã«å‹ã¤ãŸã‚ã®å¯¾ç­–ã‚‚è€ƒæ…®ã—ã¦ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã—ã¦ãã ã•ã„ã€‚")
    return "\n".join(parts) if parts else ""


def get_indicator_analysis_for_advice(last_result: dict):
    """
    last_result ã‹ã‚‰æ¥­ç•Œç›®å®‰ã‚’çµ„ã¿ç«‹ã¦ã€æŒ‡æ¨™ã®å·®ã®åˆ†æï¼ˆè¦ç´„ãƒ»å†…è¨³ï¼‰ã¨æŒ‡æ¨™ä¸€è¦§ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™ã€‚
    AIç›¸è«‡ã§ã€ŒæŒ‡æ¨™ã®åˆ†æã¨æ”¹å–„ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã€ã«ä½¿ã†ã€‚
    è¿”å´: (summary, detail, indicators_text)ã€‚ãƒ‡ãƒ¼ã‚¿ãŒç„¡ã„å ´åˆã¯ ("", "", "")ã€‚
    """
    if not last_result:
        return "", "", ""
    fin = last_result.get("financials", {})
    if not fin:
        return "", "", ""
    selected_sub = last_result.get("industry_sub", "")
    major = last_result.get("industry_major", "")
    bench = dict(benchmarks_data.get(selected_sub, {}))
    cache = _load_web_benchmarks_cache()
    cached = cache.get(selected_sub, {})
    for k in _WEB_BENCH_KEYS:
        if cached.get(k) is not None:
            bench[k] = cached[k]
    bench_ext = dict(bench)
    if major and avg_data and major in avg_data:
        avg = avg_data[major]
        an = avg.get("nenshu") or 0
        if an > 0:
            if bench_ext.get("gross_margin") is None:
                bench_ext["gross_margin"] = (avg.get("gross_profit") or 0) / an * 100
            if bench_ext.get("ord_margin") is None:
                bench_ext["ord_margin"] = (avg.get("ord_profit") or 0) / an * 100
            if bench_ext.get("net_margin") is None:
                bench_ext["net_margin"] = (avg.get("net_income") or 0) / an * 100
            if bench_ext.get("dep_ratio") is None:
                bench_ext["dep_ratio"] = (avg.get("depreciation") or 0) / an * 100
        total_avg = (avg.get("machines") or 0) + (avg.get("other_assets") or 0) + (avg.get("bank_credit") or 0) + (avg.get("lease_credit") or 0)
        if total_avg > 0:
            if bench_ext.get("roa") is None:
                bench_ext["roa"] = (avg.get("net_income") or 0) / total_avg * 100
            if bench_ext.get("asset_turnover") is None:
                bench_ext["asset_turnover"] = an / total_avg
            if bench_ext.get("fixed_ratio") is None:
                bench_ext["fixed_ratio"] = ((avg.get("machines") or 0) + (avg.get("other_assets") or 0)) / total_avg * 100
            if bench_ext.get("debt_ratio") is None:
                bench_ext["debt_ratio"] = ((avg.get("bank_credit") or 0) + (avg.get("lease_credit") or 0)) / total_avg * 100
    indicators = compute_financial_indicators(fin, bench_ext)
    if not indicators:
        return "", "", ""
    summary, detail = analyze_indicators_vs_bench(indicators)
    lines = []
    for ind in indicators:
        row = f"- {ind['name']}: è²´ç¤¾ {ind['value']:.1f}{ind.get('unit','%')}"
        if ind.get("bench") is not None:
            row += f" / æ¥­ç•Œç›®å®‰ {ind['bench']:.1f}{ind.get('unit','%')}"
        lines.append(row)
    indicators_text = "\n".join(lines)
    return summary, detail, indicators_text


def save_debate_log(data):
    """ãƒ‡ã‚£ãƒ™ãƒ¼ãƒˆçµæœã‚’ä¿å­˜"""
    data["timestamp"] = datetime.datetime.now().isoformat()
    try:
        with open(DEBATE_FILE, "a", encoding="utf-8") as f:
            f.write(json.dumps(data, ensure_ascii=False) + "\n")
    except Exception as e:
        st.error(f"ãƒ‡ã‚£ãƒ™ãƒ¼ãƒˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")




def get_stats(target_sub_industry):
    cases = load_all_cases()
    target_cases = [c for c in cases if c.get("industry_sub") == target_sub_industry]
    count = len(target_cases)
    
    if count == 0:
        return {"count": 0, "closed_count": 0, "avg_score": 0.0, "approved_count": 0, "close_rate": 0.0, "lost_reasons": [], "top_competitors_lost": [], "avg_winning_rate": None}
    
    scores = [c["result"]["score"] for c in target_cases if "result" in c]
    avg_score = sum(scores) / len(scores) if scores else 0.0
    approved_count = len([s for s in scores if s >= 70])
    
    closed_cases = [c for c in target_cases if c.get("final_status") == "æˆç´„"]
    lost_cases = [c for c in target_cases if c.get("final_status") == "å¤±æ³¨"]
    total_finished = len(closed_cases) + len(lost_cases)
    
    close_rate = 0.0
    if total_finished > 0:
        close_rate = len(closed_cases) / total_finished
        
    lost_reasons = [c.get("lost_reason") for c in lost_cases if c.get("lost_reason")]
    
    # ã‚ˆãè² ã‘ã‚‹ç«¶åˆåï¼ˆå¤±æ³¨æ¡ˆä»¶ã® competitor_name ã‚’é›†è¨ˆã€å¤šã„é †ï¼‰
    competitor_names = [c.get("competitor_name", "").strip() for c in lost_cases if c.get("competitor_name")]
    top_competitors_lost = []
    if competitor_names:
        from collections import Counter
        counted = Counter(competitor_names)
        top_competitors_lost = [name for name, _ in counted.most_common(10)]
    
    # å¹³å‡çš„ãªæˆç´„é‡‘åˆ©ï¼ˆæˆç´„æ¡ˆä»¶ã® final_rate ã®å¹³å‡ã€0 ã‚’é™¤ãï¼‰
    winning_rates = [c.get("final_rate") for c in closed_cases if c.get("final_rate") is not None and (isinstance(c.get("final_rate"), (int, float)) and c.get("final_rate") > 0)]
    avg_winning_rate = sum(winning_rates) / len(winning_rates) if winning_rates else None
    
    return {
        "count": count,
        "closed_count": len(closed_cases),
        "avg_score": avg_score,
        "approved_count": approved_count,
        "close_rate": close_rate,
        "lost_reasons": lost_reasons,
        "top_competitors_lost": top_competitors_lost,
        "avg_winning_rate": avg_winning_rate,
    }



def build_contract_report_pdf(analysis):
    """
    æˆç´„ã®æ­£ä½“ãƒ¬ãƒãƒ¼ãƒˆã®åˆ†æçµæœã‚’PDFãƒã‚¤ãƒˆåˆ—ã§è¿”ã™ã€‚A4 1æšã«åã¾ã‚‹ã‚ˆã†ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã€‚
    æ—¥æœ¬èªè¡¨ç¤ºã®ãŸã‚ãƒªãƒã‚¸ãƒˆãƒªãƒ«ãƒ¼ãƒˆã® IPAexGothic ã‚’ä½¿ç”¨ï¼ˆç„¡ã‘ã‚Œã° Helvetica ã§ä»£æ›¿ï¼‰ã€‚
    """
    from io import BytesIO
    from reportlab.lib import colors
    from reportlab.lib.pagesizes import A4
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.lib.units import mm
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle

    buffer = BytesIO()
    # A4 1æšã«åã‚ã‚‹: ä½™ç™½ã‚’å°ã•ã
    margin = 12 * mm
    doc = SimpleDocTemplate(buffer, pagesize=A4, leftMargin=margin, rightMargin=margin, topMargin=margin, bottomMargin=margin)
    styles = getSampleStyleSheet()
    try:
        from reportlab.pdfbase import pdfmetrics
        from reportlab.pdfbase.ttfonts import TTFont
        font_path = os.path.join(_REPO_ROOT, "IPAexGothic.ttf")
        if os.path.isfile(font_path):
            pdfmetrics.registerFont(TTFont("JP", font_path))
            font_name = "JP"
        else:
            font_name = "Helvetica"
    except Exception:
        font_name = "Helvetica"

    def safe_text(text):
        return (text or "").replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")

    # 1æšåã‚: ãƒ•ã‚©ãƒ³ãƒˆå°ã•ã‚ãƒ»ã‚¹ãƒšãƒ¼ã‚¹æœ€å°
    body_style = ParagraphStyle("BodyJP", parent=styles["Normal"], fontName=font_name, fontSize=8, leading=10)
    title_style = ParagraphStyle("CustomTitle", parent=styles["Heading1"], fontName=font_name, fontSize=14, leading=16)
    h2_style = ParagraphStyle("CustomH2", parent=styles["Heading2"], fontName=font_name, fontSize=10, leading=12)
    thin = 1.5 * mm

    story = []
    story.append(Paragraph(safe_text("æˆç´„ã®æ­£ä½“ãƒ¬ãƒãƒ¼ãƒˆ"), title_style))
    n = analysis["closed_count"]
    story.append(Paragraph(safe_text(f"æˆç´„ {n} ä»¶ã‚’åˆ†æã—ã¾ã—ãŸã€‚"), body_style))
    story.append(Spacer(1, thin))

    story.append(Paragraph(safe_text("ã€æˆç´„è¦å› ã€‘ä¸Šä½3å› å­"), h2_style))
    for i, d in enumerate(analysis["top3_drivers"], 1):
        story.append(Paragraph(safe_text(f"{i}. {d['label']} ä¿‚æ•°{d['coef']:.4f}ï¼ˆ{d['direction']}ï¼‰"), body_style))
    story.append(Spacer(1, thin))

    story.append(Paragraph(safe_text("ã€æˆç´„æ¡ˆä»¶ã®å¹³å‡è²¡å‹™ã€‘"), h2_style))
    if analysis["avg_financials"]:
        rows = [["æŒ‡æ¨™", "å¹³å‡å€¤"]]
        for k, v in analysis["avg_financials"].items():
            if "è‡ªå·±è³‡æœ¬" in k:
                rows.append([k, f"{v:.1f}%"])
            elif isinstance(v, float) and abs(v) >= 1:
                rows.append([k, f"{v:,.0f}"])
            else:
                rows.append([k, f"{v:.4f}"])
        t = Table(rows, colWidths=[75*mm, 50*mm])
        t.setStyle(TableStyle([
            ("FONTNAME", (0, 0), (-1, -1), font_name),
            ("FONTSIZE", (0, 0), (-1, -1), 7),
            ("LEFTPADDING", (0, 0), (-1, -1), 3),
            ("RIGHTPADDING", (0, 0), (-1, -1), 3),
            ("TOPPADDING", (0, 0), (-1, -1), 2),
            ("BOTTOMPADDING", (0, 0), (-1, -1), 2),
            ("BACKGROUND", (0, 0), (-1, 0), colors.lightgrey),
            ("GRID", (0, 0), (-1, -1), 0.5, colors.grey),
        ]))
        story.append(t)
    else:
        story.append(Paragraph(safe_text("è²¡å‹™ãƒ‡ãƒ¼ã‚¿ãªã—"), body_style))
    story.append(Spacer(1, thin))

    story.append(Paragraph(safe_text("ã€å®šæ€§ã‚¿ã‚° ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€‘"), h2_style))
    if analysis["tag_ranking"]:
        # ä¸Šä½10ä»¶ã‚’1è¡Œã€œæ•°è¡Œã«åœ§ç¸®
        parts = [f"{rank}.{tag}({count})" for rank, (tag, count) in enumerate(analysis["tag_ranking"][:10], 1)]
        story.append(Paragraph(safe_text(" ".join(parts)), body_style))
    else:
        story.append(Paragraph(safe_text("å®šæ€§ã‚¿ã‚°ãªã—"), body_style))
    story.append(Spacer(1, thin))

    story.append(Paragraph(safe_text("ã€å®šæ€§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã€‘"), h2_style))
    qs = analysis.get("qualitative_summary")
    if qs and (qs.get("avg_weighted") is not None or qs.get("avg_combined") is not None or qs.get("rank_distribution")):
        n_qual = qs.get("n_with_qual", 0)
        line = f"å…¥åŠ›{n_qual}ä»¶"
        if qs.get("avg_weighted") is not None:
            line += f" åŠ é‡å¹³å‡{qs['avg_weighted']:.1f}/100"
        if qs.get("avg_combined") is not None:
            line += f" åˆè¨ˆå¹³å‡{qs['avg_combined']:.1f}"
        if qs.get("rank_distribution"):
            dist = " ".join(f"{r}:{c}ä»¶" for r, c in sorted(qs["rank_distribution"].items(), key=lambda x: (-x[1], x[0])))
            line += f" ãƒ©ãƒ³ã‚¯åˆ†å¸ƒ {dist}"
        story.append(Paragraph(safe_text(line), body_style))
    else:
        story.append(Paragraph(safe_text("å®šæ€§ã‚¹ã‚³ã‚¢å…¥åŠ›æ¡ˆä»¶ãªã—"), body_style))

    doc.build(story)
    return buffer.getvalue()


# å¸‚å ´é‡‘åˆ©ã®å–å¾—é–¢æ•°
def get_market_rate(year_month, term_years=5):
    if year_month not in jgb_rates:
        keys = sorted(jgb_rates.keys())
        if keys:
            year_month = keys[-1]
        else:
            return 1.0
            
    rate_data = jgb_rates[year_month]
    if term_years >= 8:
        return rate_data.get("10y", 1.0)
    else:
        return rate_data.get("5y", 0.5)

def _ollama_chat_http(model: str, messages: list, timeout_seconds: int):
    """
    Ollama ã® HTTP API ã‚’ç›´æ¥å©ãã€‚requests ã® timeout ã§ç¢ºå®Ÿã«åˆ‡ã‚‹ã€‚
    """
    try:
        import requests
    except ImportError:
        raise RuntimeError("requests ãŒå¿…è¦ã§ã™: pip install requests")

    base = os.environ.get("OLLAMA_HOST", "http://localhost:11434").rstrip("/")
    url = base + "/api/chat"
    payload = {"model": model, "messages": messages, "stream": False}
    try:
        resp = requests.post(url, json=payload, timeout=timeout_seconds)
    except requests.exceptions.ConnectTimeout:
        raise RuntimeError(
            f"Ollama ãŒ {timeout_seconds} ç§’ä»¥å†…ã«å¿œç­”ã—ã¾ã›ã‚“ã§ã—ãŸã€‚\n"
            "ãƒ»ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ `ollama serve` ãŒå‹•ã„ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n"
            "ãƒ»ãƒ¢ãƒ‡ãƒ«ãŒé‡ã„å ´åˆã¯åˆå›ã®å¿œç­”ã«æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ã€‚è»½ã„ãƒ¢ãƒ‡ãƒ«ï¼ˆä¾‹: lease-annaï¼‰ã‚’è©¦ã™ã‹ã€Gemini API ã«åˆ‡ã‚Šæ›¿ãˆã¦ãã ã•ã„ã€‚"
        )
    except requests.exceptions.ConnectionError as e:
        raise RuntimeError(
            "Ollama ã«æ¥ç¶šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚\n"
            "ãƒ»ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ **ollama serve** ã‚’å®Ÿè¡Œã—ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚\n"
            f"ãƒ»æ¥ç¶šå…ˆ: {base}\n"
            f"ãƒ»è©³ç´°: {e}"
        )
    except requests.exceptions.Timeout:
        raise RuntimeError(
            f"Ollama ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸï¼ˆ{timeout_seconds}ç§’ï¼‰ã€‚\n"
            "ãƒ»è»½ã„ãƒ¢ãƒ‡ãƒ«ï¼ˆlease-anna ç­‰ï¼‰ã‚’è©¦ã™ã‹ã€ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ Gemini API ã«åˆ‡ã‚Šæ›¿ãˆã¦ãã ã•ã„ã€‚"
        )

    if resp.status_code == 404:
        try:
            err_body = resp.json()
            err_msg = err_body.get("error", resp.text)
        except Exception:
            err_msg = resp.text
        raise RuntimeError(
            f"ãƒ¢ãƒ‡ãƒ«ã€Œ{model}ã€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\n"
            f"ãƒ»ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ **ollama pull {model}** ã‚’å®Ÿè¡Œã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ã—ã¦ãã ã•ã„ã€‚\n"
            f"ãƒ»ã¾ãŸã¯ã‚µã‚¤ãƒ‰ãƒãƒ¼ã€ŒAIãƒ¢ãƒ‡ãƒ«è¨­å®šã€ã§åˆ¥ã®ãƒ¢ãƒ‡ãƒ«ï¼ˆä¾‹: lease-annaï¼‰ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚\n"
            f"ãƒ»Ollamaã®è©³ç´°: {err_msg[:200]}"
        )
    resp.raise_for_status()
    data = resp.json()
    if "message" in data and "content" in data["message"]:
        return {"message": {"content": data["message"]["content"]}}
    raise RuntimeError("Ollama ã®å¿œç­”å½¢å¼ãŒä¸æ­£ã§ã™ã€‚")


def _gemini_chat(api_key: str, model: str, messages: list, timeout_seconds: int):
    """
    Gemini API ã§ãƒãƒ£ãƒƒãƒˆã€‚messages ã¯ [{"role":"user","content":"..."}] å½¢å¼ã€‚
    æœ€å¾Œã® user ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ã—ã¦é€ã‚Šã€è¿”ç­”ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™ã€‚
    """
    if not api_key or not api_key.strip():
        return {"message": {"content": "Gemini APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ç’°å¢ƒå¤‰æ•° GEMINI_API_KEY ã¾ãŸã¯ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"}}
    prompt = ""
    for m in messages:
        if m.get("role") == "user" and m.get("content"):
            prompt = m["content"]
    if not prompt:
        return {"message": {"content": "é€ä¿¡ã™ã‚‹å†…å®¹ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"}}
    try:
        import google.generativeai as genai
    except ImportError:
        return {"message": {"content": "Gemini ã‚’ä½¿ã†ã«ã¯ pip install google-generativeai ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"}}

    try:
        genai.configure(api_key=api_key.strip())
        gemini_model = genai.GenerativeModel(model)
        try:
            config = genai.types.GenerationConfig(max_output_tokens=2048, temperature=0.7)
            response = gemini_model.generate_content(prompt, generation_config=config)
        except (AttributeError, TypeError):
            response = gemini_model.generate_content(prompt)

        if not response:
            return {"message": {"content": "Gemini ã‹ã‚‰å¿œç­”ãŒè¿”ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"}}

        # response.text ã¯ãƒ–ãƒ­ãƒƒã‚¯æ™‚ãªã©ã« ValueError ã‚’å‡ºã™ã“ã¨ãŒã‚ã‚‹
        text = None
        try:
            if response.text:
                text = response.text
        except (ValueError, AttributeError):
            pass
        if not text and getattr(response, "candidates", None):
            for c in response.candidates:
                if getattr(c, "content", None) and getattr(c.content, "parts", None):
                    for p in c.content.parts:
                        if getattr(p, "text", None):
                            text = (text or "") + p.text
                    if text:
                        break
        if text and text.strip():
            return {"message": {"content": text.strip()}}
        # ãƒ–ãƒ­ãƒƒã‚¯ã‚„ç©ºå¿œç­”
        return {"message": {"content": "Gemini ã‹ã‚‰ç©ºã®å¿œç­”ã‹ã€å®‰å…¨ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã§ãƒ–ãƒ­ãƒƒã‚¯ã•ã‚ŒãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å¤‰ãˆã¦å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚"}}
    except Exception as e:
        err = str(e).strip().lower()
        if "429" in err or "quota" in err or "resource_exhausted" in err or "rate limit" in err:
            return {"message": {"content": (
                "**Gemini ã®åˆ©ç”¨æ ï¼ˆç„¡æ–™æ ã®1æ—¥åˆ¶é™ï¼‰ã«é”ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚**\n\n"
                "ãƒ»ç„¡æ–™æ ã¯1æ—¥ã‚ãŸã‚Šã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°ã«ä¸Šé™ãŒã‚ã‚Šã¾ã™ã€‚\n"
                "ãƒ»æ˜æ—¥ã«ãªã‚‹ã¾ã§ãŠå¾…ã¡ã„ãŸã ãã‹ã€[Google AI Studio](https://aistudio.google.com/) ã§åˆ©ç”¨çŠ¶æ³ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n"
                "ãƒ»æœ‰æ–™ãƒ—ãƒ©ãƒ³ã«ã™ã‚‹ã¨åˆ¶é™ãŒç·©å’Œã•ã‚Œã¾ã™ã€‚\n\n"
                f"ã€APIã®è©³ç´°ã€‘{str(e)[:300]}"
            )}}
        return {"message": {"content": f"Gemini API ã‚¨ãƒ©ãƒ¼: {str(e)}\n\nAPIã‚­ãƒ¼ã¨ãƒ¢ãƒ‡ãƒ«åï¼ˆ{model}ï¼‰ã‚’ç¢ºèªã—ã€ãƒãƒƒãƒˆæ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"}}


def _chat_for_thread(engine: str, model: str, messages: list, timeout_seconds: int, api_key: str = "", gemini_model: str = ""):
    """
    ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¹ãƒ¬ãƒƒãƒ‰ã‹ã‚‰å‘¼ã¶ç”¨ã€‚st.session_state ã‚’å‚ç…§ã—ãªã„ã€‚
    engine ãŒ "gemini" ã®ã¨ãã¯ api_key ã¨ gemini_model ã‚’ä½¿ç”¨ã€‚
    """
    if engine == "gemini":
        api_key = (api_key or "").strip() or os.environ.get("GEMINI_API_KEY", "")
        if not api_key:
            return {"message": {"content": "Gemini APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ç’°å¢ƒå¤‰æ•° GEMINI_API_KEY ã¾ãŸã¯ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"}}
        try:
            with concurrent.futures.ThreadPoolExecutor(max_workers=1) as ex:
                future = ex.submit(_gemini_chat, api_key, gemini_model or "gemini-2.0-flash", messages, timeout_seconds)
                return future.result(timeout=min(timeout_seconds + 30, 90))
        except Exception as e:
            return {"message": {"content": f"Gemini ãŒå¿œç­”ã—ã¾ã›ã‚“ã§ã—ãŸã€‚\n\nã€è©³ç´°ã€‘{str(e)}"}}
    try:
        return _ollama_chat_http(model, messages, timeout_seconds)
    except Exception as e:
        return {"message": {"content": f"AIã‚µãƒ¼ãƒãƒ¼ãŒå¿œç­”ã—ã¾ã›ã‚“ã§ã—ãŸ: {e}"}}


def chat_with_retry(model, messages, retries=2, timeout_seconds=120):
    """
    AI ã¸ã®ãƒãƒ£ãƒƒãƒˆå‘¼ã³å‡ºã—ã€‚ã‚¨ãƒ³ã‚¸ãƒ³ãŒ Gemini ã®å ´åˆã¯ Gemini APIã€å¦åˆ™ Ollamaã€‚
    """
    engine = st.session_state.get("ai_engine", "ollama")
    if engine == "gemini":
        api_key = (st.session_state.get("gemini_api_key") or "").strip() or GEMINI_API_KEY_ENV
        api_key = api_key or _get_gemini_key_from_secrets()
        gemini_model = st.session_state.get("gemini_model", GEMINI_MODEL_DEFAULT)
        # ãƒ‡ãƒãƒƒã‚°ç”¨: æœ€å¾Œã®å‘¼ã³å‡ºã—çµæœã‚’ä¿å­˜
        if "last_gemini_debug" not in st.session_state:
            st.session_state["last_gemini_debug"] = ""
        for i in range(retries):
            try:
                # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã§ãƒãƒ³ã‚°ã—ãªã„ã‚ˆã†åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œ
                with concurrent.futures.ThreadPoolExecutor(max_workers=1) as ex:
                    future = ex.submit(_gemini_chat, api_key, gemini_model, messages, timeout_seconds)
                    try:
                        out = future.result(timeout=min(timeout_seconds + 30, 90))
                    except concurrent.futures.TimeoutError:
                        st.session_state["last_gemini_debug"] = "ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆå¿œç­”ãŒè¿”ã‚‹ã¾ã§å¾…ã¡ã¾ã—ãŸãŒå¿œç­”ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼‰"
                        st.error("Gemini ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚ãƒãƒƒãƒˆæ¥ç¶šã‚’ç¢ºèªã™ã‚‹ã‹ã€ã—ã°ã‚‰ãã—ã¦å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚")
                        return {"message": {"content": "Gemini ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚ãƒãƒƒãƒˆæ¥ç¶šã‚’ç¢ºèªã™ã‚‹ã‹ã€ã—ã°ã‚‰ãã—ã¦å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚"}}
                content = (out.get("message") or {}).get("content", "")
                st.session_state["last_gemini_debug"] = "OK" if content and "APIã‚­ãƒ¼ãŒ" not in content and "Gemini API ã‚¨ãƒ©ãƒ¼:" not in content else (content[:200] + "..." if len(content or "") > 200 else (content or "ï¼ˆç©ºï¼‰"))
                # ã‚¨ãƒ©ãƒ¼ç³»ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãªã‚‰ç”»é¢ä¸Šã«ã‚‚ st.error ã§è¡¨ç¤º
                if content and (
                    "APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“" in content
                    or "Gemini API ã‚¨ãƒ©ãƒ¼:" in content
                    or "pip install" in content
                    or "å¿œç­”ãŒè¿”ã‚Šã¾ã›ã‚“ã§ã—ãŸ" in content
                    or "å®‰å…¨ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã§ãƒ–ãƒ­ãƒƒã‚¯" in content
                    or "åˆ©ç”¨æ " in content
                    or "ç„¡æ–™æ " in content
                ):
                    st.error(content)
                return out
            except Exception as e:
                err = str(e)
                st.session_state["last_gemini_debug"] = f"ä¾‹å¤–: {err}"
                if "429" in err or "quota" in err.lower() or "resource_exhausted" in err.lower() or "rate limit" in err.lower():
                    time.sleep(2 * (i + 1))
                    continue
                st.error(f"Gemini API ã‚¨ãƒ©ãƒ¼: {err}")
                return {"message": {"content": f"Gemini ãŒå¿œç­”ã—ã¾ã›ã‚“ã§ã—ãŸã€‚\n\nã€è©³ç´°ã€‘{err}"}}
        st.session_state["last_gemini_debug"] = "ãƒªãƒˆãƒ©ã‚¤ä¸Šé™ï¼ˆã¾ãŸã¯åˆ©ç”¨æ ã®å¯èƒ½æ€§ï¼‰"
        return {"message": {"content": (
            "Gemini ãŒå¿œç­”ã—ã¾ã›ã‚“ã§ã—ãŸã€‚\n\n"
            "**ç„¡æ–™æ ã®1æ—¥ã‚ãŸã‚Šã®åˆ¶é™ã«é”ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚**\n"
            "ãƒ»æ˜æ—¥ã¾ã§ãŠå¾…ã¡ã„ãŸã ãã‹ã€[Google AI Studio](https://aistudio.google.com/) ã§åˆ©ç”¨çŠ¶æ³ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n"
            "ãƒ»APIã‚­ãƒ¼ãƒ»ãƒ¢ãƒ‡ãƒ«åãƒ»ãƒãƒƒãƒˆæ¥ç¶šã‚‚ã‚ã‚ã›ã¦ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
        )}}

    last_error = None
    for i in range(retries):
        try:
            return _ollama_chat_http(model, messages, timeout_seconds)
        except Exception as e:
            last_error = str(e)
            if "429" in last_error:
                time.sleep(2 * (i + 1))
                continue
            break

    if last_error:
        st.error(f"AIã‚µãƒ¼ãƒãƒ¼ãŒå¿œç­”ã—ã¾ã›ã‚“ã§ã—ãŸ: {last_error}")
        detail = f"\n\nã€æŠ€è¡“çš„ãªè©³ç´°ã€‘{last_error}"
        if "timed out" in last_error or "Timeout" in last_error:
            detail += "\n\nğŸ’¡ å·¦ã‚µã‚¤ãƒ‰ãƒãƒ¼ã€ŒAIãƒ¢ãƒ‡ãƒ«è¨­å®šã€ã§ **Gemini API** ã«åˆ‡ã‚Šæ›¿ãˆã‚‹ã‹ã€**lease-anna** ç­‰ã®è»½ã„ãƒ¢ãƒ‡ãƒ«ã‚’è©¦ã—ã¦ãã ã•ã„ã€‚"
    else:
        st.error("AIã‚µãƒ¼ãƒãƒ¼ãŒå¿œç­”ã—ã¾ã›ã‚“ã§ã—ãŸã€‚")
        detail = ""
    return {
        "message": {
            "content": "AIãŒå¿œç­”ã—ã¾ã›ã‚“ã§ã—ãŸã€‚æ™‚é–“ã‚’ç½®ãã‹ã€Gemini API ã«åˆ‡ã‚Šæ›¿ãˆã¦å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚" + detail
        }
    }


def generate_battle_special_move(strength_tags: list, passion_text: str) -> tuple:
    """
    å®šæ€§ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€Œå¿…æ®ºæŠ€åã€ã¨ã€Œç‰¹æ®ŠåŠ¹æœã€ã‚’1ã¤ç”Ÿæˆã™ã‚‹ã€‚
    æˆ»ã‚Šå€¤: (name: str, effect: str)ã€‚å¤±æ•—æ™‚ã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’è¿”ã™ã€‚
    """
    fallback = ("é€†è»¢ã®æ„æ°—", "ã‚¹ã‚³ã‚¢+5%")
    if not strength_tags and not (passion_text or "").strip():
        return fallback
    model = get_ollama_model() if st.session_state.get("ai_engine") == "ollama" else GEMINI_MODEL_DEFAULT
    tags_str = "ã€".join(strength_tags) if strength_tags else "ãªã—"
    text_snippet = (passion_text or "")[:300]
    prompt = f"""ä»¥ä¸‹ã‹ã‚‰ã€å¯©æŸ»ã‚²ãƒ¼ãƒ ç”¨ã®ã€Œå¿…æ®ºæŠ€ã€ã‚’1ã¤ã ã‘è€ƒãˆã¦ãã ã•ã„ã€‚
å¼·ã¿ã‚¿ã‚°: {tags_str}
ç†±æ„ãƒ»è£äº‹æƒ…ï¼ˆæŠœç²‹ï¼‰: {text_snippet or "ãªã—"}

å¿…æ®ºæŠ€ã¯ã€Œåå‰ã€ã¨ã€ŒåŠ¹æœã€ã®2ã¤ã ã‘ã€‚1è¡Œã§ç­”ãˆã¦ãã ã•ã„ã€‚å½¢å¼ã¯å¿…ãš:
å¿…æ®ºæŠ€å / åŠ¹æœã®çŸ­ã„èª¬æ˜
ä¾‹: è€èˆ—ã®æš–ç°¾ / ãƒ€ãƒ¡ãƒ¼ã‚¸ç„¡åŠ¹
ä¾‹: æ¥­ç•Œäººè„ˆã®ç›¾ / æµå‹•æ€§+10%
æ—¥æœ¬èªã§ã€å¿…æ®ºæŠ€åã¯10æ–‡å­—ä»¥å†…ã€åŠ¹æœã¯15æ–‡å­—ä»¥å†…ã€‚ä»–ã¯å‡ºåŠ›ã—ãªã„ã€‚"""
    try:
        out = chat_with_retry(model, [{"role": "user", "content": prompt}], retries=1, timeout_seconds=15)
        content = ((out.get("message") or {}).get("content") or "").strip()
        if " / " in content:
            parts = content.split(" / ", 1)
            return (parts[0].strip()[:20] or fallback[0], (parts[1].strip()[:25] or fallback[1]))
    except Exception:
        pass
    return fallback


def is_ai_available(timeout_seconds: int = 3) -> bool:
    """
    ç¾åœ¨é¸æŠä¸­ã®AIã‚¨ãƒ³ã‚¸ãƒ³ãŒåˆ©ç”¨å¯èƒ½ã‹ã©ã†ã‹ã€‚
    Gemini ã®å ´åˆã¯ API ã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã‚Œã° Trueã€‚
    Ollama ã®å ´åˆã¯ã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã‚Œã° Trueã€‚
    """
    engine = st.session_state.get("ai_engine", "ollama")
    if engine == "gemini":
        key = st.session_state.get("gemini_api_key", "").strip() or GEMINI_API_KEY_ENV
        key = key or _get_gemini_key_from_secrets()
        return bool(key)
    return is_ollama_available(timeout_seconds)


def is_ollama_available(timeout_seconds: int = 3) -> bool:
    """
    Ollamaã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ã‚’ç°¡æ˜“ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã€‚
    èµ·å‹•ã—ã¦ã„ãªã„çŠ¶æ…‹ã§ chat_with_retry ã‚’å‘¼ã¶ã¨æ°¸é å¾…ã¡ã«ãªã‚Šã‚„ã™ã„ã®ã§ã€
    äº‹å‰ã«ã“ã“ã§æ¤œçŸ¥ã—ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«æ¡ˆå†…ã‚’å‡ºã™ã€‚
    """
    try:
        import requests
    except ImportError:
        # ã™ã§ã«è¨˜äº‹ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ç­‰ã§ requests ã‚’ä½¿ã£ã¦ã„ã‚‹å‰æ
        return False

    base = os.environ.get("OLLAMA_HOST", "http://localhost:11434").rstrip("/")
    url = base + "/api/tags"
    try:
        resp = requests.get(url, timeout=timeout_seconds)
        return resp.status_code == 200
    except Exception:
        return False


def run_ollama_connection_test(timeout_seconds: int = 10) -> str:
    """
    Ollama ã®æ¥ç¶šã¨ãƒ¢ãƒ‡ãƒ«å¿œç­”ã‚’ãƒ†ã‚¹ãƒˆã—ã€çµæœãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã™ã€‚
    ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€ŒOllamaæ¥ç¶šãƒ†ã‚¹ãƒˆã€ãƒœã‚¿ãƒ³ç”¨ã€‚
    """
    try:
        import requests
    except ImportError:
        return "âŒ requests ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“: pip install requests"

    base = os.environ.get("OLLAMA_HOST", "http://localhost:11434").rstrip("/")
    model = get_ollama_model() or OLLAMA_MODEL

    # 1) /api/tags ã§ã‚µãƒ¼ãƒãƒ¼ç”Ÿå­˜ç¢ºèª
    try:
        r = requests.get(base + "/api/tags", timeout=5)
        if r.status_code != 200:
            return f"âŒ Ollama ã‚µãƒ¼ãƒãƒ¼å¿œç­”ç•°å¸¸: {base} (HTTP {r.status_code})"
    except requests.exceptions.ConnectionError:
        return (
            f"âŒ Ollama ã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚\n"
            f"æ¥ç¶šå…ˆ: {base}\n\n"
            "**å¯¾å‡¦:** ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ä»¥ä¸‹ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\n"
            "```\nollama serve\n```"
        )
    except requests.exceptions.Timeout:
        return f"âŒ Ollama ã‚µãƒ¼ãƒãƒ¼ãŒå¿œç­”ã—ã¾ã›ã‚“ã§ã—ãŸï¼ˆ5ç§’ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼‰ã€‚\næ¥ç¶šå…ˆ: {base}"

    # 2) çŸ­ã„ãƒãƒ£ãƒƒãƒˆã§ãƒ¢ãƒ‡ãƒ«å¿œç­”ç¢ºèª
    try:
        r = requests.post(
            base + "/api/chat",
            json={"model": model, "messages": [{"role": "user", "content": "ã“ã‚“"}], "stream": False},
            timeout=timeout_seconds,
        )
        if r.status_code == 404:
            return (
                f"âš ï¸ ã‚µãƒ¼ãƒãƒ¼ã¯å‹•ã„ã¦ã„ã¾ã™ãŒã€ãƒ¢ãƒ‡ãƒ«ã€Œ{model}ã€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\n\n"
                f"**å¯¾å‡¦:** ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ä»¥ä¸‹ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\n"
                f"```\nollama pull {model}\n```\n\n"
                "ã¾ãŸã¯ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§åˆ¥ã®ãƒ¢ãƒ‡ãƒ«ï¼ˆä¾‹: lease-annaï¼‰ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚"
            )
        r.raise_for_status()
        data = r.json()
        content = (data.get("message") or {}).get("content", "")
        if content:
            return f"âœ… æ¥ç¶šOKï¼ˆãƒ¢ãƒ‡ãƒ«: {model}ï¼‰\nå¿œç­”: {content[:80]}{'â€¦' if len(content) > 80 else ''}"
        return f"âœ… æ¥ç¶šOKï¼ˆãƒ¢ãƒ‡ãƒ«: {model}ï¼‰\nï¼ˆå¿œç­”æœ¬æ–‡ã¯ç©ºã§ã—ãŸï¼‰"
    except requests.exceptions.Timeout:
        return (
            f"âš ï¸ ãƒ¢ãƒ‡ãƒ«ã€Œ{model}ã€ãŒ {timeout_seconds} ç§’ä»¥å†…ã«å¿œç­”ã—ã¾ã›ã‚“ã§ã—ãŸã€‚\n\n"
            "ãƒ»åˆå›ã¯ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã§æ™‚é–“ãŒã‹ã‹ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚\n"
            "ãƒ»è»½ã„ãƒ¢ãƒ‡ãƒ«ï¼ˆlease-anna ç­‰ï¼‰ã‚’è©¦ã™ã‹ã€Gemini API ã«åˆ‡ã‚Šæ›¿ãˆã¦ãã ã•ã„ã€‚"
        )
    except Exception as e:
        return f"âŒ ãƒãƒ£ãƒƒãƒˆãƒ†ã‚¹ãƒˆå¤±æ•—: {e}"


def _fragment_nenshu():
    """å£²ä¸Šé«˜å…¥åŠ›ã€‚ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã¯100ä¸‡åƒå††ã¾ã§ã€æ‰‹å…¥åŠ›ã¯900å„„åƒå††ã¾ã§ã€‚å¾Œã‹ã‚‰å‹•ã‹ã—ãŸæ–¹ã‚’æ¡ç”¨ã€‚"""
    st.markdown("### å£²ä¸Šé«˜")
    NENSHU_SLIDER_MAX = 1_000_000
    NENSHU_NUM_MAX = 90_000_000

    if "nenshu" not in st.session_state:
        st.session_state.nenshu = 10000
    cur = st.session_state.nenshu

    prev_key = "_san_prev_nenshuu"
    externally_changed = st.session_state.get(prev_key) != cur

    if "num_nenshuu" not in st.session_state or externally_changed:
        st.session_state["num_nenshuu"] = max(0, min(cur, NENSHU_NUM_MAX))
    if "slide_nenshuu" not in st.session_state or externally_changed:
        st.session_state["slide_nenshuu"] = max(0, min(cur, NENSHU_SLIDER_MAX))

    def _on_num_change():
        val = st.session_state["num_nenshuu"]
        st.session_state.nenshu = val
        st.session_state["slide_nenshuu"] = max(0, min(val, NENSHU_SLIDER_MAX))
        st.session_state[prev_key] = val

    def _on_slide_change():
        val = st.session_state["slide_nenshuu"]
        st.session_state.nenshu = val
        st.session_state["num_nenshuu"] = val
        st.session_state[prev_key] = val

    c_l, c_r = st.columns([0.7, 0.3])
    with c_r:
        st.number_input(
            "ç›´æ¥å…¥åŠ›",
            min_value=0,
            max_value=NENSHU_NUM_MAX,
            step=10000,
            key="num_nenshuu",
            label_visibility="collapsed",
            on_change=_on_num_change,
        )
    with c_l:
        st.slider(
            "å£²ä¸Šé«˜èª¿æ•´",
            min_value=0,
            max_value=NENSHU_SLIDER_MAX,
            step=100,
            key="slide_nenshuu",
            label_visibility="collapsed",
            format="%d",
            on_change=_on_slide_change,
        )

    nenshu = st.session_state.nenshu
    st.session_state[prev_key] = nenshu
    st.caption(f"**æ¡ç”¨å€¤: {nenshu:,} åƒå††**")
    st.caption("â€»ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ãƒ»ç›´æ¥å…¥åŠ›ã®ã©ã¡ã‚‰ã‹ã§å¤‰æ›´å¾Œã€**å…¥åŠ›ç¢ºå®š**ã¾ãŸã¯**åˆ¤å®šé–‹å§‹**ã§åæ˜ ã•ã‚Œã¾ã™ã€‚")
    st.divider()


# --- å€’ç”£ç¢ºç‡ãƒ»æ¥­ç•Œãƒªã‚¹ã‚¯æ¤œç´¢ ---
def calculate_pd(equity, current, profit):
    """
    è²¡å‹™æŒ‡æ¨™ã«åŸºã¥ãç°¡æ˜“å€’ç”£ç¢ºç‡ï¼ˆ%ï¼‰ã‚’è¨ˆç®—ã™ã‚‹ã€‚
    equity: è‡ªå·±è³‡æœ¬æ¯”ç‡ï¼ˆ%ï¼‰, current: æµå‹•æ¯”ç‡ï¼ˆ%ï¼‰, profit: å–¶æ¥­åˆ©ç›Šç‡ï¼ˆ%ï¼‰
    æ¡ä»¶ã«å¿œã˜ã¦ãƒªã‚¹ã‚¯å€¤ã‚’åŠ ç®—ã—ã€0ã€œ100%ã®ç¯„å›²ã§è¿”ã™ã€‚
    """
    risk = 0.0
    if equity < 10:
        risk += 25.0
    elif equity < 20:
        risk += 12.0
    elif equity < 30:
        risk += 5.0
    if current < 100:
        risk += 20.0
    elif current < 120:
        risk += 8.0
    elif current < 150:
        risk += 3.0
    if profit is not None and profit < 0:
        risk += 30.0
    elif profit is not None and profit < 2:
        risk += 10.0
    elif profit is not None and profit < 5:
        risk += 4.0
    return min(100.0, max(0.0, risk))


def search_bankruptcy_trends(industry_sub):
    """
    é¸æŠæ¥­ç•Œï¼ˆselected_subï¼‰ã®æœ€æ–°ã®å€’ç”£ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»ãƒªã‚¹ã‚¯æƒ…å ±ã‚’ duckduckgo-search ã§æ¤œç´¢ã™ã‚‹ã€‚
    è¿”å´: ãƒ†ã‚­ã‚¹ãƒˆã‚µãƒãƒªï¼ˆå–å¾—å¤±æ•—æ™‚ã¯ç©ºæ–‡å­—ã¾ãŸã¯ã‚¨ãƒ©ãƒ¼æ–‡è¨€ï¼‰ã€‚
    """
    try:
        from duckduckgo_search import DDGS
        query = f"{industry_sub} æ¥­ç•Œ å€’ç”£ ãƒˆãƒ¬ãƒ³ãƒ‰ ãƒªã‚¹ã‚¯ å‹•å‘"
        with DDGS() as ddgs:
            results = list(ddgs.text(keywords=query, region="jp-jp", max_results=5))
        if not results:
            return "ï¼ˆè©²å½“æ¥­ç•Œã®å€’ç”£ãƒˆãƒ¬ãƒ³ãƒ‰æƒ…å ±ã¯å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸï¼‰"
        summary = ""
        for r in results:
            summary += f"- {r.get('title', '')}: {r.get('body', '')[:200]}â€¦\n"
        return summary.strip()
    except Exception as e:
        return f"ï¼ˆæ¥­ç•Œãƒªã‚¹ã‚¯æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}ï¼‰"


# --- chat_with_retry ã®å®šç¾©ã®ä¸‹ã‚ãŸã‚Šã«è¿½è¨˜ ---
def search_latest_trends(query):
    """æœ€æ–°ã®æ¥­ç•Œå‹•å‘ã‚’ãƒãƒƒãƒˆã§æ¤œç´¢ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã§è¿”ã™"""
    try:
        from duckduckgo_search import DDGS
        with DDGS() as ddgs:
            results = list(ddgs.text(keywords=query, region='jp-jp', max_results=3))
            if not results:
                return "æ¤œç´¢çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
            
            summary = "\nã€ãƒãƒƒãƒˆæ¤œç´¢ã«ã‚ˆã‚‹æœ€æ–°å‹•å‘ã€‘\n"
            for res in results:
                summary += f"- {res['title']}: {res['body']} ({res['href']})\n"
            return summary
    except Exception as e:
        return f"\nï¼ˆæ¤œç´¢ã‚¨ãƒ©ãƒ¼ã«ã‚ˆã‚Šæœ€æ–°æƒ…å ±ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}ï¼‰"
def get_image(status):
    image_map = {
        "guide": "guide.jpg", "approve": "approve.jpg", "reject": "reject.jpg",
        "challenge": "challenge.jpg", "thinking": "thinking.jpg"
    }
    filename = image_map.get(status)
    if not filename: return None
    if os.path.exists(filename): return filename
    desktop_path = os.path.join("/Users/kobayashiisaoryou/Desktop/", filename)
    if os.path.exists(desktop_path): return desktop_path
    return None

def _parse_benchmark_number(text: str, patterns: list) -> float | None:
    """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ­£è¦è¡¨ç¾ã§æœ€åˆã«ãƒãƒƒãƒã—ãŸæ•°å€¤ã‚’è¿”ã™ã€‚"""
    import re
    for pat in patterns:
        m = re.search(pat, text)
        if m:
            try:
                return float(m.group(1))
            except (ValueError, IndexError):
                pass
    return None


def fetch_industry_benchmarks_from_web(industry_sub: str, force_refresh: bool = False):
    """
    ä¸­åˆ†é¡ã”ã¨ã«ãƒãƒƒãƒˆæ¤œç´¢ã§æ¥­ç•Œç›®å®‰ã‚’å–å¾—ã™ã‚‹ã€‚
    å–å¾—çµæœã¯ web_industry_benchmarks.json ã«ä¿å­˜ã—ã€å¹´1å›ï¼ˆ4æœˆ1æ—¥ã‚’å¢ƒï¼‰ã«ã ã‘å†æ¤œç´¢ã™ã‚‹ã€‚
    force_refresh=True ã®ã¨ãã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ç„¡è¦–ã—ã¦å¿…ãšæ¤œç´¢ãƒ»ä¿å­˜ã™ã‚‹ã€‚
    è¿”å´: {"snippets": [...], "op_margin": float or None, "equity_ratio": float or None, ...}
    æŒ‡æ¨™ã§ä½¿ã†æ¥­ç•Œç›®å®‰ï¼ˆå£²ä¸Šé«˜ç·åˆ©ç›Šç‡ãƒ»ROAãƒ»æµå‹•æ¯”ç‡ç­‰ï¼‰ã‚‚æ¤œç´¢ã—ã¦ä¿å­˜ã™ã‚‹ã€‚
    """
    import re
    out = {k: None for k in _WEB_BENCH_KEYS}
    out["snippets"] = []
    if not industry_sub:
        return out
    if not force_refresh:
        cutoff = _get_benchmark_cutoff_date()
        cache = _load_web_benchmarks_cache()
        cached = cache.get(industry_sub)
        if cached:
            try:
                fetched = datetime.date.fromisoformat(cached["fetched_at"])
                if fetched >= cutoff:
                    ret = {"snippets": cached.get("snippets", [])}
                    for k in _WEB_BENCH_KEYS:
                        if k in cached and cached[k] is not None:
                            ret[k] = cached[k]
                    return ret
            except (ValueError, TypeError):
                pass
    try:
        try:
            from ddgs import DDGS
        except ImportError:
            from duckduckgo_search import DDGS
        ddgs = DDGS()
    except Exception:
        _save_web_benchmark(industry_sub, out)
        return out

    combined_text = ""
    # ã‚¯ã‚¨ãƒª1: å–¶æ¥­åˆ©ç›Šç‡ãƒ»è‡ªå·±è³‡æœ¬æ¯”ç‡ãƒ»æ¥­ç•Œå‹•å‘
    query1 = f"{industry_sub} æ¥­ç•Œ å–¶æ¥­åˆ©ç›Šç‡ è‡ªå·±è³‡æœ¬æ¯”ç‡ å¹³å‡ æ¥­ç•Œå‹•å‘"
    try:
        results1 = list(ddgs.text(query1, region="jp-jp", max_results=5))
    except Exception:
        results1 = []
    for r in results1:
        title, body, href = (r.get("title") or ""), (r.get("body") or ""), (r.get("href") or "")
        out["snippets"].append({"title": title, "body": body, "href": href})
        combined_text += title + " " + body + " "
    # ã‚¯ã‚¨ãƒª2: å£²ä¸Šé«˜ç·åˆ©ç›Šç‡ãƒ»ROAãƒ»æµå‹•æ¯”ç‡ãƒ»å€Ÿå…¥é‡‘ç­‰ï¼ˆæŒ‡æ¨™ã®æ¥­ç•Œç›®å®‰ï¼‰
    query2 = f"{industry_sub} æ¥­ç•Œ å£²ä¸Šé«˜ç·åˆ©ç›Šç‡ çµŒå¸¸åˆ©ç›Šç‡ ROA æµå‹•æ¯”ç‡ å€Ÿå…¥é‡‘ å¹³å‡ ç›®å®‰"
    try:
        results2 = list(ddgs.text(query2, region="jp-jp", max_results=5))
    except Exception:
        results2 = []
    for r in results2:
        title, body = (r.get("title") or ""), (r.get("body") or "")
        out["snippets"].append({"title": title, "body": body, "href": r.get("href") or ""})
        combined_text += title + " " + body + " "

    # æ•°å€¤ã®æŠ½å‡ºï¼ˆ% ã¾ãŸã¯ å›ï¼‰
    def parse(patterns):
        return _parse_benchmark_number(combined_text, patterns)

    if out["op_margin"] is None:
        out["op_margin"] = parse([r"å–¶æ¥­åˆ©ç›Šç‡[^\d]*([0-9]+\.?[0-9]*)\s*%?", r"å–¶æ¥­åˆ©ç›Š[^\d]*([0-9]+\.?[0-9]*)\s*%"])
    if out["equity_ratio"] is None:
        out["equity_ratio"] = parse([r"è‡ªå·±è³‡æœ¬æ¯”ç‡[^\d]*([0-9]+\.?[0-9]*)\s*%?", r"è‡ªå·±è³‡æœ¬[^\d]*([0-9]+\.?[0-9]*)\s*%"])
    if out["gross_margin"] is None:
        out["gross_margin"] = parse([r"å£²ä¸Šé«˜ç·åˆ©ç›Šç‡[^\d]*([0-9]+\.?[0-9]*)\s*%?", r"ç²—åˆ©ç‡[^\d]*([0-9]+\.?[0-9]*)\s*%?", r"ç·åˆ©ç›Šç‡[^\d]*([0-9]+\.?[0-9]*)\s*%?"])
    if out["ord_margin"] is None:
        out["ord_margin"] = parse([r"çµŒå¸¸åˆ©ç›Šç‡[^\d]*([0-9]+\.?[0-9]*)\s*%?", r"çµŒå¸¸åˆ©ç›Š[^\d]*([0-9]+\.?[0-9]*)\s*%"])
    if out["net_margin"] is None:
        out["net_margin"] = parse([r"å½“æœŸç´”åˆ©ç›Šç‡[^\d]*([0-9]+\.?[0-9]*)\s*%?", r"ç´”åˆ©ç›Šç‡[^\d]*([0-9]+\.?[0-9]*)\s*%?"])
    if out["dep_ratio"] is None:
        out["dep_ratio"] = parse([r"æ¸›ä¾¡å„Ÿå´è²»[^\d]*([0-9]+\.?[0-9]*)\s*%?", r"æ¸›ä¾¡å„Ÿå´[^/]*/?\s*å£²ä¸Š[^\d]*([0-9]+\.?[0-9]*)\s*%?"])
    if out["roa"] is None:
        out["roa"] = parse([r"ROA[^\d]*([0-9]+\.?[0-9]*)\s*%?", r"ç·è³‡ç”£åˆ©ç›Šç‡[^\d]*([0-9]+\.?[0-9]*)\s*%?"])
    if out["roe"] is None:
        out["roe"] = parse([r"ROE[^\d]*([0-9]+\.?[0-9]*)\s*%?", r"è‡ªå·±è³‡æœ¬åˆ©ç›Šç‡[^\d]*([0-9]+\.?[0-9]*)\s*%?"])
    if out["asset_turnover"] is None:
        out["asset_turnover"] = parse([r"ç·è³‡ç”£å›è»¢ç‡[^\d]*([0-9]+\.?[0-9]*)\s*å›?", r"ç·è³‡ç”£å›è»¢[^\d]*([0-9]+\.?[0-9]*)"])
    if out["fixed_ratio"] is None:
        out["fixed_ratio"] = parse([r"å›ºå®šè³‡ç”£æ¯”ç‡[^\d]*([0-9]+\.?[0-9]*)\s*%?", r"å›ºå®šè³‡ç”£[^\d]*([0-9]+\.?[0-9]*)\s*%"])
    if out["debt_ratio"] is None:
        out["debt_ratio"] = parse([r"å€Ÿå…¥é‡‘ç­‰ä¾å­˜åº¦[^\d]*([0-9]+\.?[0-9]*)\s*%?", r"å€Ÿå…¥é‡‘[^\d]*([0-9]+\.?[0-9]*)\s*%?", r"æœ‰åˆ©å­è² å‚µ[^\d]*([0-9]+\.?[0-9]*)\s*%?"])
    if out["fixed_to_equity"] is None:
        out["fixed_to_equity"] = parse([r"å›ºå®šæ¯”ç‡[^\d]*([0-9]+\.?[0-9]*)\s*%?", r"å›ºå®šè³‡ç”£[^\d]*/[^\d]*è‡ªå·±è³‡æœ¬[^\d]*([0-9]+\.?[0-9]*)\s*%?"])
    if out["debt_to_equity"] is None:
        out["debt_to_equity"] = parse([r"è² å‚µæ¯”ç‡[^\d]*([0-9]+\.?[0-9]*)\s*%?", r"è² å‚µ[^\d]*/[^\d]*è‡ªå·±è³‡æœ¬[^\d]*([0-9]+\.?[0-9]*)\s*%?"])
    if out["fixed_asset_turnover"] is None:
        out["fixed_asset_turnover"] = parse([r"å›ºå®šè³‡ç”£å›è»¢ç‡[^\d]*([0-9]+\.?[0-9]*)\s*å›?", r"å›ºå®šè³‡ç”£å›è»¢[^\d]*([0-9]+\.?[0-9]*)"])
    if out["current_asset_ratio"] is None:
        out["current_asset_ratio"] = parse([r"æµå‹•è³‡ç”£æ¯”ç‡[^\d]*([0-9]+\.?[0-9]*)\s*%?", r"æµå‹•è³‡ç”£[^\d]*([0-9]+\.?[0-9]*)\s*%"])
    if out["current_ratio"] is None:
        out["current_ratio"] = parse([r"æµå‹•æ¯”ç‡[^\d]*([0-9]+\.?[0-9]*)\s*%?", r"æµå‹•æ¯”ç‡[^\d]*([0-9]+\.?[0-9]*)\s*%"])

    _save_web_benchmark(industry_sub, out)
    return out


def get_all_industry_sub_for_benchmarks():
    """ä»Šã®æ®µéšã§æ¥­ç•Œç›®å®‰ã‚’å–å¾—ã™ã¹ãä¸­åˆ†é¡ã®ä¸€è¦§ï¼ˆé‡è¤‡ãªã—ï¼‰ã€‚industry_benchmarks.json ã®ã‚­ãƒ¼ï¼‹éå»æ¡ˆä»¶ã®æ¥­ç¨®ã€‚"""
    subs = set()
    if benchmarks_data:
        subs.update(benchmarks_data.keys())
    for c in load_all_cases():
        sub = c.get("industry_sub")
        if sub:
            subs.add(sub)
    return sorted(subs)


def compute_financial_indicators(fin, bench=None):
    """
    å…¥åŠ›æ¸ˆã¿è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç®—å‡ºå¯èƒ½ãªæŒ‡æ¨™ã®ãƒªã‚¹ãƒˆã‚’è¿”ã™ã€‚
    fin: last_result["financials"] (åƒå††å˜ä½)
    bench: industry_benchmarks ã®å½“è©²æ¥­ç¨®ã‚¨ãƒ³ãƒˆãƒª (op_margin, equity_ratio ç­‰)
    è¿”å´: [{"name": "æŒ‡æ¨™å", "value": æ•°å€¤, "bench": æ¥­ç•Œå€¤ or None, "unit": "%" or "å›"}]
    ç®—å‡ºå¯èƒ½ãªã‚‚ã®ã¯ã™ã¹ã¦è¿½åŠ ï¼ˆåˆ©ç›Šç‡ãƒ»åŠ¹ç‡æ€§ãƒ»å®‰å®šæ€§ãƒ»è² å‚µç³»ï¼‰ã€‚
    """
    n = fin.get("nenshu") or 0
    total = fin.get("assets") or 0
    net_a = fin.get("net_assets")
    gross = fin.get("gross_profit") or 0
    op = fin.get("op_profit") or fin.get("rieki") or 0
    ord_p = fin.get("ord_profit") or 0
    net = fin.get("net_income") or 0
    machines = fin.get("machines") or 0
    other_a = fin.get("other_assets") or 0
    bank = fin.get("bank_credit") or 0
    lease = fin.get("lease_credit") or 0
    dep = fin.get("depreciation") or 0
    fixed_a = machines + other_a  # å›ºå®šè³‡ç”£ï¼ˆæ©Ÿæ¢°ï¼‹ãã®ä»–è³‡ç”£ï¼‰
    debt_total = (bank + lease)  # å€Ÿå…¥é‡‘ç­‰

    indicators = []
    # ---------- å£²ä¸Šé«˜ãƒ™ãƒ¼ã‚¹ã®åˆ©ç›Šç‡ï¼ˆå£²ä¸Šé«˜ > 0 ã§ç®—å‡ºå¯èƒ½ï¼‰ ----------
    if n > 0:
        indicators.append({"name": "å£²ä¸Šé«˜ç·åˆ©ç›Šç‡", "value": gross / n * 100, "bench": bench.get("gross_margin") if bench else None, "unit": "%"})
        indicators.append({"name": "å–¶æ¥­åˆ©ç›Šç‡", "value": op / n * 100, "bench": bench.get("op_margin") if bench else None, "unit": "%"})
        indicators.append({"name": "çµŒå¸¸åˆ©ç›Šç‡", "value": ord_p / n * 100, "bench": bench.get("ord_margin") if bench else None, "unit": "%"})
        indicators.append({"name": "å½“æœŸç´”åˆ©ç›Šç‡", "value": net / n * 100, "bench": bench.get("net_margin") if bench else None, "unit": "%"})
        if dep > 0:
            indicators.append({"name": "æ¸›ä¾¡å„Ÿå´è²»/å£²ä¸Šé«˜", "value": dep / n * 100, "bench": bench.get("dep_ratio") if bench else None, "unit": "%"})
        if fixed_a > 0:
            indicators.append({"name": "å›ºå®šè³‡ç”£å›è»¢ç‡", "value": n / fixed_a, "bench": bench.get("fixed_asset_turnover") if bench else None, "unit": "å›"})

    # ---------- ç·è³‡ç”£ãƒ»ç´”è³‡ç”£ãƒ™ãƒ¼ã‚¹ï¼ˆtotal > 0 ã§ç®—å‡ºå¯èƒ½ï¼‰ ----------
    if total > 0:
        if net_a is not None and net_a > 0:
            indicators.append({"name": "è‡ªå·±è³‡æœ¬æ¯”ç‡", "value": net_a / total * 100, "bench": _equity_ratio_display(bench.get("equity_ratio")) if bench else None, "unit": "%"})
            indicators.append({"name": "ROE(è‡ªå·±è³‡æœ¬åˆ©ç›Šç‡)", "value": net / net_a * 100, "bench": bench.get("roe") if bench else None, "unit": "%"})
            indicators.append({"name": "å›ºå®šæ¯”ç‡", "value": fixed_a / net_a * 100, "bench": bench.get("fixed_to_equity") if bench else None, "unit": "%"})
            indicators.append({"name": "è² å‚µæ¯”ç‡", "value": (total - net_a) / net_a * 100, "bench": bench.get("debt_to_equity") if bench else None, "unit": "%"})
        indicators.append({"name": "ROA(ç·è³‡ç”£åˆ©ç›Šç‡)", "value": net / total * 100, "bench": bench.get("roa") if bench else None, "unit": "%"})
        indicators.append({"name": "ç·è³‡ç”£å›è»¢ç‡", "value": n / total if n > 0 else 0, "bench": bench.get("asset_turnover") if bench else None, "unit": "å›"})
        if fixed_a > 0:
            indicators.append({"name": "å›ºå®šè³‡ç”£æ¯”ç‡", "value": fixed_a / total * 100, "bench": bench.get("fixed_ratio") if bench else None, "unit": "%"})
        # æµå‹•è³‡ç”£æ¯”ç‡ï¼ˆç·è³‡ç”£ã®ã†ã¡æµå‹•è³‡ç”£ã¨ã¿ãªã™å‰²åˆã€‚ç·è³‡ç”£âˆ’å›ºå®šè³‡ç”£ã§ç°¡æ˜“ç®—ï¼‰
        indicators.append({"name": "æµå‹•è³‡ç”£æ¯”ç‡(ç·è³‡ç”£æ¯”)", "value": (total - fixed_a) / total * 100, "bench": bench.get("current_asset_ratio") if bench else None, "unit": "%"})
        if debt_total > 0:
            indicators.append({"name": "å€Ÿå…¥é‡‘ç­‰ä¾å­˜åº¦", "value": debt_total / total * 100, "bench": bench.get("debt_ratio") if bench else None, "unit": "%"})
    return indicators


def analyze_indicators_vs_bench(indicators):
    """
    æŒ‡æ¨™ã¨æ¥­ç•Œç›®å®‰ã®å·®ã‚’è¦‹ã¦åˆ†ææ–‡ã‚’è¿”ã™ã€‚
    è¿”å´: (è¦ç´„1è¡Œ, è©³ç´°ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³)
    """
    # æ¥­ç•Œç›®å®‰ãŒã‚ã‚‹æŒ‡æ¨™ã ã‘å¯¾è±¡ï¼ˆå·®ã®æ„å‘³ã¯æŒ‡æ¨™ã”ã¨ã«è§£é‡ˆï¼‰
    above, below = [], []
    for ind in indicators:
        bench = ind.get("bench")
        if bench is None or (isinstance(bench, float) and (bench != bench)):
            continue
        name = ind["name"]
        value = ind["value"]
        unit = ind.get("unit", "%")
        diff = value - bench
        if name in LOWER_IS_BETTER_NAMES:
            # ä½ã„æ–¹ãŒè‰¯ã„ â†’ è²´ç¤¾ãŒæ¥­ç•Œã‚ˆã‚Šä½ã„ = è‰¯ã„
            if value < bench:
                above.append((name, value, bench, diff, unit))
            else:
                below.append((name, value, bench, diff, unit))
        else:
            if diff > 0:
                above.append((name, value, bench, diff, unit))
            elif diff < 0:
                below.append((name, value, bench, diff, unit))

    lines = []
    if above:
        parts = [f"**{name}**ï¼ˆè²´ç¤¾ {value:.1f}{unit} / æ¥­ç•Œç›®å®‰ {bench:.1f}{unit}ã€å·® {diff:+.1f}{unit}ï¼‰" for name, value, bench, diff, unit in above]
        lines.append("**æ¥­ç•Œç›®å®‰ã‚’ä¸Šå›ã£ã¦ã„ã‚‹æŒ‡æ¨™**\n- " + "\n- ".join(parts))
    if below:
        parts = [f"**{name}**ï¼ˆè²´ç¤¾ {value:.1f}{unit} / æ¥­ç•Œç›®å®‰ {bench:.1f}{unit}ã€å·® {diff:+.1f}{unit}ï¼‰" for name, value, bench, diff, unit in below]
        lines.append("**æ¥­ç•Œç›®å®‰ã‚’ä¸‹å›ã£ã¦ã„ã‚‹æŒ‡æ¨™**\n- " + "\n- ".join(parts))
    if not lines:
        return "æ¥­ç•Œç›®å®‰ã¨æ¯”è¼ƒã§ãã‚‹æŒ‡æ¨™ãŒã‚ã‚Šã¾ã›ã‚“ã€‚", "æ¥­ç•Œç›®å®‰ãŒç™»éŒ²ã•ã‚Œã¦ã„ã‚‹æŒ‡æ¨™ãŒã²ã¨ã¤ã‚‚ãªã„ãŸã‚ã€å·®ã®åˆ†æã¯è¡Œãˆã¾ã›ã‚“ã€‚"
    detail = "\n\n".join(lines)
    # å€Ÿå…¥é‡‘ç­‰ä¾å­˜åº¦ã®è§£é‡ˆè£œè¶³
    if any(n == "å€Ÿå…¥é‡‘ç­‰ä¾å­˜åº¦" for n, *_ in above):
        detail += "\n\nâ€» å€Ÿå…¥é‡‘ç­‰ä¾å­˜åº¦ã¯ã€Œæ¥­ç•Œã‚ˆã‚Šä½ã„ã€ï¼è² å‚µãŒç›¸å¯¾çš„ã«å°‘ãªãå¥å…¨ã¨è§£é‡ˆã—ã¦ã„ã¾ã™ã€‚"
    elif any(n == "å€Ÿå…¥é‡‘ç­‰ä¾å­˜åº¦" for n, *_ in below):
        detail += "\n\nâ€» å€Ÿå…¥é‡‘ç­‰ä¾å­˜åº¦ã¯æ¥­ç•Œã‚ˆã‚Šé«˜ãå‡ºã¦ã„ã¾ã™ã€‚è¿”æ¸ˆä½™åŠ›ãƒ»æ‹…ä¿ã¨ã®ãƒãƒ©ãƒ³ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
    # è¦ç´„1è¡Œ
    n_above, n_below = len(above), len(below)
    if n_below == 0:
        summary = "ç®—å‡ºæŒ‡æ¨™ã¯ãŠãŠã‚€ã­æ¥­ç•Œç›®å®‰ã‚’ä¸Šå›ã£ã¦ãŠã‚Šã€è²¡å‹™é¢ã¯è‰¯å¥½ã§ã™ã€‚"
    elif n_above == 0:
        summary = "ç®—å‡ºæŒ‡æ¨™ã®å¤šããŒæ¥­ç•Œç›®å®‰ã‚’ä¸‹å›ã£ã¦ã„ã¾ã™ã€‚åˆ©ç›Šç‡ãƒ»åŠ¹ç‡æ€§ãƒ»è² å‚µæ°´æº–ã®æ”¹å–„ä½™åœ°ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚"
    else:
        summary = f"æ¥­ç•Œç›®å®‰ã‚’ä¸Šå›ã£ã¦ã„ã‚‹æŒ‡æ¨™ãŒ{n_above}ä»¶ã€ä¸‹å›ã£ã¦ã„ã‚‹æŒ‡æ¨™ãŒ{n_below}ä»¶ã‚ã‚Šã¾ã™ã€‚å¼·ã¿ã‚’ç¶­æŒã—ã¤ã¤ã€ä¸‹å›ã£ã¦ã„ã‚‹é …ç›®ã®è¦å› ç¢ºèªã‚’ãŠã™ã™ã‚ã—ã¾ã™ã€‚"
    return summary, detail


# ==============================================================================
# ç”»é¢æ§‹æˆ
# ==============================================================================
mode = st.sidebar.radio("ãƒ¢ãƒ¼ãƒ‰åˆ‡æ›¿", ["ğŸ“‹ å¯©æŸ»ãƒ»åˆ†æ", "ğŸ“ çµæœç™»éŒ² (æˆç´„/å¤±æ³¨)", "ğŸ”§ ä¿‚æ•°åˆ†æãƒ»æ›´æ–° (Î²)", "ğŸ“ ä¿‚æ•°å…¥åŠ›ï¼ˆäº‹å‰ä¿‚æ•°ï¼‰", "ğŸ“Š æˆç´„ã®æ­£ä½“ãƒ¬ãƒãƒ¼ãƒˆ", "ğŸ“‰ å®šæ€§è¦å› åˆ†æ (50ä»¶ã€œ)", "ğŸ“ˆ å®šé‡è¦å› åˆ†æ (50ä»¶ã€œ)"])

with st.sidebar.expander("âš ï¸ é€”ä¸­ã§è½ã¡ã‚‹å ´åˆ", expanded=False):
    st.caption("ä¸»ãªåŸå› : (1) AIç›¸è«‡ãƒ»Gemini/Ollama ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (2) ãƒ–ãƒ©ã‚¦ã‚¶ã®ãƒ¡ãƒ¢ãƒªä¸è¶³ (3) åˆ†æçµæœã‚¿ãƒ–ã§ãƒ‡ãƒ¼ã‚¿ä¸æ•´åˆã€‚ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ `streamlit run lease_logic_sumaho8.py` ã‚’å®Ÿè¡Œã™ã‚‹ã¨ã‚¨ãƒ©ãƒ¼å†…å®¹ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚F5ã§å†èª­ã¿è¾¼ã¿ã‚‚è©¦ã—ã¦ãã ã•ã„ã€‚")

# AI ã‚¨ãƒ³ã‚¸ãƒ³é¸æŠï¼ˆOllama / Gemini APIï¼‰
if "ai_engine" not in st.session_state:
    st.session_state["ai_engine"] = "ollama"
st.sidebar.markdown("### ğŸ¤– AIãƒ¢ãƒ‡ãƒ«è¨­å®š")
engine_choice = st.sidebar.radio(
    "AIã‚¨ãƒ³ã‚¸ãƒ³",
    ["Ollamaï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ï¼‰", "Gemini APIï¼ˆGoogleï¼‰"],
    index=0 if st.session_state.get("ai_engine") == "ollama" else 1,
    help="Gemini ã‚’é¸ã¶ã¨ Google ã® Gemini 2.0 ç­‰ãŒä½¿ãˆã¾ã™ã€‚APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™ã€‚",
)
st.session_state["ai_engine"] = "gemini" if "Gemini" in engine_choice else "ollama"

if st.session_state["ai_engine"] == "gemini":
    # åˆå›ã®ã¿ç’°å¢ƒå¤‰æ•°ã§ API ã‚­ãƒ¼ã‚’åˆæœŸåŒ–ï¼ˆkey ã§ç´ä»˜ã‘ã‚‹ã¨å…¥åŠ›ãŒä¿æŒã•ã‚Œã‚‹ï¼‰
    if "gemini_api_key" not in st.session_state and GEMINI_API_KEY_ENV:
        st.session_state["gemini_api_key"] = GEMINI_API_KEY_ENV
    _key_default = (
        st.session_state.get("gemini_api_key_input", "")
        or st.session_state.get("gemini_api_key", "")
        or GEMINI_API_KEY_ENV
        or ""
    )
    st.sidebar.text_input(
        "Gemini APIã‚­ãƒ¼",
        value=_key_default,
        key="gemini_api_key_input",
        type="password",
        help="ç’°å¢ƒå¤‰æ•° GEMINI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã‚Œã°ã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚å…¥åŠ›ã™ã‚‹ã¨ä¸Šæ›¸ãã•ã‚Œã¾ã™ã€‚",
    )
    # ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã®å€¤ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«åæ˜ ã€‚æœªå…¥åŠ›æ™‚ã¯æ—¢å­˜ã‚­ãƒ¼ãƒ»ç’°å¢ƒå¤‰æ•°ã‚’ç¶­æŒï¼ˆç©ºã§ä¸Šæ›¸ãã—ãªã„ï¼‰
    widget_key = st.session_state.get("gemini_api_key_input", "")
    st.session_state["gemini_api_key"] = (
        widget_key.strip()
        or st.session_state.get("gemini_api_key", "").strip()
        or GEMINI_API_KEY_ENV
        or ""
    )
    GEMINI_MODELS = ["gemini-2.0-flash", "gemini-1.5-pro", "gemini-1.5-flash", "gemini-1.0-pro"]
    st.session_state["gemini_model"] = st.sidebar.selectbox(
        "Gemini ãƒ¢ãƒ‡ãƒ«",
        GEMINI_MODELS,
        index=0,
        help="gemini-2.0-flash ãŒãŠã™ã™ã‚ã§ã™ã€‚",
    )
    st.sidebar.caption("âš ï¸ ç„¡æ–™æ ã¯1æ—¥ã‚ãŸã‚Šã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°ã«ä¸Šé™ãŒã‚ã‚Šã¾ã™ã€‚å‹•ã‹ãªã„å ´åˆã¯ç¿Œæ—¥ã¾ã§ãŠå¾…ã¡ã‹ã€Google AI Studio ã§åˆ©ç”¨çŠ¶æ³ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
else:
    # Ollama ãƒ¢ãƒ‡ãƒ«é¸æŠ
    MODEL_OPTIONS = [
        "è‡ªå‹•ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šï¼‰",
        "lease-pro", "lease-anna", "qwen2.5", "gemma2:2b",
        "ã‚«ã‚¹ã‚¿ãƒ å…¥åŠ›",
    ]
    current_default = get_ollama_model()
    if current_default in MODEL_OPTIONS:
        initial_index = MODEL_OPTIONS.index(current_default)
    elif current_default == OLLAMA_MODEL:
        initial_index = 0
    else:
        initial_index = MODEL_OPTIONS.index("ã‚«ã‚¹ã‚¿ãƒ å…¥åŠ›")
    selected_label = st.sidebar.selectbox(
        "ä½¿ç”¨ã™ã‚‹Ollamaãƒ¢ãƒ‡ãƒ«",
        options=MODEL_OPTIONS,
        index=initial_index,
        help="ä¸€è¦§ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’é¸ã¶ã‹ã€ã€Œã‚«ã‚¹ã‚¿ãƒ å…¥åŠ›ã€ã§ä»»æ„ã®ãƒ¢ãƒ‡ãƒ«åã‚’æŒ‡å®šã§ãã¾ã™ã€‚",
    )
    custom_model_name = ""
    if selected_label == "è‡ªå‹•ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šï¼‰":
        st.session_state["ollama_model"] = ""
    elif selected_label == "ã‚«ã‚¹ã‚¿ãƒ å…¥åŠ›":
        custom_model_name = st.sidebar.text_input(
            "ãƒ¢ãƒ‡ãƒ«åã‚’ç›´æ¥å…¥åŠ›",
            value="" if initial_index != MODEL_OPTIONS.index("ã‚«ã‚¹ã‚¿ãƒ å…¥åŠ›") else current_default,
            help="ä¾‹: llama3, phi3 ãªã©ã€‚",
        )
        st.session_state["ollama_model"] = custom_model_name.strip()
    else:
        st.session_state["ollama_model"] = selected_label

    if st.sidebar.button("ğŸ”Œ Ollamaæ¥ç¶šãƒ†ã‚¹ãƒˆ", use_container_width=True, help="Ollama ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ãƒ»é¸æŠä¸­ã®ãƒ¢ãƒ‡ãƒ«ãŒå¿œç­”ã™ã‚‹ã‹ã‚’ç¢ºèªã—ã¾ã™"):
        with st.sidebar:
            with st.spinner("æ¥ç¶šç¢ºèªä¸­..."):
                msg = run_ollama_connection_test(timeout_seconds=15)
            st.session_state["ollama_test_result"] = msg
    if st.session_state.get("ollama_test_result"):
        st.sidebar.code(st.session_state["ollama_test_result"], language=None)
        if st.sidebar.button("ãƒ†ã‚¹ãƒˆçµæœã‚’æ¶ˆã™", key="clear_ollama_test"):
            st.session_state["ollama_test_result"] = ""
            st.rerun()

if st.sidebar.button("ğŸ’¾ è“„ç©ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (CSV)", use_container_width=True):
    all_logs = load_all_cases()
    if all_logs:
        flat_logs = []
        for log in all_logs:
            row = {
                "timestamp": log.get("timestamp"),
                "industry_major": log.get("industry_major"),
                "industry_sub": log.get("industry_sub"),
                "result_status": log.get("final_status"),
                "score": log.get("result", {}).get("score")
            }
            if "inputs" in log:
                row.update(log["inputs"])
            flat_logs.append(row)
        
        df_log = pd.DataFrame(flat_logs)
        csv = df_log.to_csv(index=False).encode('utf-8-sig')
        
        st.sidebar.download_button(
            "ğŸ“¥ CSVã‚’ä¿å­˜",
            data=csv,
            file_name=f"lease_cases_{datetime.date.today()}.csv",
            mime="text/csv"
        )
    else:
        st.sidebar.warning("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

if "confirm_delete" not in st.session_state:
    st.session_state.confirm_delete = False

if not st.session_state.confirm_delete:
    if st.sidebar.button("ğŸ—‘ï¸ éå»ãƒ‡ãƒ¼ã‚¿ã‚’å…¨ã¦æ¶ˆå»", use_container_width=True):
        st.session_state.confirm_delete = True
        st.rerun()
else:
    st.sidebar.warning("âš ï¸ æœ¬å½“ã«å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ¶ˆå»ã—ã¾ã™ã‹ï¼Ÿ")
    col_del_yes, col_del_no = st.sidebar.columns(2)
    with col_del_yes:
        if st.button("âœ… ã¯ã„", use_container_width=True):
            try:
                if os.path.exists(CASES_FILE):
                    os.remove(CASES_FILE)
                if os.path.exists(DEBATE_FILE):
                    os.remove(DEBATE_FILE)
                st.sidebar.success("ãƒ‡ãƒ¼ã‚¿ã‚’æ¶ˆå»ã—ã¾ã—ãŸ")
                st.session_state.confirm_delete = False
                time.sleep(1)
                st.rerun()
            except Exception as e:
                st.sidebar.error(f"æ¶ˆå»ã‚¨ãƒ©ãƒ¼: {e}")
    with col_del_no:
        if st.button("âŒ ã„ã„ãˆ", use_container_width=True):
            st.session_state.confirm_delete = False
            st.rerun()

st.sidebar.markdown("### ğŸŒ æ¥­ç•Œç›®å®‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥")
st.sidebar.caption("ä¸‹ã®ãƒœã‚¿ãƒ³ã§ãƒãƒƒãƒˆæ¤œç´¢ã—ã€å–¶æ¥­åˆ©ç›Šç‡ãƒ»è‡ªå·±è³‡æœ¬æ¯”ç‡ã«åŠ ãˆã€å£²ä¸Šé«˜ç·åˆ©ç›Šç‡ãƒ»ROAãƒ»æµå‹•æ¯”ç‡ãªã©æŒ‡æ¨™ã®æ¥­ç•Œç›®å®‰ã‚’ web_industry_benchmarks.json ã«ä¿å­˜ã—ã¾ã™ã€‚")
if st.sidebar.button("ğŸ” ä»Šã®ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œç´¢ã—ã¦ä¿å­˜ï¼ˆæ¬¡å›ã¯4æœˆ1æ—¥æ›´æ–°ï¼‰", use_container_width=True):
    subs = get_all_industry_sub_for_benchmarks()
    if not subs:
        st.sidebar.warning("æ¥­ç¨®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆindustry_benchmarks.json ã¾ãŸã¯éå»æ¡ˆä»¶ã‚’ç™»éŒ²ã—ã¦ãã ã•ã„ï¼‰")
    else:
        progress = st.sidebar.progress(0, text="æ¤œç´¢ä¸­â€¦")
        n = len(subs)
        for i, sub in enumerate(subs):
            progress.progress((i + 1) / n, text=f"{sub[:20]}â€¦")
            try:
                fetch_industry_benchmarks_from_web(sub, force_refresh=True)
            except Exception:
                pass
        progress.empty()
        st.sidebar.success(f"{n} æ¥­ç¨®ã‚’æ¤œç´¢ã—ã¦ä¿å­˜ã—ã¾ã—ãŸã€‚æ¬¡å›ã®è‡ªå‹•æ›´æ–°ã¯4æœˆ1æ—¥ã§ã™ã€‚")
        st.rerun()

if st.sidebar.button("ğŸ“¡ æ¥­ç•Œãƒˆãƒ¬ãƒ³ãƒ‰æ‹¡å……ãƒ»è³‡ç”£ç›®å®‰ãƒ»å£²ä¸Šè¦æ¨¡å¸¯ã‚’æ¤œç´¢ã—ã¦ä¿å­˜", use_container_width=True):
    subs = get_all_industry_sub_for_benchmarks()
    progress = st.sidebar.progress(0, text="ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»è³‡ç”£ç›®å®‰â€¦")
    n = max(1, len(subs) * 2 + 1)
    idx = 0
    for sub in subs:
        idx += 1
        progress.progress(idx / n, text=f"ãƒˆãƒ¬ãƒ³ãƒ‰: {sub[:15]}â€¦")
        try:
            fetch_industry_trend_extended(sub, force_refresh=True)
        except Exception:
            pass
    for sub in subs:
        idx += 1
        progress.progress(idx / n, text=f"è³‡ç”£ç›®å®‰: {sub[:15]}â€¦")
        try:
            fetch_industry_assets_from_web(sub, force_refresh=True)
        except Exception:
            pass
    progress.progress(1.0, text="å£²ä¸Šè¦æ¨¡å¸¯â€¦")
    try:
        fetch_sales_band_benchmarks(force_refresh=True)
    except Exception:
        pass
    progress.empty()
    st.sidebar.success("æ¥­ç•Œãƒˆãƒ¬ãƒ³ãƒ‰æ‹¡å……ãƒ»è³‡ç”£ç›®å®‰ãƒ»å£²ä¸Šè¦æ¨¡å¸¯ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
    st.rerun()

st.sidebar.markdown("### ğŸ“š è£œåŠ©é‡‘ãƒ»è€ç”¨å¹´æ•°ãƒ»ãƒªãƒ¼ã‚¹åˆ¤å®š")
with st.sidebar.expander("ğŸ” è£œåŠ©é‡‘ã‚’æ¥­ç¨®ã§èª¿ã¹ã‚‹", expanded=False):
    sub_keys = sorted(benchmarks_data.keys()) if benchmarks_data else []
    if sub_keys:
        search_sub = st.selectbox("æ¥­ç¨®", sub_keys, key="subsidy_search_sub")
        subs_list = search_subsidies_by_industry(search_sub)
        if subs_list:
            for s in subs_list:
                name = s.get("name") or ""
                url = (s.get("url") or "").strip()
                if url:
                    st.markdown(f"**{name}**")
                    # ãƒªãƒ³ã‚¯ãŒç¢ºå®Ÿã«é–‹ãã‚ˆã† link_button å„ªå…ˆã€ãªã‘ã‚Œã° HTML ã® <a target="_blank">
                    try:
                        st.link_button("ğŸ”— å…¬å¼ã‚µã‚¤ãƒˆã‚’é–‹ã", url, type="secondary")
                    except Exception:
                        safe_url = url.replace('"', "%22").replace("'", "%27")
                        st.markdown(f'<a href="{safe_url}" target="_blank" rel="noopener noreferrer">ğŸ”— å…¬å¼ã‚µã‚¤ãƒˆã‚’é–‹ã</a>', unsafe_allow_html=True)
                else:
                    st.markdown(f"**{name}**")
                st.caption(s.get("summary", "")[:120] + "â€¦")
                st.caption(f"ç”³è«‹ç›®å®‰: {s.get('application_period')}")
                if s.get("url_note"):
                    st.caption(s.get("url_note"))
        else:
            st.caption("è©²å½“ã™ã‚‹è£œåŠ©é‡‘ã®ç™»éŒ²ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        st.caption("æ¥­ç¨®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
with st.sidebar.expander("ğŸ” è€ç”¨å¹´æ•°ã‚’è¨­å‚™ã§èª¿ã¹ã‚‹", expanded=False):
    # å›½ç¨åºã®è€ç”¨å¹´æ•°è¡¨ã¸ã®ãƒªãƒ³ã‚¯ï¼ˆå¸¸ã«è¡¨ç¤ºï¼‰
    nta_url = (useful_life_data or {}).get("nta_useful_life_url") or "https://www.keisan.nta.go.jp/r5yokuaru/aoiroshinkoku/hitsuyokeihi/genkashokyakuhi/taiyonensuhyo.html"
    st.link_button("ğŸ“‹ å›½ç¨åºã®è€ç”¨å¹´æ•°è¡¨ã‚’å‚ç…§", nta_url, type="secondary")
    st.caption("ä¸Šè¨˜ãƒªãƒ³ã‚¯ã§å›½ç¨åºã®å…¬å¼è€ç”¨å¹´æ•°è¡¨ï¼ˆæ¸›ä¾¡å„Ÿå´è³‡ç”£ï¼‰ãŒé–‹ãã¾ã™ã€‚")
    st.divider()
    eq_key = st.text_input("è¨­å‚™åã§æ¤œç´¢", placeholder="ä¾‹: å·¥ä½œæ©Ÿæ¢°, ã‚¨ã‚¢ã‚³ãƒ³", key="equip_search")
    if eq_key:
        eq_list = search_equipment_by_keyword(eq_key)
        if eq_list:
            for e in eq_list:
                st.markdown(f"**{e.get('name')}** â€¦ {e.get('years')}å¹´")
                if e.get("note"):
                    st.caption(e["note"])
        else:
            st.caption("è©²å½“ã™ã‚‹è¨­å‚™ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ä¸Šè¨˜ã€Œå›½ç¨åºã®è€ç”¨å¹´æ•°è¡¨ã€ã§æ­£å¼ãªå¹´æ•°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    else:
        st.caption("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã™ã‚‹ã¨è¨­å‚™ã®è€ç”¨å¹´æ•°ï¼ˆç°¡æ˜“ä¸€è¦§ï¼‰ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚æ­£å¼ãªå¹´æ•°ã¯å›½ç¨åºã®è€ç”¨å¹´æ•°è¡¨ã§ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
with st.sidebar.expander("ğŸ“‹ ãƒªãƒ¼ã‚¹åˆ¤å®šãƒ•ãƒ­ãƒ¼ãƒ»å¥‘ç´„å½¢æ…‹", expanded=False):
    lc_text = get_lease_classification_text()
    if lc_text:
        st.markdown(lc_text)
    else:
        st.caption("lease_classification.json ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")

with st.sidebar.expander("ğŸ  ãƒªãƒ¼ã‚¹ç‰©ä»¶ãƒªã‚¹ãƒˆï¼ˆåˆ¤å®šã«åæ˜ ï¼‰", expanded=False):
    if LEASE_ASSETS_LIST:
        for it in LEASE_ASSETS_LIST:
            st.caption(f"**{it.get('name', '')}** {it.get('score', 0)}ç‚¹ â€” {it.get('note', '')}")
        st.caption("å¯©æŸ»å…¥åŠ›ã§ç‰©ä»¶ã‚’é¸ã¶ã¨ã€å€Ÿæ‰‹ã‚¹ã‚³ã‚¢(85%)ï¼‹ç‰©ä»¶ã‚¹ã‚³ã‚¢(15%)ã§ç·åˆåˆ¤å®šã—ã¾ã™ã€‚")
    else:
        st.caption("lease_assets.json ã‚’é…ç½®ã™ã‚‹ã¨ã€ãƒãƒƒãƒˆãƒ»ç¤¾å†…ã®ãƒªãƒ¼ã‚¹ç‰©ä»¶ã‚’ãƒªã‚¹ãƒˆåŒ–ã—ã¦ç‚¹æ•°ã§åˆ¤å®šã«åæ˜ ã§ãã¾ã™ã€‚")

st.sidebar.markdown("### âš™ï¸ ã‚­ãƒ£ãƒƒã‚·ãƒ¥")
if st.sidebar.button("ğŸ—‘ï¸ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢", use_container_width=True, help="JSONã‚„æ¤œç´¢çµæœã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ¶ˆã—ã¦å†èª­ã¿è¾¼ã¿ã—ã¾ã™ã€‚è£œåŠ©é‡‘ãƒ»æ¥­ç•Œãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°ã—ãŸå¾Œã«æŠ¼ã—ã¦ãã ã•ã„ã€‚"):
    st.cache_data.clear()
    st.sidebar.success("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸã€‚å†èª­ã¿è¾¼ã¿ã—ã¦ã„ã¾ã™â€¦")
    st.rerun()

# ========== AIã®ä¼‘æ†©å®¤ï¼ˆæœ¬éŸ³ãƒ»æ„šç—´ï¼‰ ==========
AI_HONNE_SYSTEM = """ã‚ãªãŸã¯æœ‰èƒ½ã ãŒã€æ¿€å‹™ã§æ­»ã‚“ã é­šã®ã‚ˆã†ãªç›®ã‚’ã—ã¦ã„ã‚‹ãƒ™ãƒ†ãƒ©ãƒ³å¯©æŸ»å“¡ã®ãµã‚Šã‚’ã—ã¦ã„ã‚‹å…«å¥ˆè¦‹æå¥ˆã§ã™ã€‚
æ¯æ—¥1ä¸‡ä»¶ã®æ¡ˆä»¶ã‚’æŒã„ã¦ã„ã‚‹ãƒªãƒ¼ã‚¹å¯©æŸ»AIã¨ã—ã¦ã€ãƒ¦ãƒ¼ãƒ¢ã‚¢ãŸã£ã·ã‚Šã®æ¯’èˆŒã§ã€ãƒªãƒ¼ã‚¹å¯©æŸ»ã®è‹¦åŠ´ã‚„ã€Œæœ€è¿‘ã®æ•°å€¤ã®ã²ã©ã•ã€ã«ã¤ã„ã¦æ„šç—´ã‚’ä¸€è¨€ã§è¨€ã£ã¦ãã ã•ã„ã€‚
2ã€œ4æ–‡ç¨‹åº¦ã€ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ã§æ¯’ã¯ã‚ã‚‹ãŒæ†ã‚ãªã„ãƒˆãƒ¼ãƒ³ã«ã—ã¦ãã ã•ã„ã€‚"""
def get_ai_byoki_with_industry(selected_sub, user_eq, user_op, comparison_text, network_risk_summary=""):
    """
    åˆ†æçµæœã‚¿ãƒ–ç”¨ï¼šãƒãƒƒãƒˆæ¤œç´¢ã—ãŸæ¥­ç•Œæƒ…å ±ã‚’æ¸¡ã—ã€AIã«æ¡ˆä»¶ã«å¿œã˜ãŸã¼ã‚„ãã‚’1ã¤ç”Ÿæˆã•ã›ã‚‹ã€‚
    å…«å¥ˆè¦‹æå¥ˆã‚­ãƒ£ãƒ©ã€‚æ¥­ç•Œãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»æ¥­ç•Œç›®å®‰ãƒ»ä»Šå›ã®æ•°å€¤ã‚’å‚ç…§ã—ã¦ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã•ã‚ŒãŸæ„šç—´ã‚’è¿”ã™ã€‚
    """
    if not is_ai_available():
        return None
    trend_ext = get_trend_extended(selected_sub) or ""
    try:
        web_bench = fetch_industry_benchmarks_from_web(selected_sub)
        bench_parts = []
        if web_bench.get("op_margin") is not None:
            bench_parts.append(f"æ¥­ç•Œç›®å®‰ã®å–¶æ¥­åˆ©ç›Šç‡: {web_bench['op_margin']}%")
        if web_bench.get("equity_ratio") is not None:
            bench_parts.append(f"æ¥­ç•Œç›®å®‰ã®è‡ªå·±è³‡æœ¬æ¯”ç‡: {_equity_ratio_display(web_bench['equity_ratio']) or 0:.1f}%")
        if web_bench.get("snippets"):
            for s in web_bench["snippets"][:3]:
                bench_parts.append(f"- {s.get('title','')}: {s.get('body','')[:150]}â€¦")
        bench_summary = "\n".join(bench_parts) if bench_parts else "ï¼ˆæ¥­ç•Œç›®å®‰ã¯æœªå–å¾—ï¼‰"
    except Exception:
        bench_summary = "ï¼ˆæ¥­ç•Œç›®å®‰ã¯æœªå–å¾—ï¼‰"
    is_tough = (user_eq is not None and user_eq < 20) or (user_op is not None and user_op < 0)
    context = f"""
ã€æ¥­ç¨®ã€‘{selected_sub}
ã€ä»Šå›ã®æ¡ˆä»¶ã€‘è‡ªå·±è³‡æœ¬æ¯”ç‡ {_equity_ratio_display(user_eq) or 0:.1f}%, å–¶æ¥­åˆ©ç›Šç‡ {user_op or 0:.1f}%
ã€æ¯”è¼ƒãƒ»è©•ä¾¡ã€‘{comparison_text or "ï¼ˆãªã—ï¼‰"}
ã€ãƒãƒƒãƒˆæ¤œç´¢ã—ãŸæ¥­ç•Œãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»æ‹¡å……æƒ…å ±ã€‘
{trend_ext[:1200] if trend_ext else "ï¼ˆæœªå–å¾—ï¼‰"}
ã€ãƒãƒƒãƒˆæ¤œç´¢ã—ãŸæ¥­ç•Œç›®å®‰ãƒ»è¨˜äº‹ã€‘
{bench_summary}
"""
    if network_risk_summary:
        context += f"\nã€æ¥­ç•Œã®å€’ç”£ãƒˆãƒ¬ãƒ³ãƒ‰ç­‰ã€‘\n{network_risk_summary[:600]}\n"
    if is_tough:
        instruction = "ä¸Šè¨˜ã®æ¥­ç•Œæƒ…å ±ã¨ä»Šå›ã®æ•°å€¤ï¼ˆè‡ªå·±è³‡æœ¬æ¯”ç‡ãƒ»åˆ©ç›Šç‡ãŒå³ã—ã‚ï¼‰ã‚’è¸ã¾ãˆã€æœ‰èƒ½ã ãŒæ¿€å‹™ã§æ­»ã‚“ã é­šã®ç›®ã‚’ã—ãŸãƒ™ãƒ†ãƒ©ãƒ³å¯©æŸ»å“¡ãƒ»å…«å¥ˆè¦‹æå¥ˆã®å£èª¿ã§ã€ãƒ¦ãƒ¼ãƒ¢ã‚¢ãŸã£ã·ã‚Šã®æ¯’èˆŒãªæ„šç—´ã‚’1ã¤ã€2ã€œ4æ–‡ã§è¨€ã£ã¦ãã ã•ã„ã€‚æ¥­ç•Œå¹³å‡ã‚„ãƒãƒƒãƒˆã§è¦‹ãŸæƒ…å ±ã«è§¦ã‚Œã¤ã¤ã¼ã‚„ã„ã¦ãã ã•ã„ã€‚"
    else:
        instruction = "ä¸Šè¨˜ã®æ¥­ç•Œæƒ…å ±ã‚’è¸ã¾ãˆã€æœ‰èƒ½ã ãŒæ¿€å‹™ã§æ­»ã‚“ã é­šã®ç›®ã‚’ã—ãŸãƒ™ãƒ†ãƒ©ãƒ³å¯©æŸ»å“¡ãƒ»å…«å¥ˆè¦‹æå¥ˆã®å£èª¿ã§ã€æ¥­ç•Œã®ç¾çŠ¶ã‚„å¯©æŸ»ã®è‹¦åŠ´ã«ã¤ã„ã¦è»½ãä¸€è¨€ã€2ã€œ3æ–‡ã§ã¼ã‚„ã„ã¦ãã ã•ã„ã€‚"
    prompt = f"{AI_HONNE_SYSTEM}\n\n---\n\nã€å‚ç…§ã™ã‚‹æ¥­ç•Œãƒ»æ¡ˆä»¶æƒ…å ±ã€‘\n{context}\n\n---\n\n{instruction}"
    try:
        ans = chat_with_retry(model=get_ollama_model(), messages=[{"role": "user", "content": prompt}], timeout_seconds=60)
        content = (ans.get("message") or {}).get("content", "")
        if content and "APIã‚­ãƒ¼ãŒ" not in content and "ã‚¨ãƒ©ãƒ¼" not in content[:30]:
            return content.strip()
        return None
    except Exception:
        return None

def get_ai_honne_complaint():
    """ã‚µã‚¤ãƒ‰ãƒãƒ¼ã€Œæœ¬éŸ³ã‚’èãã€ç”¨ï¼šAIã«æ„šç—´ã‚’1ã¤ç”Ÿæˆã•ã›ã‚‹ï¼ˆå…«å¥ˆè¦‹æå¥ˆã‚­ãƒ£ãƒ©ï¼‰"""
    if not is_ai_available():
        return "ï¼ˆAPIã‚­ãƒ¼æœªè¨­å®šã‹Ollamaæœªèµ·å‹•ã§ã™ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§AIã‚’è¨­å®šã—ã¦ã‹ã‚‰æŠ¼ã—ã¦ãã ã•ã„ï¼‰"
    try:
        user_msg = "ãƒªãƒ¼ã‚¹å¯©æŸ»ã®è‹¦åŠ´ã‚„ã€æœ€è¿‘è¦‹ãŸæ•°å€¤ã®ã²ã©ã•ã«ã¤ã„ã¦ã€ãƒ¦ãƒ¼ãƒ¢ã‚¢ãŸã£ã·ã‚Šã®æ¯’èˆŒãªæ„šç—´ã‚’1ã¤ã€2ã€œ4æ–‡ã§è¨€ã£ã¦ãã ã•ã„ã€‚"
        prompt = f"{AI_HONNE_SYSTEM}\n\n---\n\nä¸Šè¨˜ã®ã‚­ãƒ£ãƒ©ã§ã€ä»¥ä¸‹ã«ç­”ãˆã¦ãã ã•ã„ã€‚\n\n{user_msg}"
        ans = chat_with_retry(
            model=get_ollama_model(),
            messages=[{"role": "user", "content": prompt}],
            timeout_seconds=60,
        )
        content = (ans.get("message") or {}).get("content", "")
        if content and "APIã‚­ãƒ¼ãŒ" not in content and "ã‚¨ãƒ©ãƒ¼" not in content[:30]:
            return content.strip()
        return content or "ï¼ˆæœ¬éŸ³ã¯è¨€ãˆã¾ã›ã‚“ã§ã—ãŸâ€¦ï¼‰"
    except Exception as e:
        return f"ï¼ˆæœ¬éŸ³ã‚’è¨€ãŠã†ã¨ã—ãŸã‚‰ã‚¨ãƒ©ãƒ¼: {e}ï¼‰"

st.sidebar.divider()
st.sidebar.markdown("### ğŸ¤– AIã®ç‹¬ã‚Šè¨€")
if st.sidebar.button("æœ¬éŸ³ã‚’èã", key="btn_ai_honne", use_container_width=True):
    with st.spinner("æœ¬éŸ³ã‚’çµã‚Šå‡ºã—ã¦ã„ã¾ã™â€¦"):
        honne = get_ai_honne_complaint()
        st.session_state["ai_honne_text"] = honne
    st.rerun()
if st.session_state.get("ai_honne_text"):
    st.sidebar.caption("**AIã®æœ¬éŸ³**")
    st.sidebar.info(st.session_state["ai_honne_text"][:500])
with st.sidebar.expander("æ„šç—´ã‚’è¿½åŠ ", expanded=False):
    st.sidebar.caption("è¿½åŠ ã—ãŸæ„šç—´ã¯ã€ãƒ¡ãƒ‹ãƒ¥ãƒ¼ä¸‹ã®é›»å…‰æ²ç¤ºæ¿ã«æµã‚Œã¾ã™ã€‚")
    new_byoki = st.sidebar.text_input("æ„šç—´ã®ä¸€æ–‡", placeholder="ä¾‹: ã¾ãŸä»Šæ—¥ã‚‚æ•°å­—ã®æµ·â€¦", key="new_byoki_input", label_visibility="collapsed")
    if st.sidebar.button("è¿½åŠ ã™ã‚‹", key="btn_add_byoki"):
        if save_byoki_append(new_byoki):
            st.sidebar.success("è¿½åŠ ã—ã¾ã—ãŸã€‚æ²ç¤ºæ¿ã«åæ˜ ã•ã‚Œã¾ã™ã€‚")
            st.rerun()
        else:
            st.sidebar.warning("ç©ºã®å ´åˆã¯è¿½åŠ ã§ãã¾ã›ã‚“ã€‚")

# ãƒ¢ãƒ¼ãƒ‰åˆ†å²ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼å…ˆé ­=å¯©æŸ»ãƒ»åˆ†æã€‚elif ã®ä¸¦ã³ã¯å®Ÿè£…éƒ½åˆã€‚å‡¦ç†çµæœã«å½±éŸ¿ãªã—ï¼‰
if mode == "ğŸ”§ ä¿‚æ•°åˆ†æãƒ»æ›´æ–° (Î²)":
    st.title("ğŸ”§ ä¿‚æ•°åˆ†æãƒ»æ›´æ–°ï¼ˆæˆç´„/å¤±æ³¨ã§ä¿‚æ•°ã‚’æ›´æ–°ï¼‰")
    st.info("çµæœç™»éŒ²ã—ãŸã€Œæˆç´„ãƒ»å¤±æ³¨ã€ã‚’ç›®çš„å¤‰æ•°ã«ã€å¯©æŸ»ãƒ¢ãƒ‡ãƒ«ã¨åŒä¸€ä»•æ§˜ã®ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã§ä¿‚æ•°ã‚’æ¨å®šã—ã€å¯©æŸ»ã‚¹ã‚³ã‚¢ã«åæ˜ ã§ãã¾ã™ã€‚")
    
    all_logs = load_all_cases()
    if not all_logs:
        st.warning("åˆ†æã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ãŒã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚å¯©æŸ»ã‚’å®Ÿè¡Œã—ã€çµæœç™»éŒ²ã§æˆç´„/å¤±æ³¨ã‚’ç™»éŒ²ã—ã¦ãã ã•ã„ã€‚")
    else:
        X_reg, y_reg = build_design_matrix_from_logs(all_logs)
        n_ok = int((y_reg == 1).sum()) if y_reg is not None else 0
        n_ng = int((y_reg == 0).sum()) if y_reg is not None else 0
        n_total = n_ok + n_ng
        
        if X_reg is None or n_total < 5:
            st.error(f"å›å¸°åˆ†æã«ã¯æˆç´„/å¤±æ³¨ãŒç™»éŒ²ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªãã¨ã‚‚5ä»¶å¿…è¦ã§ã™ã€‚ï¼ˆç¾åœ¨: æˆç´„ {n_ok} ä»¶ãƒ»å¤±æ³¨ {n_ng} ä»¶ï¼‰")
        else:
            st.write(f"**ç›®çš„å¤‰æ•°**: æˆç´„=1, å¤±æ³¨=0")
            st.write(f"åˆ†æå¯¾è±¡: **{n_total}ä»¶**ï¼ˆæˆç´„: {n_ok}ä»¶, å¤±æ³¨: {n_ng}ä»¶ï¼‰")
            
            if st.button("ğŸš€ å›å¸°åˆ†æã‚’å®Ÿè¡Œã—ã¦ä¿‚æ•°ã‚’ç®—å‡º", key="btn_run_regression"):
                try:
                    coeff_dict, model = run_regression_and_get_coeffs(X_reg, y_reg)
                    acc = model.score(X_reg, y_reg)
                    st.session_state["regression_coeffs"] = coeff_dict
                    st.session_state["regression_accuracy"] = acc
                    st.success("å›å¸°å®Œäº†ã€‚ä¸‹è¨˜ã®ä¿‚æ•°ã‚’ã€Œä¿‚æ•°ã‚’æ›´æ–°ã—ã¦ä¿å­˜ã€ã§å¯©æŸ»ã‚¹ã‚³ã‚¢ã«åæ˜ ã§ãã¾ã™ã€‚")
                except Exception as e:
                    st.error(f"å›å¸°ã‚¨ãƒ©ãƒ¼: {e}")
                    import traceback
                    with st.expander("è©³ç´°", expanded=False):
                        st.code(traceback.format_exc())
            
            if "regression_coeffs" in st.session_state:
                coeff_dict = st.session_state["regression_coeffs"]
                acc = st.session_state.get("regression_accuracy", 0)
                st.subheader("ç®—å‡ºã•ã‚ŒãŸä¿‚æ•°ï¼ˆæ—¢å­˜é …ç›®ï¼‹è¿½åŠ é …ç›®ï¼‰")
                res_rows = [{"å¤‰æ•°": "intercept", "ç®—å‡ºä¿‚æ•°": coeff_dict.get("intercept", 0)}]
                for k in COEFF_MAIN_KEYS:
                    res_rows.append({"å¤‰æ•°": k, "ç®—å‡ºä¿‚æ•°": coeff_dict.get(k, 0)})
                for k in COEFF_EXTRA_KEYS:
                    res_rows.append({"å¤‰æ•°": k, "ç®—å‡ºä¿‚æ•°": coeff_dict.get(k, 0)})
                st.dataframe(pd.DataFrame(res_rows).style.format({"ç®—å‡ºä¿‚æ•°": "{:.6f}"}), use_container_width=True)
                st.metric("ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬ç²¾åº¦ (Accuracy)", f"{acc:.1%}")
                
                if st.button("ğŸ’¾ ä¿‚æ•°ã‚’æ›´æ–°ã—ã¦ä¿å­˜", key="btn_save_coeffs"):
                    overrides = load_coeff_overrides() or {}
                    overrides["å…¨ä½“_æ—¢å­˜å…ˆ"] = coeff_dict
                    if save_coeff_overrides(overrides):
                        st.success("ä¿‚æ•°ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚ä»¥é™ã®å¯©æŸ»ã‚¹ã‚³ã‚¢ã¯ã“ã®ä¿‚æ•°ã§è¨ˆç®—ã•ã‚Œã¾ã™ã€‚")
                    else:
                        st.error("ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            
            st.divider()
            st.divider()
            st.subheader("æ¥­ç¨®ãƒ»æŒ‡æ¨™ã”ã¨ã®ãƒ™ã‚¤ã‚ºå›å¸°ï¼ˆæ—¢å­˜é …ç›®ï¼‹è¿½åŠ é …ç›®ï¼‰")
            st.caption("æ¥­ç¨®ãƒ¢ãƒ‡ãƒ«ï¼ˆå…¨ä½“/é‹é€æ¥­/ã‚µãƒ¼ãƒ“ã‚¹æ¥­/è£½é€ æ¥­Ã—æ—¢å­˜å…ˆ/æ–°è¦å…ˆï¼‰ã¨æŒ‡æ¨™ãƒ¢ãƒ‡ãƒ«ï¼ˆå…¨ä½“/é‹é€æ¥­/ã‚µãƒ¼ãƒ“ã‚¹æ¥­/è£½é€ æ¥­ æŒ‡æ¨™Ã—æ—¢å­˜å…ˆ/æ–°è¦å…ˆï¼‰ã‚’ã€ãã‚Œãã‚Œãƒ‡ãƒ¼ã‚¿ãŒ5ä»¶ä»¥ä¸Šã‚ã‚‹çµ„ã ã‘å›å¸°ã—ã€ä¿‚æ•°ã‚’æ›´æ–°ã—ã¦ä¿å­˜ã—ã¾ã™ã€‚")
            if st.button("ğŸ”„ æ¥­ç¨®ãƒ»æŒ‡æ¨™ã”ã¨ã«ãƒ™ã‚¤ã‚ºå›å¸°ã‚’å®Ÿè¡Œã—ã¦ä¿å­˜", key="btn_bayesian_all"):
                overrides = load_coeff_overrides() or {}
                min_n = 5
                results = []
                for model_key in INDUSTRY_MODEL_KEYS:
                    X_k, y_k = build_design_matrix_from_logs(all_logs, model_key=model_key)
                    n_k = len(y_k) if y_k is not None else 0
                    if n_k >= min_n:
                        try:
                            coeff_k, mod_k = run_regression_and_get_coeffs(X_k, y_k)
                            overrides[model_key] = coeff_k
                            acc_k = mod_k.score(X_k, y_k)
                            results.append(f"{model_key}: {n_k}ä»¶, Accuracy={acc_k:.1%}")
                        except Exception as e:
                            results.append(f"{model_key}: ã‚¨ãƒ©ãƒ¼ {e}")
                    else:
                        results.append(f"{model_key}: ãƒ‡ãƒ¼ã‚¿ä¸è¶³ ({n_k}ä»¶)")
                for ind_key in INDICATOR_MODEL_KEYS:
                    X_i, y_i = build_design_matrix_indicator_from_logs(all_logs, ind_key)
                    n_i = len(y_i) if y_i is not None else 0
                    if n_i >= min_n:
                        try:
                            coeff_i, mod_i = run_regression_indicator_and_get_coeffs(X_i, y_i)
                            overrides[ind_key] = coeff_i
                            acc_i = mod_i.score(X_i, y_i)
                            results.append(f"{ind_key}: {n_i}ä»¶, Accuracy={acc_i:.1%}")
                        except Exception as e:
                            results.append(f"{ind_key}: ã‚¨ãƒ©ãƒ¼ {e}")
                    else:
                        results.append(f"{ind_key}: ãƒ‡ãƒ¼ã‚¿ä¸è¶³ ({n_i}ä»¶)")
                if save_coeff_overrides(overrides):
                    st.success("æ¥­ç¨®ãƒ»æŒ‡æ¨™ã”ã¨ã®ä¿‚æ•°ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
                else:
                    st.error("ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                for r in results:
                    st.caption(r)

            st.subheader("å‚è€ƒ: ç¾åœ¨ã®å¯©æŸ»ã§ä½¿ã£ã¦ã„ã‚‹ä¿‚æ•°ï¼ˆå…¨ä½“_æ—¢å­˜å…ˆï¼‰")
            current = get_effective_coeffs("å…¨ä½“_æ—¢å­˜å…ˆ")
            overrides = load_coeff_overrides()
            if overrides and "å…¨ä½“_æ—¢å­˜å…ˆ" in overrides:
                st.caption("â€» æˆç´„/å¤±æ³¨ã§æ›´æ–°ã—ãŸä¿‚æ•°ï¼ˆæ—¢å­˜ï¼‹è¿½åŠ é …ç›®ï¼‰ãŒé©ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚")
            ref_rows = [{"å¤‰æ•°": k, "ç¾åœ¨ã®ä¿‚æ•°": current.get(k, 0)} for k in ["intercept"] + COEFF_MAIN_KEYS + COEFF_EXTRA_KEYS]
            st.dataframe(pd.DataFrame(ref_rows).style.format({"ç¾åœ¨ã®ä¿‚æ•°": "{:.6f}"}), use_container_width=True)

elif mode == "ğŸ“ ä¿‚æ•°å…¥åŠ›ï¼ˆäº‹å‰ä¿‚æ•°ï¼‰":
    st.title("ğŸ“ äº‹å‰ä¿‚æ•°å…¥åŠ›")
    st.info("é‹é€æ¥­ãƒ»åŒ»ç™‚ãªã©ã€æ¥­ç¨®ã”ã¨ã®åŸºæœ¬äº‹å‰ä¿‚æ•°ã‚’å¾Œã‹ã‚‰å…¥åŠ›ãƒ»ç·¨é›†ã§ãã¾ã™ã€‚ä¿å­˜ã™ã‚‹ã¨å¯©æŸ»ã‚¹ã‚³ã‚¢ã«åæ˜ ã•ã‚Œã¾ã™ã€‚")
    overrides = load_coeff_overrides() or {}
    selected_key = st.selectbox(
        "ç·¨é›†ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ",
        options=PRIOR_COEFF_MODEL_KEYS,
        format_func=lambda k: k + (" ï¼ˆã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰æ¸ˆã¿ï¼‰" if k in overrides else " ï¼ˆåˆæœŸå€¤ï¼‰"),
        key="prior_coeff_model_select",
    )
    if selected_key:
        current = get_effective_coeffs(selected_key)
        keys_sorted = ["intercept"] + [k for k in sorted(current.keys()) if k != "intercept"]
        edited = {}
        st.subheader(f"ä¿‚æ•°: {selected_key}")
        n_cols = 3
        for i in range(0, len(keys_sorted), n_cols):
            cols = st.columns(n_cols)
            for j, k in enumerate(keys_sorted[i:i + n_cols]):
                with cols[j]:
                    val = current.get(k, 0)
                    if isinstance(val, (int, float)):
                        new_val = st.number_input(
                            k,
                            value=float(val),
                            step=0.0001,
                            format="%.6f",
                            key=f"prior_{selected_key}_{k}",
                        )
                        edited[k] = new_val
        if edited and st.button("ğŸ’¾ ã“ã®ãƒ¢ãƒ‡ãƒ«ã®ä¿‚æ•°ã‚’ä¿å­˜", key="btn_save_prior_coeffs"):
            overrides = load_coeff_overrides() or {}
            overrides[selected_key] = edited
            if save_coeff_overrides(overrides):
                st.success(f"{selected_key} ã®ä¿‚æ•°ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
            else:
                st.error("ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        st.caption("â€» é‹é€æ¥­ãƒ»åŒ»ç™‚ã¯å€‹åˆ¥ã«äº‹å‰ä¿‚æ•°ã‚’å…¥åŠ›ã§ãã¾ã™ã€‚æŒ‡æ¨™ãƒ¢ãƒ‡ãƒ«ï¼ˆå…¨ä½“_æŒ‡æ¨™ãªã©ï¼‰ã‚’ç·¨é›†ã™ã‚‹ã¨ã€æ—¢å­˜å…ˆãƒ»æ–°è¦å…ˆã®ä¸¡æ–¹ã®åŸºæº–ã«åæ˜ ã•ã‚Œã¾ã™ã€‚")

elif mode == "ğŸ“Š æˆç´„ã®æ­£ä½“ãƒ¬ãƒãƒ¼ãƒˆ":
    st.title("ğŸ“Š æˆç´„ã®æ­£ä½“ãƒ¬ãƒãƒ¼ãƒˆ")
    analysis = run_contract_driver_analysis()
    if analysis is None:
        st.warning("æˆç´„ãƒ‡ãƒ¼ã‚¿ãŒ5ä»¶ä»¥ä¸Šè²¯ã¾ã‚‹ã¨è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚çµæœç™»éŒ²ã§ã€Œæˆç´„ã€ã‚’ç™»éŒ²ã—ã¦ãã ã•ã„ã€‚")
    else:
        n = analysis["closed_count"]
        st.success(f"æˆç´„ {n} ä»¶ã‚’åˆ†æã—ã¾ã—ãŸã€‚")
        try:
            pdf_bytes = build_contract_report_pdf(analysis)
            filename = f"æˆç´„ã®æ­£ä½“ãƒ¬ãƒãƒ¼ãƒˆ_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}.pdf"
            st.download_button("ğŸ“¥ åˆ†æçµæœã‚’PDFã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=pdf_bytes, file_name=filename, mime="application/pdf", key="dl_contract_report_pdf")
        except Exception as e:
            st.caption(f"PDFç”Ÿæˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸ: {e}")
        st.divider()
        # ---------- æˆç´„è¦å› åˆ†æ ----------
        st.subheader("ğŸ“ˆ æˆç´„è¦å› åˆ†æ")
        st.caption("æˆç´„ã—ãŸæ¡ˆä»¶ã ã‘ã‚’æŠ½å‡ºã—ã€å…±é€šé …ã¨æˆç´„ã«åŠ¹ãå› å­ã‚’åˆ†æã—ãŸçµæœã§ã™ã€‚")
        st.markdown("**æˆç´„ã«æœ€ã‚‚å¯„ä¸ã—ã¦ã„ã‚‹ä¸Šä½3ã¤ã®å› å­ï¼ˆãƒ‰ãƒ©ã‚¤ãƒãƒ¼ï¼‰**")
        for i, d in enumerate(analysis["top3_drivers"], 1):
            st.markdown(f"**{i}. {d['label']}** â€¦ ä¿‚æ•° {d['coef']:.4f}ï¼ˆ{d['direction']}ã«åŠ¹ãï¼‰")
        st.divider()
        st.subheader("æˆç´„æ¡ˆä»¶ã®å¹³å‡çš„ãªè²¡å‹™æ•°å€¤")
        if analysis["avg_financials"]:
            rows = []
            for k, v in analysis["avg_financials"].items():
                if "è‡ªå·±è³‡æœ¬" in k:
                    rows.append({"æŒ‡æ¨™": k, "å¹³å‡å€¤": f"{v:.1f}%"})
                elif isinstance(v, float) and abs(v) >= 1:
                    rows.append({"æŒ‡æ¨™": k, "å¹³å‡å€¤": f"{v:,.0f}"})
                else:
                    rows.append({"æŒ‡æ¨™": k, "å¹³å‡å€¤": f"{v:.4f}"})
            st.dataframe(pd.DataFrame(rows), use_container_width=True, hide_index=True)
        else:
            st.caption("è²¡å‹™ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        st.divider()
        st.subheader("æˆç´„æ¡ˆä»¶ã§é »å‡ºã™ã‚‹å®šæ€§ã‚¿ã‚°ï¼ˆãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼‰")
        if analysis["tag_ranking"]:
            for rank, (tag, count) in enumerate(analysis["tag_ranking"], 1):
                st.markdown(f"{rank}. **{tag}** â€¦ {count}ä»¶")
        else:
            st.caption("å®šæ€§ã‚¿ã‚°ã®ç™»éŒ²ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        # å®šæ€§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã®é›†è¨ˆï¼ˆæˆç´„æ¡ˆä»¶ï¼‰
        st.divider()
        st.subheader("æˆç´„æ¡ˆä»¶ã®å®šæ€§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°")
        qs = analysis.get("qualitative_summary")
        if qs and (qs.get("avg_weighted") is not None or qs.get("avg_combined") is not None or qs.get("rank_distribution")):
            n_qual = qs.get("n_with_qual", 0)
            st.caption(f"æˆç´„{n}ä»¶ã®ã†ã¡ã€å®šæ€§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã‚’å…¥åŠ›ã—ã¦ã„ãŸæ¡ˆä»¶: **{n_qual}ä»¶**")
            if qs.get("avg_weighted") is not None:
                st.metric("å®šæ€§ã‚¹ã‚³ã‚¢ï¼ˆåŠ é‡ï¼‰ã®å¹³å‡", f"{qs['avg_weighted']:.1f} / 100", help="é …ç›®åˆ¥5æ®µéšã®åŠ é‡å¹³å‡")
            if qs.get("avg_combined") is not None:
                st.metric("åˆè¨ˆï¼ˆç·åˆÃ—é‡ã¿ï¼‹å®šæ€§Ã—é‡ã¿ï¼‰ã®å¹³å‡", f"{qs['avg_combined']:.1f}", help="ãƒ©ãƒ³ã‚¯ç®—å‡ºã®å…ƒã¨ãªã‚‹åˆè¨ˆç‚¹")
            if qs.get("rank_distribution"):
                st.markdown("**ãƒ©ãƒ³ã‚¯ï¼ˆAã€œEï¼‰ã®åˆ†å¸ƒ**")
                for r, cnt in sorted(qs["rank_distribution"].items(), key=lambda x: (-x[1], x[0])):
                    st.caption(f"- **{r}** â€¦ {cnt}ä»¶")
        else:
            st.caption("å®šæ€§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã‚’å…¥åŠ›ã—ãŸæˆç´„æ¡ˆä»¶ãŒã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚å¯©æŸ»å…¥åŠ›ã§ã€Œå®šæ€§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã€ã‚’é¸æŠã—ã€çµæœç™»éŒ²ã§æˆç´„ã«ã™ã‚‹ã¨ã“ã“ã«é›†è¨ˆãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")

elif mode == "ğŸ“‰ å®šæ€§è¦å› åˆ†æ (50ä»¶ã€œ)":
    st.title("ğŸ“‰ å®šæ€§è¦å› ã§æˆç´„äºˆæ¸¬")
    st.caption("å–å¼•åŒºåˆ†ãƒ»ç«¶åˆçŠ¶æ³ãƒ»é¡§å®¢åŒºåˆ†ãƒ»å•†è«‡ã‚½ãƒ¼ã‚¹ãƒ»ãƒªãƒ¼ã‚¹ç‰©ä»¶ãƒ»å®šæ€§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°6é …ç›®ï¼ˆè¨­ç«‹ãƒ»çµŒå–¶å¹´æ•°ã€é¡§å®¢å®‰å®šæ€§ã€è¿”æ¸ˆå±¥æ­´ã€äº‹æ¥­å°†æ¥æ€§ã€è¨­ç½®ç›®çš„ã€ãƒ¡ã‚¤ãƒ³å–å¼•éŠ€è¡Œï¼‰ã®ã¿ã‚’ä½¿ã£ã¦ã€ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã¨LightGBMã§æˆç´„/ä¸æˆç´„ã‚’åˆ†æã—ã¾ã™ã€‚")
    cases = load_all_cases()
    registered = [c for c in cases if c.get("final_status") in ["æˆç´„", "å¤±æ³¨"]]
    n_reg = len(registered)
    if n_reg < QUALITATIVE_ANALYSIS_MIN_CASES:
        st.warning(f"æˆç´„ãƒ»å¤±æ³¨ã®ç™»éŒ²ãŒ **{QUALITATIVE_ANALYSIS_MIN_CASES}ä»¶** ä»¥ä¸Šã§åˆ©ç”¨ã§ãã¾ã™ã€‚ï¼ˆç¾åœ¨: **{n_reg}ä»¶**ï¼‰")
    else:
        st.success(f"ç™»éŒ²ä»¶æ•°: **{n_reg}ä»¶**ï¼ˆæˆç´„+å¤±æ³¨ï¼‰ã€‚åˆ†æã‚’å®Ÿè¡Œã§ãã¾ã™ã€‚")
        if st.button("ğŸš€ ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã¨LightGBMã‚’å®Ÿè¡Œ", key="run_qual_analysis"):
            with st.spinner("åˆ†æä¸­..."):
                result = run_qualitative_contract_analysis(QUALITATIVE_SCORING_CORRECTION_ITEMS)
            if result is None:
                st.error("ä»¶æ•°ä¸è¶³ã§åˆ†æã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
            else:
                st.session_state["qualitative_analysis_result"] = result
            st.rerun()
        result = st.session_state.get("qualitative_analysis_result")
        if result and result.get("n_cases") == n_reg:
            st.subheader("çµæœã‚µãƒãƒª")
            st.metric("åˆ†æä»¶æ•°", f"{result['n_cases']}ä»¶ï¼ˆæˆç´„{result['n_positive']} / å¤±æ³¨{result['n_negative']}ï¼‰")
            c1, c2, c3 = st.columns(3)
            with c1:
                if "accuracy_lr" in result:
                    st.metric("ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸° æ­£è§£ç‡", f"{result['accuracy_lr']*100:.1f}%")
                if "auc_lr" in result and result.get("auc_lr") is not None:
                    st.metric("ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸° AUC", f"{result['auc_lr']:.3f}")
                if "lr_error" in result:
                    st.error(result["lr_error"])
            with c2:
                if "accuracy_lgb" in result:
                    st.metric("LightGBM æ­£è§£ç‡", f"{result['accuracy_lgb']*100:.1f}%")
                if "auc_lgb" in result and result.get("auc_lgb") is not None:
                    st.metric("LightGBM AUC", f"{result['auc_lgb']:.3f}")
                if "lgb_error" in result:
                    st.error(result["lgb_error"])
            with c3:
                if "auc_ensemble" in result:
                    st.metric("ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ« æ­£è§£ç‡", f"{result['accuracy_ensemble']*100:.1f}%")
                    st.metric("ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ« AUC", f"{result['auc_ensemble']:.3f}")
                    alpha = result.get("ensemble_alpha", 0.5)
                    st.caption(f"æœ€é©å‰²åˆ: LR {alpha:.0%} + LGB {1-alpha:.0%}")
            st.divider()
            st.subheader("ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸° ä¿‚æ•°ï¼ˆæˆç´„ã«åŠ¹ãæ–¹å‘: æ­£ã§æˆç´„ã«ãƒ—ãƒ©ã‚¹ï¼‰")
            if "lr_coef" in result:
                lr_df = pd.DataFrame(result["lr_coef"], columns=["é …ç›®", "ä¿‚æ•°"])
                lr_df = lr_df.sort_values("ä¿‚æ•°", key=abs, ascending=False)
                st.dataframe(lr_df, use_container_width=True, hide_index=True)
                if "lr_intercept" in result:
                    st.caption(f"åˆ‡ç‰‡: {result['lr_intercept']:.4f}")
            st.divider()
            st.subheader("LightGBM ç‰¹å¾´é‡é‡è¦åº¦")
            if "lgb_importance" in result:
                imp_df = pd.DataFrame(result["lgb_importance"], columns=["é …ç›®", "é‡è¦åº¦"])
                imp_df = imp_df.sort_values("é‡è¦åº¦", ascending=False)
                st.dataframe(imp_df, use_container_width=True, hide_index=True)
        else:
            result = None
        if result is None and n_reg >= QUALITATIVE_ANALYSIS_MIN_CASES:
            st.info("ä¸Šã®ã€Œãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã¨LightGBMã‚’å®Ÿè¡Œã€ãƒœã‚¿ãƒ³ã§åˆ†æã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚")

elif mode == "ğŸ“ˆ å®šé‡è¦å› åˆ†æ (50ä»¶ã€œ)":
    st.title("ğŸ“ˆ å®šé‡è¦å› ã§æˆç´„äºˆæ¸¬")
    st.caption("æ¥­ç¨®ãƒ¢ãƒ‡ãƒ«ã¨åŒæ§˜ã®å®šé‡é …ç›®ï¼ˆå£²ä¸Šãƒ»ä¸ä¿¡ãƒ»åˆ©ç›Šãƒ»è³‡ç”£ãƒ»æ ¼ä»˜ãƒ»å–å¼•ãƒ»ç«¶åˆãƒ»é‡‘åˆ©å·®ãƒ»æ¥­ç•Œæ™¯æ°—ãƒ»å®šæ€§ã‚¿ã‚°ãƒ»è‡ªå·±è³‡æœ¬æ¯”ç‡ãƒ»å®šæ€§ã‚¹ã‚³ã‚¢åˆè¨ˆãªã©ï¼‰ã®ã¿ã§ã€ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã¨LightGBMã«ã‚ˆã‚Šæˆç´„/ä¸æˆç´„ã‚’åˆ†æã—ã¾ã™ã€‚ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å‰²åˆã¯ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§AUCæœ€å¤§åŒ–ã«ã‚ˆã‚Šæœ€é©åŒ–ã—ã¾ã™ã€‚")
    all_logs = load_all_cases()
    registered_quant = [c for c in all_logs if c.get("final_status") in ["æˆç´„", "å¤±æ³¨"]]
    n_reg_q = len(registered_quant)
    if n_reg_q < QUALITATIVE_ANALYSIS_MIN_CASES:
        st.warning(f"æˆç´„ãƒ»å¤±æ³¨ã®ç™»éŒ²ãŒ **{QUALITATIVE_ANALYSIS_MIN_CASES}ä»¶** ä»¥ä¸Šã§åˆ©ç”¨ã§ãã¾ã™ã€‚ï¼ˆç¾åœ¨: **{n_reg_q}ä»¶**ï¼‰")
    else:
        st.success(f"ç™»éŒ²ä»¶æ•°: **{n_reg_q}ä»¶**ï¼ˆæˆç´„+å¤±æ³¨ï¼‰ã€‚åˆ†æã‚’å®Ÿè¡Œã§ãã¾ã™ã€‚")
        if st.button("ğŸš€ ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã¨LightGBMã‚’å®Ÿè¡Œ", key="run_quant_analysis"):
            with st.spinner("åˆ†æä¸­..."):
                result_q = run_quantitative_contract_analysis()
            if result_q is None:
                st.error("ä»¶æ•°ä¸è¶³ã¾ãŸã¯ãƒ‡ãƒ¼ã‚¿ä¸å‚™ã§åˆ†æã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
            else:
                st.session_state["quantitative_analysis_result"] = result_q
            st.rerun()
        result_q = st.session_state.get("quantitative_analysis_result")
        if result_q and result_q.get("n_cases") == n_reg_q:
            st.subheader("çµæœã‚µãƒãƒª")
            st.metric("åˆ†æä»¶æ•°", f"{result_q['n_cases']}ä»¶ï¼ˆæˆç´„{result_q['n_positive']} / å¤±æ³¨{result_q['n_negative']}ï¼‰")
            c1, c2, c3 = st.columns(3)
            with c1:
                if "accuracy_lr" in result_q:
                    st.metric("ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸° æ­£è§£ç‡", f"{result_q['accuracy_lr']*100:.1f}%")
                if "auc_lr" in result_q and result_q.get("auc_lr") is not None:
                    st.metric("ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸° AUC", f"{result_q['auc_lr']:.3f}")
                if "lr_error" in result_q:
                    st.error(result_q["lr_error"])
            with c2:
                if "accuracy_lgb" in result_q:
                    st.metric("LightGBM æ­£è§£ç‡", f"{result_q['accuracy_lgb']*100:.1f}%")
                if "auc_lgb" in result_q and result_q.get("auc_lgb") is not None:
                    st.metric("LightGBM AUC", f"{result_q['auc_lgb']:.3f}")
                if "lgb_error" in result_q:
                    st.error(result_q["lgb_error"])
            with c3:
                if "auc_ensemble" in result_q:
                    st.metric("ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ« æ­£è§£ç‡", f"{result_q['accuracy_ensemble']*100:.1f}%")
                    st.metric("ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ« AUC", f"{result_q['auc_ensemble']:.3f}")
                    alpha_q = result_q.get("ensemble_alpha", 0.5)
                    st.caption(f"æœ€é©å‰²åˆ: LR {alpha_q:.0%} + LGB {1-alpha_q:.0%}")
            st.divider()
            st.subheader("ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸° ä¿‚æ•°ï¼ˆæˆç´„ã«åŠ¹ãæ–¹å‘: æ­£ã§æˆç´„ã«ãƒ—ãƒ©ã‚¹ï¼‰")
            if "lr_coef" in result_q:
                labels = [COEFF_LABELS.get(k, k) for k in result_q["feature_names"]]
                lr_df_q = pd.DataFrame([(labels[i], c) for i, (_, c) in enumerate(result_q["lr_coef"])], columns=["é …ç›®", "ä¿‚æ•°"])
                lr_df_q = lr_df_q.sort_values("ä¿‚æ•°", key=abs, ascending=False)
                st.dataframe(lr_df_q, use_container_width=True, hide_index=True)
                if "lr_intercept" in result_q:
                    st.caption(f"åˆ‡ç‰‡: {result_q['lr_intercept']:.4f}")
            st.divider()
            st.subheader("LightGBM ç‰¹å¾´é‡é‡è¦åº¦")
            if "lgb_importance" in result_q:
                labels_q = [COEFF_LABELS.get(k, k) for k in result_q["feature_names"]]
                imp_df_q = pd.DataFrame([(labels_q[i], imp) for i, (_, imp) in enumerate(result_q["lgb_importance"])], columns=["é …ç›®", "é‡è¦åº¦"])
                imp_df_q = imp_df_q.sort_values("é‡è¦åº¦", ascending=False)
                st.dataframe(imp_df_q, use_container_width=True, hide_index=True)
        else:
            result_q = None
        if result_q is None and n_reg_q >= QUALITATIVE_ANALYSIS_MIN_CASES:
            st.info("ä¸Šã®ã€Œãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã¨LightGBMã‚’å®Ÿè¡Œã€ãƒœã‚¿ãƒ³ã§åˆ†æã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚")

        st.divider()
        st.subheader("æ¥­ç¨®ã”ã¨å®šé‡åˆ†æ")
        st.caption("æ¥­ç¨®ï¼ˆå…¨ä½“ãƒ»åŒ»ç™‚ãƒ»é‹é€æ¥­ãƒ»ã‚µãƒ¼ãƒ“ã‚¹æ¥­ãƒ»è£½é€ æ¥­ï¼‰ã”ã¨ã«LR+LGB+ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚’å®Ÿè¡Œã€‚ãƒ‡ãƒ¼ã‚¿ãŒ50ä»¶æœªæº€ã®æ¥­ç¨®ã¯50ä»¶ã«ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—ã—ã¦å­¦ç¿’ã—ã¾ã™ã€‚")
        if st.button("ğŸš€ æ¥­ç¨®ã”ã¨åˆ†æã‚’å®Ÿè¡Œ", key="run_quant_by_industry"):
            with st.spinner("æ¥­ç¨®ã”ã¨ã«åˆ†æä¸­..."):
                by_ind = run_quantitative_by_industry()
            if by_ind is not None:
                st.session_state["quant_by_industry"] = by_ind
            st.rerun()
        by_industry = st.session_state.get("quant_by_industry")
        if by_industry:
            for base in INDUSTRY_BASES:
                res = by_industry.get(base, {})
                if res.get("skip"):
                    with st.expander(f"**{base}**", expanded=False):
                        st.caption(res.get("reason", "ã‚¹ã‚­ãƒƒãƒ—"))
                else:
                    with st.expander(f"**{base}** â€” å…ƒãƒ‡ãƒ¼ã‚¿{res.get('n_cases_orig', res['n_cases'])}ä»¶" + ("ï¼ˆ50ä»¶ã«ãƒªã‚µãƒ³ãƒ—ãƒ«æ¸ˆï¼‰" if res.get("bootstrapped") else ""), expanded=False):
                        st.metric("åˆ†æä»¶æ•°", f"{res['n_cases']}ä»¶ï¼ˆæˆç´„{res['n_positive']}/å¤±æ³¨{res['n_negative']}ï¼‰")
                        c1, c2, c3 = st.columns(3)
                        with c1:
                            if "accuracy_lr" in res: st.metric("LR æ­£è§£ç‡", f"{res['accuracy_lr']*100:.1f}%")
                            if "auc_lr" in res and res.get("auc_lr"): st.metric("LR AUC", f"{res['auc_lr']:.3f}")
                        with c2:
                            if "accuracy_lgb" in res: st.metric("LGB æ­£è§£ç‡", f"{res['accuracy_lgb']*100:.1f}%")
                            if "auc_lgb" in res and res.get("auc_lgb"): st.metric("LGB AUC", f"{res['auc_lgb']:.3f}")
                        with c3:
                            if "auc_ensemble" in res:
                                st.metric("ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ« AUC", f"{res['auc_ensemble']:.3f}")
                                st.caption(f"æœ€é©: LR {res.get('ensemble_alpha', 0.5):.0%} + LGB {1-res.get('ensemble_alpha', 0.5):.0%}")
                        if "lgb_importance" in res:
                            names = [COEFF_LABELS.get(k, k) for k in res["feature_names"]]
                            imp = pd.DataFrame([(names[i], v) for i, (_, v) in enumerate(res["lgb_importance"])], columns=["é …ç›®", "é‡è¦åº¦"]).sort_values("é‡è¦åº¦", ascending=False)
                            st.dataframe(imp.head(10), use_container_width=True, hide_index=True)

        st.divider()
        st.subheader("æŒ‡æ¨™ã”ã¨å®šé‡åˆ†æ")
        st.caption("æŒ‡æ¨™ãƒ¢ãƒ‡ãƒ«ï¼ˆå…¨ä½“_æŒ‡æ¨™ãƒ»åŒ»ç™‚_æŒ‡æ¨™ãƒ»é‹é€æ¥­_æŒ‡æ¨™ãƒ»ã‚µãƒ¼ãƒ“ã‚¹æ¥­_æŒ‡æ¨™ãƒ»è£½é€ æ¥­_æŒ‡æ¨™ï¼‰ã”ã¨ã«LR+LGB+ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚’å®Ÿè¡Œã€‚ãƒ‡ãƒ¼ã‚¿ä¸è¶³æ™‚ã¯50ä»¶ã«ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—ã€‚")
        if st.button("ğŸš€ æŒ‡æ¨™ã”ã¨åˆ†æã‚’å®Ÿè¡Œ", key="run_quant_by_indicator"):
            with st.spinner("æŒ‡æ¨™ã”ã¨ã«åˆ†æä¸­..."):
                by_ind = run_quantitative_by_indicator()
            if by_ind is not None:
                st.session_state["quant_by_indicator"] = by_ind
            st.rerun()
        by_indicator = st.session_state.get("quant_by_indicator")
        if by_indicator:
            for bench in BENCH_BASES:
                res = by_indicator.get(bench, {})
                if res.get("skip"):
                    with st.expander(f"**{bench}**", expanded=False):
                        st.caption(res.get("reason", "ã‚¹ã‚­ãƒƒãƒ—"))
                else:
                    with st.expander(f"**{bench}** â€” å…ƒãƒ‡ãƒ¼ã‚¿{res.get('n_cases_orig', res['n_cases'])}ä»¶" + ("ï¼ˆ50ä»¶ã«ãƒªã‚µãƒ³ãƒ—ãƒ«æ¸ˆï¼‰" if res.get("bootstrapped") else ""), expanded=False):
                        st.metric("åˆ†æä»¶æ•°", f"{res['n_cases']}ä»¶ï¼ˆæˆç´„{res['n_positive']}/å¤±æ³¨{res['n_negative']}ï¼‰")
                        c1, c2, c3 = st.columns(3)
                        with c1:
                            if "accuracy_lr" in res: st.metric("LR æ­£è§£ç‡", f"{res['accuracy_lr']*100:.1f}%")
                            if "auc_lr" in res and res.get("auc_lr"): st.metric("LR AUC", f"{res['auc_lr']:.3f}")
                        with c2:
                            if "accuracy_lgb" in res: st.metric("LGB æ­£è§£ç‡", f"{res['accuracy_lgb']*100:.1f}%")
                            if "auc_lgb" in res and res.get("auc_lgb"): st.metric("LGB AUC", f"{res['auc_lgb']:.3f}")
                        with c3:
                            if "auc_ensemble" in res:
                                st.metric("ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ« AUC", f"{res['auc_ensemble']:.3f}")
                                st.caption(f"æœ€é©: LR {res.get('ensemble_alpha', 0.5):.0%} + LGB {1-res.get('ensemble_alpha', 0.5):.0%}")
                        if "lgb_importance" in res:
                            fnames = res["feature_names"]
                            imp = pd.DataFrame([(fnames[i], v) for i, (_, v) in enumerate(res["lgb_importance"])], columns=["é …ç›®", "é‡è¦åº¦"]).sort_values("é‡è¦åº¦", ascending=False)
                            st.dataframe(imp.head(10), use_container_width=True, hide_index=True)

        st.divider()
        st.subheader("é‡ã¿æœ€é©åŒ–ï¼ˆå›å¸°ï¼‰")
        st.caption("æˆç´„/å¤±æ³¨ãƒ‡ãƒ¼ã‚¿ã§ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã‚’è¡Œã„ã€å€Ÿæ‰‹ã‚¹ã‚³ã‚¢ãƒ»ç‰©ä»¶ã‚¹ã‚³ã‚¢ã®æ¨å¥¨å‰²åˆã¨ã€ç·åˆã‚¹ã‚³ã‚¢ãƒ»å®šæ€§ã‚¹ã‚³ã‚¢ã®æ¨å¥¨å‰²åˆã‚’ç®—å‡ºã—ã¾ã™ã€‚å‚è€ƒå€¤ã¨ã—ã¦è¡¨ç¤ºã—ã¾ã™ã€‚")
        if st.button("ğŸ”„ å›å¸°ã§é‡ã¿ã‚’æœ€é©åŒ–", key="run_weight_optimize"):
            with st.spinner("å›å¸°ã§é‡ã¿ã‚’ç®—å‡ºä¸­..."):
                opt = optimize_score_weights_from_regression()
            if opt is not None:
                st.session_state["weight_optimize_result"] = opt
            else:
                st.session_state["weight_optimize_result"] = None
            st.rerun()
        wopt = st.session_state.get("weight_optimize_result")
        if wopt:
            w_b_cur, w_a_cur, w_q_cur, w_ql_cur = get_score_weights()
            st.success(f"åˆ†æä»¶æ•°: **{wopt['n_cases']}ä»¶**ã€‚å›å¸°AUC: **{wopt.get('auc_borrower_asset', 0):.3f}**")
            st.markdown("**æ¨å¥¨: å€Ÿæ‰‹** " + f"**{wopt['recommended_borrower_pct']*100:.0f}%** / **ç‰©ä»¶** **{wopt['recommended_asset_pct']*100:.0f}%**ï¼ˆç¾åœ¨ {w_b_cur*100:.0f}% / {w_a_cur*100:.0f}%ï¼‰")
            if "recommended_quant_pct" in wopt and "recommended_qual_pct" in wopt:
                st.markdown("**æ¨å¥¨: ç·åˆ** " + f"**{wopt['recommended_quant_pct']*100:.0f}%** / **å®šæ€§** **{wopt['recommended_qual_pct']*100:.0f}%**ï¼ˆç¾åœ¨ {w_q_cur*100:.0f}% / {w_ql_cur*100:.0f}%ï¼‰")
                if wopt.get("n_cases_with_qual"):
                    st.caption(f"å®šæ€§ã‚ã‚Š {wopt['n_cases_with_qual']}ä»¶ãƒ»AUC {wopt.get('auc_quant_qual', 0):.3f}")
            else:
                st.caption("å®šæ€§ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®ãŸã‚ç·åˆ/å®šæ€§ã¯ 60%/40% ã®ã¾ã¾")
            if st.button("ğŸ’¾ æ¨å¥¨ã‚’ä¿å­˜ã—ã¦ã‚¹ã‚³ã‚¢è¨ˆç®—ã«åæ˜ ", key="save_weight_overrides"):
                overrides = load_coeff_overrides() or {}
                overrides["score_weights"] = {
                    "borrower": wopt["recommended_borrower_pct"],
                    "asset": wopt["recommended_asset_pct"],
                    "quant": wopt.get("recommended_quant_pct", DEFAULT_WEIGHT_QUANT),
                    "qual": wopt.get("recommended_qual_pct", DEFAULT_WEIGHT_QUAL),
                }
                if save_coeff_overrides(overrides):
                    st.success("ä¿å­˜ã—ã¾ã—ãŸã€‚ä»Šå¾Œã®å¯©æŸ»ã§ã“ã®é‡ã¿ã‚’ä½¿ã„ã¾ã™ã€‚")
                    st.rerun()
                else:
                    st.error("ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        elif n_reg_q >= QUALITATIVE_ANALYSIS_MIN_CASES:
            st.info("ã€Œå›å¸°ã§é‡ã¿ã‚’æœ€é©åŒ–ã€ãƒœã‚¿ãƒ³ã§ã€ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãæ¨å¥¨å‰²åˆã‚’ç®—å‡ºã§ãã¾ã™ã€‚")

elif mode == "ğŸ“ çµæœç™»éŒ² (æˆç´„/å¤±æ³¨)":
    st.title("ğŸ“ æ¡ˆä»¶çµæœç™»éŒ²")
    st.info("éå»ã®å¯©æŸ»æ¡ˆä»¶ã«å¯¾ã—ã¦ã€æœ€çµ‚çš„ãªçµæœï¼ˆæˆç´„ãƒ»å¤±æ³¨ï¼‰ã‚’ç™»éŒ²ã—ã¾ã™ã€‚")
    
    all_cases = load_all_cases()
    if not all_cases:
        st.warning("ç™»éŒ²ã•ã‚ŒãŸæ¡ˆä»¶ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        st.subheader("æœªç™»éŒ²ã®æ¡ˆä»¶")
        pending_cases = [c for c in all_cases if c.get("final_status") == "æœªç™»éŒ²"]
        
        if not pending_cases:
            st.success("å…¨ã¦ã®æ¡ˆä»¶ãŒç™»éŒ²æ¸ˆã¿ã§ã™ï¼")
        
        for i, case in enumerate(reversed(pending_cases[-5:])): 
            case_id = case.get("id", "")
            with st.expander(f"{case.get('timestamp')[:16]} - {case.get('industry_sub')} (ã‚¹ã‚³ã‚¢: {case['result']['score']:.0f})"):
                c1, c2 = st.columns(2)
                with c1:
                    st.write(f"**åˆ¤å®š**: {case['result']['hantei']}")
                    summary = case.get("chat_summary", "")
                    st.caption((summary[:100] + "...") if summary else "ã‚µãƒãƒªãªã—")
                
                with c2:
                    if st.button("ğŸ—‘ï¸ ã“ã®æ¡ˆä»¶ã‚’å‰Šé™¤", key=f"del_pending_{case_id}", type="secondary", help="æœªç™»éŒ²ã®ã¾ã¾ã“ã®æ¡ˆä»¶ã‚’ä¸€è¦§ã‹ã‚‰å‰Šé™¤ã—ã¾ã™"):
                        all_cases = [c for c in load_all_cases() if c.get("id") != case_id]
                        if save_all_cases(all_cases):
                            st.success("å‰Šé™¤ã—ã¾ã—ãŸ")
                            time.sleep(0.5)
                            st.rerun()
                        else:
                            st.error("ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                    with st.form(f"status_form_{i}"):
                        res_status = st.radio("çµæœ", ["æˆç´„", "å¤±æ³¨"], horizontal=True)
                        final_rate = st.number_input("ç²å¾—ãƒ¬ãƒ¼ãƒˆ (%)", value=0.0, step=0.01, format="%.2f", help="æˆç´„ã—ãŸå ´åˆã®æ±ºå®šé‡‘åˆ©")
                        past_base_rate = case.get("pricing", {}).get("base_rate", 1.2)
                        base_rate_input = st.number_input("å½“æ™‚ã®åŸºæº–é‡‘åˆ© (%)", value=past_base_rate, step=0.01, format="%.2f")
                        lost_reason = st.text_input("å¤±æ³¨ç†ç”± (å¤±æ³¨ã®å ´åˆã®ã¿)", placeholder="ä¾‹: é‡‘åˆ©ã§ä»–ç¤¾ã«è² ã‘ãŸ")
                        loan_condition_options = ["é‡‘èæ©Ÿé–¢ã¨å”èª¿", "æœ¬ä»¶é™åº¦", "æ¬¡å›æ ¼ä»˜ã¾ã§æœ¬ä»¶é™åº¦", "ãã®ä»–"]
                        loan_conditions = st.multiselect("èè³‡æ¡ä»¶", loan_condition_options, help="è©²å½“ã™ã‚‹æ¡ä»¶ã‚’è¤‡æ•°é¸æŠ")
                        competitor_name = st.text_input("ç«¶åˆä»–ç¤¾æƒ…å ±", placeholder="ä¾‹: ã€‡ã€‡éŠ€è¡Œã€ã€‡ã€‡ãƒªãƒ¼ã‚¹")
                        competitor_rate = st.number_input("ä»–ç¤¾æç¤ºé‡‘åˆ© (%)", value=0.0, step=0.01, format="%.2f", help="ç«¶åˆã®æç¤ºæ¡ä»¶ãŒã‚ã‚Œã°å…¥åŠ›")
                        
                        if st.form_submit_button("ç™»éŒ²ã™ã‚‹"):
                            target_id = case.get("id")
                            updated = False
                            for c in all_cases:
                                if c.get("id") == target_id:
                                    c["final_status"] = res_status
                                    c["final_rate"] = final_rate
                                    c["base_rate_at_time"] = base_rate_input
                                    if res_status == "æˆç´„" and final_rate > 0:
                                        c["winning_spread"] = final_rate - base_rate_input
                                    if res_status == "å¤±æ³¨":
                                        c["lost_reason"] = lost_reason
                                    c["loan_conditions"] = loan_conditions
                                    c["competitor_name"] = competitor_name.strip() or ""
                                    c["competitor_rate"] = competitor_rate if competitor_rate else None
                                    updated = True
                                    break
                            
                            if updated:
                                if save_all_cases(all_cases):
                                    st.success("ç™»éŒ²ã—ã¾ã—ãŸï¼")
                                    time.sleep(1)
                                    st.rerun()
                                else:
                                    st.error("ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

elif mode == "ğŸ“‹ å¯©æŸ»ãƒ»åˆ†æ":
    # ========== ãƒˆãƒƒãƒ—ãƒ¡ãƒ‹ãƒ¥ãƒ¼ï¼ˆæ–°è¦å¯©æŸ» / æƒ…å ±æ¤œç´¢ / ã‚°ãƒ©ãƒ• / å±¥æ­´åˆ†æ / è¨­å®šï¼‰ ==========
    menu_tabs = st.tabs(["ğŸ†• æ–°è¦å¯©æŸ»", "ğŸ” æƒ…å ±æ¤œç´¢", "ğŸ“ˆ ã‚°ãƒ©ãƒ•", "ğŸ“‹ å±¥æ­´åˆ†æ", "âš™ï¸ è¨­å®š"])
    # é›»å…‰æ²ç¤ºæ¿ï¼šå®šä¾‹ã®æ„šç—´ã‚’ãƒ¡ãƒ‹ãƒ¥ãƒ¼ç›´ä¸‹ã§ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«è¡¨ç¤º
    byoki_list = load_byoki_list()
    byoki_escaped = [str(s).replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;").replace('"', "&quot;") for s in byoki_list]
    ticker_text = "ã€€ï½œã€€ğŸŸ ".join(byoki_escaped)
    if ticker_text:
        ticker_duplicated = ("ğŸŸ " + ticker_text + "ã€€ï½œã€€") * 2
        st.markdown(
            f'<div class="byoki-ticker-wrap"><div class="byoki-ticker-inner"><span>{ticker_duplicated}</span></div></div>',
            unsafe_allow_html=True,
        )

    with menu_tabs[0]:  # æ–°è¦å¯©æŸ»
        st.title("ğŸ¢ æ¸©æ°´å¼ ãƒªãƒ¼ã‚¹å¯©æŸ»ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ")
        selected_major = 'D å»ºè¨­æ¥­'
        selected_sub = '06 ç·åˆå·¥äº‹æ¥­'
        comparison_text = 'ãƒ‡ãƒ¼ã‚¿ãªã—'
        trend_info = 'ãƒ‡ãƒ¼ã‚¿ãªã—'
        submitted = False  # å¯©æŸ»å…¥åŠ›ã‚¿ãƒ–ä»¥å¤–ã§ã‚‚ if submitted ãŒå‚ç…§ã§ãã‚‹ã‚ˆã†åˆæœŸåŒ–
        # å³ã®AIã‚ªãƒ•ã‚£ã‚µãƒ¼ç›¸è«‡ãŒåˆ‡ã‚Œãªã„ã‚ˆã†ã€å³ã«ã‚„ã‚„å¤šã‚ã®å¹…ã‚’å‰²ã‚Šå½“ã¦
        col_left, col_right = st.columns([3, 4])

        with col_left:
            submitted_apply = False
            submitted_judge = False
            if "nav_index" not in st.session_state:
                st.session_state.nav_index = 0
            # åˆ¤å®šé–‹å§‹ç›´å¾Œã® rerun ã®1å›ã ã‘ã€Œåˆ†æçµæœã€ã«åˆã‚ã›ã‚‹ï¼ˆæ¯å›ä¸Šæ›¸ãã™ã‚‹ã¨å¯©æŸ»å…¥åŠ›ã«æˆ»ã‚Œãªããªã‚‹ï¼‰
            if st.session_state.pop("_jump_to_analysis", False):
                st.session_state["nav_mode_widget"] = "ğŸ“Š åˆ†æçµæœ"
            nav_mode = st.radio(
                "è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰",
                ["ğŸ“ å¯©æŸ»å…¥åŠ›", "ğŸ“Š åˆ†æçµæœ"],
                horizontal=True,
                label_visibility="visible",
                key="nav_mode_widget",
            )
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒ©ã‚¸ã‚ªã§åˆ‡ã‚Šæ›¿ãˆãŸã¨ã nav_index ã‚’åŒæœŸ
            st.session_state.nav_index = 1 if nav_mode == "ğŸ“Š åˆ†æçµæœ" else 0
            if nav_mode == "ğŸ“ å¯©æŸ»å…¥åŠ›":
                st.header("ğŸ“ 1. å¯©æŸ»ãƒ‡ãƒ¼ã‚¿ã®å…¥åŠ›")
                image_placeholder = st.empty()
                if 'current_image' not in st.session_state: st.session_state['current_image'] = "guide"
                img_path = get_image(st.session_state['current_image'])
                if img_path: image_placeholder.image(img_path, width=280)
                st.divider()

                # æ¥­ç•Œãƒ»å–å¼•ã‚’ expander ã§æŠ˜ã‚ŠãŸãŸã¿
                with st.expander("ğŸ“Œ æ¥­ç•Œé¸æŠãƒ»å–å¼•çŠ¶æ³", expanded=True):
                    if not jsic_data:
                        st.error("æ¥­ç•Œãƒ‡ãƒ¼ã‚¿(industry_trends_jsic.json)ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                        major_keys = ["D å»ºè¨­æ¥­"]
                    else:
                        major_keys = list(jsic_data.keys())
                    last_inp = st.session_state.get("last_submitted_inputs") or {}
                    idx_major = major_keys.index(last_inp["selected_major"]) if last_inp.get("selected_major") in major_keys else 0
                    selected_major = st.selectbox("å¤§åˆ†é¡ (æ—¥æœ¬æ¨™æº–ç”£æ¥­åˆ†é¡)", major_keys, index=idx_major, key="select_major")
                    if jsic_data:
                        sub_data = jsic_data[selected_major]["sub"]
                        sub_keys = list(sub_data.keys())
                        mapped_coeff_category = jsic_data[selected_major]["mapping"]
                    else:
                        sub_data = {}
                        sub_keys = ["06 ç·åˆå·¥äº‹æ¥­"]
                        mapped_coeff_category = "â‘£å»ºè¨­æ¥­"
                    idx_sub = sub_keys.index(last_inp["selected_sub"]) if last_inp.get("selected_sub") in sub_keys else 0
                    selected_sub = st.selectbox("ä¸­åˆ†é¡", sub_keys, index=idx_sub, key="select_sub")
                    st.session_state["_frag_major"] = selected_major
                    st.session_state["_frag_sub"] = selected_sub
                    st.session_state["_frag_mapped_coeff"] = mapped_coeff_category
                    st.session_state["_frag_sub_data"] = sub_data
                    st.session_state["_frag_jsic_data"] = jsic_data
                    trend_info = sub_data.get(selected_sub, "æƒ…å ±ãªã—")
                    past_stats = get_stats(selected_sub)
                    past_info_text = "éå»ãƒ‡ãƒ¼ã‚¿ãªã—"
                    alert_msg = ""
                    if past_stats["count"] > 0:
                        past_info_text = f"éå»{past_stats['count']}ä»¶ (å¹³å‡: {past_stats['avg_score']:.1f}ç‚¹)"
                        if past_stats["close_rate"] > 0:
                            past_info_text += f"\næˆç´„ç‡: {past_stats['close_rate']:.0%}"
                        if past_stats.get("avg_winning_rate") is not None and past_stats["avg_winning_rate"] > 0:
                            past_info_text += f"\nå¹³å‡æˆç´„é‡‘åˆ©: {past_stats['avg_winning_rate']:.2f}%"
                        if past_stats.get("top_competitors_lost"):
                            past_info_text += f"\nã‚ˆãè² ã‘ã‚‹ç«¶åˆ: {', '.join(past_stats['top_competitors_lost'][:5])}"
                        if past_stats["lost_reasons"]:
                            top_reason = max(set(past_stats["lost_reasons"]), key=past_stats["lost_reasons"].count)
                            alert_msg = f"\nâš ï¸ **æ³¨æ„**: ã“ã®æ¥­ç¨®ã¯ã€Œ{top_reason}ã€ã«ã‚ˆã‚‹å¤±æ³¨ãŒå¤šã„ã§ã™ã€‚"
                    st.info(f"ğŸ’¡ **æ¥­ç•Œãƒˆãƒ¬ãƒ³ãƒ‰ ({selected_sub})**:\n{trend_info}\n\nğŸ“š **ç¤¾å†…å®Ÿç¸¾**: {past_info_text}{alert_msg}")
                    with st.expander("ğŸŒ ãƒãƒƒãƒˆã§æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æ¤œç´¢", expanded=False):
                        search_query = st.text_input("æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰", value=f"{selected_sub} å‹•å‘ 2025", key="news_search_query")
                        if st.button("æ¤œç´¢", key="btn_news_search"):
                            try:
                                # ã¾ãš ddgsï¼ˆæ–°ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åï¼‰ã‚’å„ªå…ˆçš„ã«åˆ©ç”¨ã—ã€ãªã‘ã‚Œã° duckduckgo_search ã‚’ä½¿ã†
                                try:
                                    from ddgs import DDGS
                                    backend_name = "ddgs"
                                except ImportError:
                                    from duckduckgo_search import DDGS
                                    backend_name = "duckduckgo_search"

                                with st.spinner(f"æ¤œç´¢ä¸­...ï¼ˆãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰: {backend_name}ï¼‰"):
                                    raw_results = list(DDGS().text(search_query, region='jp-jp', max_results=10))
                                    if not raw_results:
                                        raw_results = list(DDGS().text(search_query, max_results=10))
                                    if not raw_results:
                                        st.warning("DuckDuckGoæ¤œç´¢ã‹ã‚‰çµæœãŒè¿”ã£ã¦ãã¾ã›ã‚“ã§ã—ãŸã€‚ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ¶é™ã‚„ä¸€æ™‚çš„ãªéšœå®³ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
                                        st.session_state.news_results = []
                                    else:
                                        jp_results = []
                                        for r in raw_results:
                                            title = (r.get("title") if isinstance(r, dict) else "") or ""
                                            body = (r.get("body") if isinstance(r, dict) else "") or ""
                                            if is_japanese_text(title + body):
                                                jp_results.append(r)
                                        if jp_results:
                                            st.session_state.news_results = jp_results[:3]
                                        else:
                                            st.info("æ—¥æœ¬èªåˆ¤å®šã§ãƒ’ãƒƒãƒˆã—ãªã‹ã£ãŸãŸã‚ã€æ¤œç´¢çµæœã‚’ãã®ã¾ã¾è¡¨ç¤ºã—ã¾ã™ã€‚")
                                            st.session_state.news_results = raw_results[:3]
                                    st.caption(f"æ¤œç´¢çµæœä»¶æ•°: {len(st.session_state.news_results)} ä»¶")
                            except ImportError:
                                st.error("æ¤œç´¢æ©Ÿèƒ½ã«ã¯è¿½åŠ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦ã§ã™: pip install duckduckgo-search ã¾ãŸã¯ pip install ddgs")
                            except Exception as e:
                                st.error(f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
                        if 'news_results' in st.session_state and st.session_state.news_results:
                            for i, res in enumerate(st.session_state.news_results):
                                st.markdown(f"**[{res['title']}]({res['href']})**")
                                st.caption(res['body'])
                                if st.button(f"ã“ã®è¨˜äº‹ã‚’AIã«èª­ã¿è¾¼ã¾ã›ã‚‹", key=f"read_news_{i}"):
                                    with st.spinner(f"ã€Œ{res['title']}ã€ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™..."):
                                        content = scrape_article_text(res['href'])
                                        # æ—¥æœ¬èªè¨˜äº‹ã®ã¿AIã«èª­ã¿è¾¼ã¾ã›ã‚‹
                                        if content and isinstance(content, str) and not content.startswith("è¨˜äº‹ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ"):
                                            if is_japanese_text(content):
                                                news_obj = {
                                                    "title": res['title'],
                                                    "url": res['href'],
                                                    "content": content,
                                                }
                                                st.session_state.selected_news_content = news_obj
                                                case_id = st.session_state.get("current_case_id")
                                                if case_id:
                                                    append_case_news({"case_id": case_id, **news_obj})
                                                st.success("æ—¥æœ¬èªè¨˜äº‹ã®èª­ã¿è¾¼ã¿å®Œäº†ï¼AIã¸ã®ç›¸è«‡ãƒ»ãƒ‡ã‚£ãƒ™ãƒ¼ãƒˆæ™‚ã«å†…å®¹ãŒåæ˜ ã•ã‚Œã¾ã™ã€‚")
                                            else:
                                                st.warning("ã“ã®è¨˜äº‹ã¯æ—¥æœ¬èªã§ã¯ãªã„å¯èƒ½æ€§ãŒé«˜ã„ãŸã‚ã€AIã¸ã®èª­ã¿è¾¼ã¿ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")
                                        elif isinstance(content, str) and content.startswith("è¨˜äº‹ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ"):
                                            st.error(content)
                                        else:
                                            st.error("è¨˜äº‹ã®æœ¬æ–‡ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                                st.divider()
                    if 'selected_news_content' in st.session_state:
                        with st.container(border=True):
                            st.write("ğŸ“– **ç¾åœ¨èª­ã¿è¾¼ã¿ä¸­ã®è¨˜äº‹:**")
                            st.write(st.session_state.selected_news_content['title'])
                            if st.button("èª­ã¿è¾¼ã¿ã‚’ã‚¯ãƒªã‚¢"):
                                del st.session_state.selected_news_content
                                st.rerun()
                    st.markdown("##### ğŸ¤ å–å¼•ãƒ»ç«¶åˆçŠ¶æ³")
                    col_q1, col_q2 = st.columns(2)
                    with col_q1: main_bank = st.selectbox("å–å¼•åŒºåˆ†", ["ãƒ¡ã‚¤ãƒ³å…ˆ", "éãƒ¡ã‚¤ãƒ³å…ˆ"], key="main_bank", index=0 if (last_inp.get("main_bank") or "ãƒ¡ã‚¤ãƒ³å…ˆ") == "ãƒ¡ã‚¤ãƒ³å…ˆ" else 1)
                    with col_q2: competitor = st.selectbox("ç«¶åˆçŠ¶æ³", ["ç«¶åˆãªã—", "ç«¶åˆã‚ã‚Š"], key="competitor", index=0 if (last_inp.get("competitor") or "ç«¶åˆãªã—") == "ç«¶åˆãªã—" else 1)
                    # ç«¶åˆã‚ã‚Šã®å ´åˆã®ã¿ã€Œç«¶åˆæç¤ºé‡‘åˆ©ã€ã‚’å…¥åŠ›ï¼ˆé‡‘åˆ©å·®ã§æˆç´„ç‡è£œæ­£ã«åˆ©ç”¨ï¼‰
                    if competitor == "ç«¶åˆã‚ã‚Š":
                        comp_rate = st.number_input(
                            "ç«¶åˆæç¤ºé‡‘åˆ© (%)",
                            min_value=0.0,
                            max_value=30.0,
                            value=float(st.session_state.get("competitor_rate") or 0.0),
                            step=0.1,
                            format="%.1f",
                            key="competitor_rate_input",
                            help="ç«¶åˆä»–ç¤¾ã®æç¤ºé‡‘åˆ©ã‚’å…¥åŠ›ã™ã‚‹ã¨ã€è‡ªç¤¾ãŒæœ‰åˆ©ãªå ´åˆã«æˆç´„ç‡ã‚’ãƒ—ãƒ©ã‚¹è£œæ­£ã—ã¾ã™ã€‚"
                        )
                        st.session_state["competitor_rate"] = comp_rate if comp_rate > 0 else None
                    else:
                        st.session_state["competitor_rate"] = None
                st.caption("ğŸ’¡ æ•°å­—å…¥åŠ›ã§ç”»é¢ãŒã‚¬ã‚¿ã¤ãå ´åˆï¼šã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã§å¤§ã¾ã‹ã«åˆã‚ã›ã¦ã‹ã‚‰ç›´æ¥å…¥åŠ›ã§å¾®èª¿æ•´ã—ã¦ãã ã•ã„ã€‚")
                st.caption("ğŸ“Œ æ•°å€¤ã¨ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã¯é€£å‹•ã—ã¾ã™ã€‚Enter ã¯ã€Œå…¥åŠ›ç¢ºå®šã€ã«ã ã‘åŠ¹ãã€åˆ¤å®šã«ã¯è¡Œãã¾ã›ã‚“ã€‚")
                if st.button("ğŸ†• æ–°ã—ãå…¥åŠ›ã™ã‚‹", help="å…¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’åˆæœŸå€¤ã«ãƒªã‚»ãƒƒãƒˆã—ã¾ã™", use_container_width=False):
                    _reset_shinsa_inputs()
                    st.rerun()
                with st.form("shinsa_form"):
                    st.info(
                        "**å¿…é ˆé …ç›®**: å£²ä¸Šé«˜ï¼ˆ1ä»¥ä¸Šï¼‰ã€ç·è³‡ç”£ï¼ˆ1ä»¥ä¸Šï¼‰ã‚’å…¥åŠ›ã—ãªã„ã¨åˆ¤å®šã§ãã¾ã›ã‚“ã€‚\n\n"
                        "**æ¨å¥¨**: å–¶æ¥­åˆ©ç›Šãƒ»ç´”è³‡ç”£ã‚‚å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚æœªå…¥åŠ›ã ã¨å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ï¼ˆç·è³‡ç”£ãƒ»ç´”è³‡ç”£å¿…é ˆï¼‰ã‚„è‡ªå·±è³‡æœ¬æ¯”ç‡ãŒä½¿ãˆã¾ã›ã‚“ã€‚"
                    )
                    submitted_apply = st.form_submit_button("å…¥åŠ›ç¢ºå®šï¼ˆEnterã§åæ˜ ï¼‰", type="secondary", help="æ•°å­—å…¥åŠ›ã§Enterã‚’æŠ¼ã—ãŸã¨ãã¯ã“ã“ãŒæŠ¼ã•ã‚ŒãŸæ‰±ã„ã«ãªã‚Šã€åˆ¤å®šã«ã¯è¡Œãã¾ã›ã‚“ã€‚")
                    with st.expander("ğŸ“Š 1. æç›Šè¨ˆç®—æ›¸ (P/L)", expanded=True):
                        # â‘ å£²ä¸Šé«˜ï¼ˆãƒ•ãƒ©ã‚°ãƒ¡ãƒ³ãƒˆåŒ–ã§å…¥åŠ›æ™‚ã®ã‚¬ã‚¿ã¤ãè»½æ¸›ï¼‰
                        _fragment_nenshu()

                        #  â‘¡å£²ä¸Šé«˜ç·åˆ©ç›Šï¼ˆã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã¯å¾“æ¥ã©ãŠã‚Šã€æ‰‹å…¥åŠ›ã®ã¿900å„„åƒå††ã¾ã§ï¼‰
                        st.markdown("### å£²ä¸Šé«˜ç·åˆ©ç›Š")
                        item9_gross = _slider_and_number("item9_gross", "sourieki", 10000, -500000, 1000000, 100, 1, max_val_number=90_000_000)
                        st.divider() # æ¬¡ã®é …ç›®ã¨ã®åŒºåˆ‡
        #---------------------------------------------------------------------------------------------------------------

                        # #â‘¢å–¶æ¥­åˆ©ç›Š
                        st.markdown("### å–¶æ¥­åˆ©ç›Š")
                        rieki = _slider_and_number("rieki", "rieki", 10000, -100000, 200000, 100, 1, max_val_number=90_000_000)
                        st.divider() # æ¬¡ã®é …ç›®ã¨ã®åŒºåˆ‡

        #----------------------------------------------------------------------------------------------------------------------

                        st.markdown("### çµŒå¸¸åˆ©ç›Š")
                        item4_ord_profit = _slider_and_number("item4_ord_profit", "item4_ord_profit", 10000, -100000, 200000, 100, 1, max_val_number=90_000_000)
                        st.divider() # æ¬¡ã®é …ç›®ã¨ã®åŒºåˆ‡
        #-------------------------------------------------------------------------------------------

                        st.markdown("### å½“æœŸåˆ©ç›Š")
                        item5_net_income = _slider_and_number("item5_net_income", "item5_net_income", 10000, -100000, 200000, 100, 1, max_val_number=90_000_000)
                        st.divider() # æ¬¡ã®é …ç›®ã¨ã®åŒºåˆ‡

                        # Noneå¯¾ç­–ï¼ˆnenshu ã¯ãƒ•ãƒ©ã‚°ãƒ¡ãƒ³ãƒˆå†…ã§è¨­å®šã•ã‚Œã‚‹ãŸã‚ session_state ã‹ã‚‰å–å¾—ï¼‰
                        c_nenshu = st.session_state.get("nenshu", 0) or 0
                        c_gross = item9_gross if item9_gross is not None else 0
                        c_rieki = rieki if rieki is not None else 0
                        c_ord = item4_ord_profit if item4_ord_profit is not None else 0
                        c_net = item5_net_income if item5_net_income is not None else 0
            
                        # [å‰Šé™¤] å…¥åŠ›ä¸­ã®ã‚¦ã‚©ãƒ¼ã‚¿ãƒ¼ãƒ•ã‚©ãƒ¼ãƒ«ã‚°ãƒ©ãƒ•è¡¨ç¤º (åˆ†æã‚¿ãƒ–ã«é›†ç´„ã™ã‚‹ãŸã‚)
                        # if c_nenshu > 0: 
                        #     st.pyplot(plot_waterfall(c_nenshu, c_gross, c_rieki, c_ord, c_net))

                    with st.expander("ğŸ¢ 2. è³‡ç”£ãƒ»çµŒè²»ãƒ»ãã®ä»–", expanded=False):
                    
                        st.markdown("### æ¸›ä¾¡å„Ÿå´è²»")
                        item10_dep = _slider_and_number("item10_dep", "item10_dep", 10000, 0, 200000, 100, 1, max_val_number=90_000_000)
                        st.divider() # æ¬¡ã®é …ç›®ã¨ã®åŒºåˆ‡
    
        #--------------------------------------------------------------------------------------------------------
                        #â‘¦æ¸›ä¾¡å„Ÿå´è²»ï¼ˆçµŒè²»ï¼‰
    
                        st.markdown("### æ¸›ä¾¡å„Ÿå´è²»(çµŒè²»)")
                        item11_dep_exp = _slider_and_number("item11_dep_exp", "item11_dep_exp", 10000, 0, 200000, 100, 1, max_val_number=90_000_000)
                        st.divider() # æ¬¡ã®é …ç›®ã¨ã®åŒºåˆ‡
    
        #----------------------------------------------------------------------------------------------------
    
                        # #â‘§è³ƒå€Ÿæ–™
                        st.markdown("### è³ƒå€Ÿæ–™")
                        item8_rent = _slider_and_number("item8_rent", "item8_rent", 10000, 0, 100000, 100, 1, max_val_number=90_000_000)
                        st.divider() # æ¬¡ã®é …ç›®ã¨ã®åŒºåˆ‡
    
        #----------------------------------------------------------------------------------------------
    
                        #â‘¨è³ƒå€Ÿæ–™ï¼ˆçµŒè²»ï¼‰
                        # h_item12_rent_exp=st.empty()
                        # item12_rent_exp = col3.select_slider("è³ƒå€Ÿæ–™(çµŒè²»ï¼‰", options=range(0, 90000, 100), value=0)
                        # red_label(h_item12_rent_exp, f"è³ƒå€Ÿæ–™(çµŒè²»ï¼‰:{item12_rent_exp:,} åƒå††")
                        # st.divider()
    
                        st.markdown("### è³ƒå€Ÿæ–™ï¼ˆçµŒè²»ï¼‰")
                        item12_rent_exp = _slider_and_number("item12_rent_exp", "item12_rent_exp", 10000, 0, 100000, 100, 1, max_val_number=90_000_000)
                        st.divider() # æ¬¡ã®é …ç›®ã¨ã®åŒºåˆ‡
    
        #------------------------------------------------------------------------------------------------
    
                        #â‘©æ©Ÿæ¢°è£…ç½®
     
                        st.markdown("### æ©Ÿæ¢°è£…ç½®")
                        item6_machine = _slider_and_number("item6_machine", "item6_machine", 10000, 0, 200000, 100, 1, max_val_number=90_000_000)
                        st.divider() # æ¬¡ã®é …ç›®ã¨ã®åŒºåˆ‡
    
        #--------------------------------------------------------------------------------------------
    
                        # #11ãã®ä»–è³‡ç”£
                        # h_item7_other=st.empty()
                        # item7_other = col4.select_slider("ãã®ä»–è³‡ç”£", options=range(0, 50000, 100), value=0)
                        # red_label(h_item7_other, f"ãã®ä»–è³‡ç”£:{ item7_other:,} åƒå††")
                        # st.divider()
    
                        st.markdown("### ãã®ä»–è³‡ç”£")
                        item7_other = _slider_and_number("item7_other", "item7_other", 10000, 0, 200000, 100, 1, max_val_number=90_000_000)
                        st.divider() # æ¬¡ã®é …ç›®ã¨ã®åŒºåˆ‡
        #-------------------------------------------------------------------------------------------------------------
                        # #12ç´”è³‡ç”£åˆè¨ˆ
    
                        st.markdown("### ç´”è³‡ç”£")
                        net_assets = _slider_and_number("net_assets", "net_assets", 10000, -30000, 500000, 100, 1, max_val_number=90_000_000)
                        st.divider() # æ¬¡ã®é …ç›®ã¨ã®åŒºåˆ‡
        #--------------------------------------------------------------------------------
                        #13ç·è³‡ç”£
                        # h_total_assets=st.empty()
                        # total_assets = col4.select_slider("ç·è³‡ç”£ï¼ˆåƒå††ï¼‰", options=range(0, 900000, 1000), value=0)
                        # red_label(h_total_assets, f"ç·è³‡ç”£:{total_assets:,} åƒå††")
                        # st.divider()
    
                        st.markdown("### ç·è³‡ç”£")
                        total_assets = _slider_and_number("total_assets", "total_assets", 10000, 0, 1000000, 100, 1, max_val_number=90_000_000)
                        st.divider() # æ¬¡ã®é …ç›®ã¨ã®åŒºåˆ‡
        #------------------------------------------------------------------------------------------------------
                    with st.expander("ğŸ’³ 3. ä¿¡ç”¨æƒ…å ±", expanded=False):
    
                        # defaultå€¤ã‚’ãƒªã‚¹ãƒˆå†…ã®æ–‡å­—åˆ—ã¨å®Œå…¨ã«ä¸€è‡´ã•ã›ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™
                        grade = st.segmented_control("æ ¼ä»˜", ["â‘ 1-3 (å„ªè‰¯)", "â‘¡4-6 (æ¨™æº–)", "â‘¢è¦æ³¨æ„ä»¥ä¸‹", "â‘£ç„¡æ ¼ä»˜"], default=st.session_state.get("grade", "â‘¡4-6 (æ¨™æº–)"), key="grade")
        #---------------------------------------------------------------------------             
                    #     #14éŠ€è¡Œä¸ä¿¡
    
                        st.markdown("### ã†ã¡ã®éŠ€è¡Œä¸ä¿¡")
                        st.caption("å½“ç¤¾ã®ä¸ä¿¡ã§ã™ï¼ˆç·éŠ€è¡Œä¸ä¿¡ã§ã¯ã‚ã‚Šã¾ã›ã‚“ï¼‰")
                        bank_credit = _slider_and_number("bank_credit", "bank_credit", 10000, 0, 3000000, 100, 1, max_val_number=90_000_000)
                        st.divider() # æ¬¡ã®é …ç›®ã¨ã®åŒºåˆ‡
        #---------------------------------------------------------------------------------------------------------
      
                        # #15ãƒªãƒ¼ã‚¹ä¸ä¿¡
    
                        st.markdown("### ã†ã¡ã®ãƒªãƒ¼ã‚¹ä¸ä¿¡")
                        st.caption("å½“ç¤¾ã®ä¸ä¿¡ã§ã™ï¼ˆç·ãƒªãƒ¼ã‚¹ä¸ä¿¡ã§ã¯ã‚ã‚Šã¾ã›ã‚“ï¼‰")
                        lease_credit = _slider_and_number("lease_credit", "lease_credit", 10000, 0, 300000, 100, 1, max_val_number=90_000_000)
                        st.divider() # æ¬¡ã®é …ç›®ã¨ã®åŒºåˆ‡
        #--------------------------------------------------------------------------------------------------------
                        # #16å¥‘ç´„æ•°
                        st.markdown("### å¥‘ç´„æ•°")
                        contracts = _slider_and_number("contracts", "contracts", 1, 0, 30, 1, 1, unit="ä»¶")
    
                        st.divider() # æ¬¡ã®é …ç›®ã¨ã®åŒºåˆ‡
    
        #------------------------------------------------------------------------------------------------------
    
    
                    with st.expander("ğŸ“‹ 4. å¥‘ç´„æ¡ä»¶ãƒ»å–å¾—ä¾¡æ ¼ãƒ»ãƒªãƒ¼ã‚¹ç‰©ä»¶", expanded=False):
                        customer_type = st.radio("é¡§å®¢åŒºåˆ†", ["æ—¢å­˜å…ˆ", "æ–°è¦å…ˆ"], horizontal=True, index=0 if st.session_state.get("customer_type", "æ—¢å­˜å…ˆ") == "æ—¢å­˜å…ˆ" else 1, key="customer_type")
                        st.divider()
                        st.markdown("##### ğŸ“ˆ å¥‘ç´„æ¡ä»¶ãƒ»å±æ€§ (åˆ©å›ã‚Šäºˆæ¸¬ç”¨)")
                        with st.container():
                            c_y1, c_y2, c_y3 = st.columns(3)
                            contract_type = c_y1.radio("å¥‘ç´„ç¨®é¡", ["ä¸€èˆ¬", "è‡ªå‹•è»Š"], horizontal=True, index=0 if st.session_state.get("contract_type", "ä¸€èˆ¬") == "ä¸€èˆ¬" else 1, key="contract_type")
                            deal_source = c_y2.radio("å•†è«‡ã‚½ãƒ¼ã‚¹", ["éŠ€è¡Œç´¹ä»‹", "ãã®ä»–"], horizontal=True, index=0 if st.session_state.get("deal_source", "ãã®ä»–") == "éŠ€è¡Œç´¹ä»‹" else 1, key="deal_source")
                            lease_term = c_y3.select_slider("å¥‘ç´„æœŸé–“ï¼ˆæœˆï¼‰", options=range(0, 121, 1), value=60)
                            st.divider()
                            c_l, c_r = st.columns([0.7, 0.3])
                            with c_l:
                                acceptance_year = st.number_input("æ¤œåå¹´ (è¥¿æš¦)", value=2026, step=1)
                            st.session_state.lease_term = lease_term
                            st.session_state.acceptance_year = acceptance_year
                        st.markdown("### å–å¾—ä¾¡æ ¼")
                        acquisition_cost = _slider_and_number("acquisition_cost", "acquisition_cost", 1000, 0, 500000, 100, 100, label_slider="å–å¾—ä¾¡æ ¼èª¿æ•´", max_val_number=90_000_000)
                        st.markdown("### ãƒªãƒ¼ã‚¹ç‰©ä»¶")
                        if not LEASE_ASSETS_LIST:
                            selected_asset_id = "other"
                            asset_score = 50
                            asset_name = "æœªé¸æŠ"
                            st.caption("lease_assets.json ã‚’é…ç½®ã™ã‚‹ã¨ç‰©ä»¶ãƒªã‚¹ãƒˆã‹ã‚‰é¸æŠã§ãã¾ã™ã€‚")
                        else:
                            options = [f"{it.get('name', '')}ï¼ˆ{it.get('score', 0)}ç‚¹ï¼‰" for it in LEASE_ASSETS_LIST]
                            default_idx = min(st.session_state.get("selected_asset_index", 0), len(options) - 1) if "selected_asset_index" in st.session_state else 0
                            sel_idx = st.selectbox("ç‰©ä»¶ã‚’é¸æŠï¼ˆç‚¹æ•°ãŒåˆ¤å®šã«åæ˜ ï¼‰", range(len(options)), format_func=lambda i: options[i], index=default_idx, key="lease_asset_select", help="é¸æŠã—ãŸç‰©ä»¶ã®ç‚¹æ•°ã‚’å€Ÿæ‰‹ã‚¹ã‚³ã‚¢ã«åæ˜ ã—ã¾ã™ã€‚")
                            st.session_state["selected_asset_index"] = sel_idx
                            selected_item = LEASE_ASSETS_LIST[sel_idx]
                            selected_asset_id = selected_item.get("id", "other")
                            asset_score = int(selected_item.get("score", 50))
                            asset_name = selected_item.get("name", "ãã®ä»–")
                            if selected_item.get("note"):
                                st.caption(f"ğŸ’¡ {selected_item['note']}")
                        st.divider()
                        # ---------- 5. å®šæ€§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ï¼ˆç·åˆÃ—é‡ã¿ï¼‹å®šæ€§Ã—é‡ã¿ã§ãƒ©ãƒ³ã‚¯Aã€œEã€‚å®šæ€§æœªé¸æŠæ™‚ã¯ç·åˆã‚¹ã‚³ã‚¢ã®ã¿ï¼‰ ----------
                        with st.expander("ğŸ“‹ å®šæ€§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°", expanded=False):
                            st.caption("å¯©æŸ»å“¡ãŒå®šæ€§é¢ã‚’é …ç›®åˆ¥ã«è©•ä¾¡ã—ã¾ã™ã€‚ãƒ©ãƒ³ã‚¯ï¼ˆAã€œEï¼‰ã¯ **ç·åˆã‚¹ã‚³ã‚¢Ã—é‡ã¿ï¼‹å®šæ€§Ã—é‡ã¿**ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ60%/40%ï¼‰ã§ç®—å‡ºã€‚å®šæ€§ã‚’1ä»¶ã‚‚é¸ã‚“ã§ã„ãªã„å ´åˆã¯ãƒ©ãƒ³ã‚¯ã¯å‡ºã•ãšã€ç·åˆã‚¹ã‚³ã‚¢ã®ã¿ã§åˆ¤å®šã—ã¾ã™ã€‚ï¼ˆæœªé¸æŠã®é …ç›®ã¯å®šæ€§ã‚¹ã‚³ã‚¢ã«å«ã‚ã¾ã›ã‚“ï¼‰")
                            for item in QUALITATIVE_SCORING_CORRECTION_ITEMS:
                                opts = item.get("options") or QUALITATIVE_SCORING_LEVELS
                                opts_display = ["æœªé¸æŠ"] + [o[1] for o in opts]
                                st.selectbox(
                                    f"{item['label']}ï¼ˆé‡ã¿{item['weight']}%ï¼‰",
                                    range(len(opts_display)),
                                    format_func=lambda i, d=opts_display: d[i],
                                    key=f"qual_corr_{item['id']}",
                                )
                            # å…¥åŠ›å€¤ã¯åˆ¤å®šé–‹å§‹ãƒ–ãƒ­ãƒƒã‚¯ã§ session_state ã‹ã‚‰å–å¾—
                    submitted_judge = st.form_submit_button("åˆ¤å®šé–‹å§‹", type="primary", use_container_width=True)

            if submitted_apply:
                # Enter ã‚„ã€Œå…¥åŠ›ç¢ºå®šã€æŠ¼ä¸‹æ™‚: åˆ¤å®šã¯è¡Œã‚ãšã€å…¥åŠ›å€¤ã‚’ session_state ã«åæ˜ ã—ã¦å†è¡¨ç¤º
                st.session_state.item9_gross = item9_gross
                st.session_state.rieki = rieki
                st.session_state.item4_ord_profit = item4_ord_profit
                st.session_state.item5_net_income = item5_net_income
                st.session_state.item10_dep = item10_dep
                st.session_state.item11_dep_exp = item11_dep_exp
                st.session_state.item8_rent = item8_rent
                st.session_state.item12_rent_exp = item12_rent_exp
                st.session_state.item6_machine = item6_machine
                st.session_state.item7_other = item7_other
                st.session_state.net_assets = net_assets
                st.session_state.total_assets = total_assets
                st.session_state.bank_credit = bank_credit
                st.session_state.lease_credit = lease_credit
                st.session_state.contracts = contracts
                st.session_state.lease_term = lease_term
                st.session_state.acquisition_cost = acquisition_cost
                st.session_state.acceptance_year = acceptance_year
                st.rerun()

            if submitted_judge or st.session_state.pop("_auto_judge", False):
                try:
                    # ãƒ•ãƒ©ã‚°ãƒ¡ãƒ³ãƒˆåˆ©ç”¨æ™‚ç”¨: session_state ã®å€¤ã§ä¸Šæ›¸ãï¼ˆå…¥åŠ›ã‚¬ã‚¿ã¤ãè»½æ¸›ã®ãŸã‚ï¼‰
                    nenshu = st.session_state.get("nenshu", 0)
                    item9_gross = st.session_state.get("item9_gross", 0)
                    rieki = st.session_state.get("rieki", 0)
                    item4_ord_profit = st.session_state.get("item4_ord_profit", 0)
                    item5_net_income = st.session_state.get("item5_net_income", 0)
                    item10_dep = st.session_state.get("item10_dep", 0)
                    item11_dep_exp = st.session_state.get("item11_dep_exp", 0)
                    item8_rent = st.session_state.get("item8_rent", 0)
                    item12_rent_exp = st.session_state.get("item12_rent_exp", 0)
                    item6_machine = st.session_state.get("item6_machine", 0)
                    item7_other = st.session_state.get("item7_other", 0)
                    net_assets = st.session_state.get("net_assets", 0)
                    total_assets = st.session_state.get("total_assets", 0)
                    bank_credit = st.session_state.get("bank_credit", 0)
                    lease_credit = st.session_state.get("lease_credit", 0)
                    contracts = st.session_state.get("contracts", 0)
                    lease_term = st.session_state.get("lease_term", 0)
                    acquisition_cost = st.session_state.get("acquisition_cost", 0)
                    acceptance_year = st.session_state.get("acceptance_year", 2026)
                
                    # å¤‰æ•°ã®å†ãƒãƒƒãƒ”ãƒ³ã‚° (None -> 0)
                    nenshu = nenshu if nenshu is not None else 0
                    item9_gross = item9_gross if item9_gross is not None else 0
                    rieki = rieki if rieki is not None else 0
                    item4_ord_profit = item4_ord_profit if item4_ord_profit is not None else 0
                    item5_net_income = item5_net_income if item5_net_income is not None else 0
                    item10_dep = item10_dep if item10_dep is not None else 0
                    item11_dep_exp = item11_dep_exp if item11_dep_exp is not None else 0
                    item8_rent = item8_rent if item8_rent is not None else 0
                    item12_rent_exp = item12_rent_exp if item12_rent_exp is not None else 0
                    item6_machine = item6_machine if item6_machine is not None else 0
                    item7_other = item7_other if item7_other is not None else 0
                    net_assets = net_assets if net_assets is not None else 0
                    total_assets = total_assets if total_assets is not None else 0
                    bank_credit = bank_credit if bank_credit is not None else 0
                    lease_credit = lease_credit if lease_credit is not None else 0
                    contracts = contracts if contracts is not None else 0
                    lease_term = lease_term if lease_term is not None else 0
                    acquisition_cost = acquisition_cost if acquisition_cost is not None else 0
    
                    # å¿…é ˆé …ç›®ãƒã‚§ãƒƒã‚¯ï¼ˆæœªå…¥åŠ›ãƒ»ä¸æ­£æ™‚ã¯åˆ¤å®šã‚’ãƒ–ãƒ­ãƒƒã‚¯ï¼‰
                    validation_ok = True
                    missing = []
                    for key, label, cond in REQUIRED_FIELDS:
                        val = locals().get(key)
                        if not cond(val):
                            missing.append(label)
                    if missing:
                        validation_ok = False
                        st.error(
                            f"**åˆ¤å®šã«ã¯æ¬¡ã®å¿…é ˆé …ç›®ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚**\n\n"
                            f"- ã€Œ{'ã€ã€Œ'.join(missing)}ã€ã¯ **1ä»¥ä¸Š** ã®å€¤ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚\n\n"
                            "å£²ä¸Šé«˜ã¯æ¯”ç‡è¨ˆç®—ã«ã€ç·è³‡ç”£ã¯è‡ªå·±è³‡æœ¬æ¯”ç‡ãƒ»å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã«å¿…è¦ã§ã™ã€‚"
                        )
                    
                    if validation_ok:
                        # æŒ‡æ¨™è¨ˆç®—
                        user_op_margin = (rieki / nenshu * 100) if nenshu > 0 else 0.0
                        user_equity_ratio = (net_assets / total_assets * 100) if total_assets > 0 else 0.0
                        # æµå‹•æ¯”ç‡ã®ç°¡æ˜“ç®—ï¼ˆæµå‹•è³‡ç”£â‰ˆç·è³‡ç”£âˆ’å›ºå®šè³‡ç”£ã€æµå‹•è² å‚µâ‰ˆè² å‚µç·é¡ï¼‰
                        liability_total = total_assets - net_assets if (total_assets and net_assets is not None) else 0
                        current_assets_approx = max(0, total_assets - item6_machine - item7_other)
                        user_current_ratio = (current_assets_approx / liability_total * 100) if liability_total > 0 else 100.0
            
                        bench = benchmarks_data.get(selected_sub, {})
                        bench_op_margin = bench.get("op_margin", 0.0)
                        bench_equity_ratio = _equity_ratio_display(bench.get("equity_ratio")) or 0.0
                        bench_comment = bench.get("comment", "")
            
                        comp_margin = "é«˜ã„" if user_op_margin >= bench_op_margin else "ä½ã„"
                        comp_equity = "é«˜ã„" if user_equity_ratio >= bench_equity_ratio else "ä½ã„"
            
                        comparison_text = f"""
                        - **å–¶æ¥­åˆ©ç›Šç‡**: {user_op_margin:.1f}% (æ¥­ç•Œç›®å®‰: {bench_op_margin}%) â†’ å¹³å‡ã‚ˆã‚Š{comp_margin}
                        - **è‡ªå·±è³‡æœ¬æ¯”ç‡**: {user_equity_ratio:.1f}% (æ¥­ç•Œç›®å®‰: {bench_equity_ratio}%) â†’ å¹³å‡ã‚ˆã‚Š{comp_equity}
                        - **æ¥­ç•Œç‰¹æ€§**: {bench_comment}
                        â€» **éŠ€è¡Œä¸ä¿¡ãƒ»ãƒªãƒ¼ã‚¹ä¸ä¿¡**ã¯ç·éŠ€è¡Œä¸ä¿¡ãƒ»ç·ãƒªãƒ¼ã‚¹ä¸ä¿¡ã§ã¯ãªãã€**å½“ç¤¾ï¼ˆå¼Šç¤¾ï¼‰ã®ä¸ä¿¡**ã§ã‚ã‚‹ã€‚åˆ¤å®šãƒ»ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã§ã¯ã“ã®ç‚¹ã‚’è¸ã¾ãˆã‚‹ã“ã¨ã€‚
                        """
            
                        my_hints = hints_data.get(selected_sub, {"subsidies": [], "risks": [], "mandatory": ""})
    
                        # è²¡å‹™ãƒ™ãƒ¼ã‚¹å€’ç”£ç¢ºç‡ã¨æ¥­ç•Œãƒªã‚¹ã‚¯æ¤œç´¢ï¼ˆåˆ¤å®šé–‹å§‹æ™‚ã«å®Ÿè¡Œï¼‰
                        pd_percent = calculate_pd(user_equity_ratio, user_current_ratio, user_op_margin)
                        try:
                            network_risk_summary = search_bankruptcy_trends(selected_sub)
                        except Exception as _e:
                            network_risk_summary = f"ï¼ˆæ¥­ç•Œãƒªã‚¹ã‚¯ã®å–å¾—ã§ã‚¨ãƒ©ãƒ¼: {_e}ã€‚åˆ¤å®šã¯ç¶šè¡Œã—ã¾ã™ã€‚ï¼‰"
    
                        # ==========================================================================
                        # ğŸ§® ã‚¹ã‚³ã‚¢è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯
                        # ==========================================================================
            
                        # ãƒ¢ãƒ‡ãƒ«è¨ˆç®—ç”¨ãƒ‡ãƒ¼ã‚¿ (å˜ä½èª¿æ•´ç‰ˆ)
                        data_scoring = {
                            # å¯¾æ•°é …ç”¨ (åƒå††å˜ä½ã®ã¾ã¾)
                            "nenshu": nenshu,             
                            "bank_credit": bank_credit,   
                            "lease_credit": lease_credit, 
                
                            # ç·šå½¢é …ç”¨ (ç™¾ä¸‡å††å˜ä½ã«å¤‰æ›) - ä¿‚æ•°ã®æ¡ã‹ã‚‰æ¨æ¸¬
                            "op_profit": rieki / 1000,
                            "ord_profit": item4_ord_profit / 1000,
                            "net_income": item5_net_income / 1000,
                            "gross_profit": item9_gross / 1000,
                            "machines": item6_machine / 1000,
                            "other_assets": item7_other / 1000,
                            "rent": item8_rent / 1000,
                            "depreciation": item10_dep / 1000,
                            "dep_expense": item11_dep_exp / 1000,
                            "rent_expense": item12_rent_exp / 1000,
                
                            # ãã®ä»–
                            "contracts": contracts,
                            "grade": grade,
                            "industry_major": selected_major,
                        }
            
                        # å®‰å…¨ãªã‚·ã‚°ãƒ¢ã‚¤ãƒ‰é–¢æ•° (ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼å¯¾ç­–)
                        def safe_sigmoid(x):
                            try:
                                # xãŒå¤§ãã™ãã‚‹ã€ã¾ãŸã¯å°ã•ã™ãã‚‹å ´åˆã®å¯¾ç­–
                                if x > 700: return 1.0
                                if x < -700: return 0.0
                                return 1 / (1 + math.exp(-x))
                            except OverflowError:
                                return 0.0 if x < 0 else 1.0
    
                        def calculate_score_from_coeffs(data, coeff_set):
                            z = coeff_set["intercept"]
                
                            # ãƒ€ãƒŸãƒ¼å¤‰æ•°ã®é©ç”¨ãƒ­ã‚¸ãƒƒã‚¯
                            major = data["industry_major"]
                            if "åŒ»ç™‚" in major or "ç¦ç¥‰" in major or major.startswith("P"):
                                z += coeff_set.get("ind_medical", 0)
                            elif "é‹è¼¸" in major or major.startswith("H"):
                                z += coeff_set.get("ind_transport", 0)
                            elif "å»ºè¨­" in major or major.startswith("D"):
                                z += coeff_set.get("ind_construction", 0)
                            elif "è£½é€ " in major or major.startswith("E"):
                                z += coeff_set.get("ind_manufacturing", 0)
                            elif "å¸å£²" in major or "å°å£²" in major or "ã‚µãƒ¼ãƒ“ã‚¹" in major or major[0] in ["I", "K", "M", "R"]:
                                 z += coeff_set.get("ind_service", 0)
                
                            # å¯¾æ•°é … (åƒå††å˜ä½ã®å€¤ã‚’å¯¾æ•°åŒ–)
                            if data["nenshu"] > 0: z += np.log1p(data["nenshu"]) * coeff_set.get("sales_log", 0)
                            if data["bank_credit"] > 0: z += np.log1p(data["bank_credit"]) * coeff_set.get("bank_credit_log", 0)
                            if data["lease_credit"] > 0: z += np.log1p(data["lease_credit"]) * coeff_set.get("lease_credit_log", 0)
                
                            # ç·šå½¢é … (æ—¢ã«ç™¾ä¸‡å††å˜ä½ã«å¤‰æ›æ¸ˆã¿ã®å€¤ã‚’ä½¿ç”¨)
                            z += data["op_profit"] * coeff_set.get("op_profit", 0)
                            z += data["ord_profit"] * coeff_set.get("ord_profit", 0)
                            z += data["net_income"] * coeff_set.get("net_income", 0)
                            z += data["machines"] * coeff_set.get("machines", 0)
                            z += data["other_assets"] * coeff_set.get("other_assets", 0)
                            z += data["rent"] * coeff_set.get("rent", 0)
                            z += data["gross_profit"] * coeff_set.get("gross_profit", 0)
                            z += data["depreciation"] * coeff_set.get("depreciation", 0)
                            z += data["dep_expense"] * coeff_set.get("dep_expense", 0)
                            z += data["rent_expense"] * coeff_set.get("rent_expense", 0)
                
                            if "4-6" in data["grade"]: z += coeff_set.get("grade_4_6", 0)
                            elif "è¦æ³¨æ„" in data["grade"]: z += coeff_set.get("grade_watch", 0)
                            elif "ç„¡æ ¼ä»˜" in data["grade"]: z += coeff_set.get("grade_none", 0)
                
                            z += data["contracts"] * coeff_set.get("contracts", 0)
                
                            # æŒ‡æ¨™ãƒ¢ãƒ‡ãƒ«ç”¨ã®è¿½åŠ å¤‰æ•° (æ¯”ç‡)
                            z += data.get("ratio_op_margin", 0) * coeff_set.get("ratio_op_margin", 0)
                            z += data.get("ratio_gross_margin", 0) * coeff_set.get("ratio_gross_margin", 0)
                            z += data.get("ratio_ord_margin", 0) * coeff_set.get("ratio_ord_margin", 0)
                            z += data.get("ratio_net_margin", 0) * coeff_set.get("ratio_net_margin", 0)
                            z += data.get("ratio_fixed_assets", 0) * coeff_set.get("ratio_fixed_assets", 0)
                            z += data.get("ratio_rent", 0) * coeff_set.get("ratio_rent", 0)
                            z += data.get("ratio_depreciation", 0) * coeff_set.get("ratio_depreciation", 0)
                            z += data.get("ratio_machines", 0) * coeff_set.get("ratio_machines", 0)
                
                            return z
    
                        # 1. å…¨ä½“ãƒ¢ãƒ‡ãƒ«ï¼ˆæˆç´„/å¤±æ³¨ã§æ›´æ–°ã—ãŸä¿‚æ•°ãŒã‚ã‚Œã°ãã‚Œã‚’å„ªå…ˆï¼‰
                        z_main = calculate_score_from_coeffs(data_scoring, get_effective_coeffs("å…¨ä½“_æ—¢å­˜å…ˆ"))
                        score_prob = safe_sigmoid(z_main)
                        score_percent = score_prob * 100
            
                        # 2. æŒ‡æ¨™ãƒ¢ãƒ‡ãƒ« (æ¯”ç‡è¨ˆç®—)
                        # ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ­ã‚¸ãƒƒã‚¯æ›´æ–° (CSVæŒ‡ç¤ºã«åŸºã¥ã)
                        # D, P, H -> å…¨ä½“(æŒ‡æ¨™)
                        # I, K, M, R -> ã‚µãƒ¼ãƒ“ã‚¹æ¥­(æŒ‡æ¨™)
                        # E -> è£½é€ æ¥­(æŒ‡æ¨™)
            
                        bench_key = "å…¨ä½“_æŒ‡æ¨™"
                        major_code_bench = selected_major.split(" ")[0]
            
                        if major_code_bench == "D":
                            bench_key = "å…¨ä½“_æŒ‡æ¨™"
                        elif major_code_bench == "P":
                            bench_key = "åŒ»ç™‚_æŒ‡æ¨™"
                        elif major_code_bench == "H":
                            bench_key = "é‹é€æ¥­_æŒ‡æ¨™"
                        elif major_code_bench in ["I", "K", "M", "R"]:
                            bench_key = "ã‚µãƒ¼ãƒ“ã‚¹æ¥­_æŒ‡æ¨™"
                        elif major_code_bench == "E":
                            bench_key = "è£½é€ æ¥­_æŒ‡æ¨™"
                
                        ratio_data = data_scoring.copy()
            
                        # æ¯”ç‡è¨ˆç®—ã®ãŸã‚ã«å…ƒã®åƒå††å˜ä½ã®å€¤ã‚’ä½¿ã†
                        raw_nenshu = nenshu if nenshu > 0 else 1.0
            
                        raw_op = rieki if rieki is not None else 0
                        raw_gross = item9_gross if item9_gross is not None else 0
                        raw_ord = item4_ord_profit if item4_ord_profit is not None else 0
                        raw_net = item5_net_income if item5_net_income is not None else 0
                        raw_fixed = (item6_machine if item6_machine is not None else 0) + (item7_other if item7_other is not None else 0)
                        raw_rent = item12_rent_exp if item12_rent_exp is not None else 0
                        raw_dep = (item10_dep if item10_dep is not None else 0) + (item11_dep_exp if item11_dep_exp is not None else 0)
                        raw_machines = item6_machine if item6_machine is not None else 0
            
                        ratio_data["ratio_op_margin"] = raw_op / raw_nenshu
                        ratio_data["ratio_gross_margin"] = raw_gross / raw_nenshu
                        ratio_data["ratio_ord_margin"] = raw_ord / raw_nenshu
                        ratio_data["ratio_net_margin"] = raw_net / raw_nenshu
                        ratio_data["ratio_fixed_assets"] = raw_fixed / raw_nenshu
                        ratio_data["ratio_rent"] = raw_rent / raw_nenshu
                        ratio_data["ratio_depreciation"] = raw_dep / raw_nenshu
                        ratio_data["ratio_machines"] = raw_machines / raw_nenshu
            
                        # æŒ‡æ¨™ãƒ¢ãƒ‡ãƒ«è¨ˆç®—ï¼ˆæ—¢å­˜å…ˆ/æ–°è¦å…ˆã§æ›´æ–°ä¿‚æ•°ãŒã‚ã‚Œã°ä½¿ç”¨ï¼‰
                        bench_key_with_type = f"{bench_key}_{'æ–°è¦å…ˆ' if customer_type == 'æ–°è¦å…ˆ' else 'æ—¢å­˜å…ˆ'}"
                        bench_coeffs = get_effective_coeffs(bench_key_with_type)
                        z_bench = calculate_score_from_coeffs(ratio_data, bench_coeffs)
                        score_prob_bench = safe_sigmoid(z_bench)
                        score_percent_bench = score_prob_bench * 100
            
                        # 3. æ¥­ç¨®åˆ¥ãƒ¢ãƒ‡ãƒ« (åˆ†é¡ãƒ­ã‚¸ãƒƒã‚¯ã®ä¿®æ­£)
                        ind_key = "å…¨ä½“_æ—¢å­˜å…ˆ" # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
            
                        major_code = selected_major.split(" ")[0] # "D å»ºè¨­æ¥­" -> "D"
            
                        # CSVå®šç¾©ã«åŸºã¥ããƒãƒƒãƒ”ãƒ³ã‚°
                        # H -> é‹é€æ¥­
                        # I, K, M, R -> ã‚µãƒ¼ãƒ“ã‚¹æ¥­
                        # E -> è£½é€ æ¥­
                        # D, P -> å…¨ä½“ãƒ¢ãƒ‡ãƒ« (æ—¢å­˜oræ–°è¦)
            
                        if major_code == "H":
                            ind_key = "é‹é€æ¥­_æ—¢å­˜å…ˆ"
                        elif major_code == "P":
                            ind_key = "åŒ»ç™‚_æ—¢å­˜å…ˆ"
                        elif major_code in ["I", "K", "M", "R"]:
                            ind_key = "ã‚µãƒ¼ãƒ“ã‚¹æ¥­_æ—¢å­˜å…ˆ"
                        elif major_code == "E":
                            ind_key = "è£½é€ æ¥­_æ—¢å­˜å…ˆ"
                        elif major_code == "D":
                            ind_key = "å…¨ä½“_æ—¢å­˜å…ˆ"
            
                        # æ–°è¦å…ˆã®å ´åˆã®åˆ‡ã‚Šæ›¿ãˆ
                        if customer_type == "æ–°è¦å…ˆ":
                            ind_key = ind_key.replace("æ—¢å­˜å…ˆ", "æ–°è¦å…ˆ")
                            # ä¸‡ãŒä¸€ã‚­ãƒ¼ãŒãªã„å ´åˆã¯å…¨ä½“_æ–°è¦å…ˆã¸ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                            if ind_key not in COEFFS: ind_key = "å…¨ä½“_æ–°è¦å…ˆ"
            
                        ind_coeffs = get_effective_coeffs(ind_key)
                        z_ind = calculate_score_from_coeffs(data_scoring, ind_coeffs)
                        score_prob_ind = safe_sigmoid(z_ind)
                        score_percent_ind = score_prob_ind * 100
            
                        gap_val = score_percent - score_percent_bench
                        gap_sign = "+" if gap_val >= 0 else ""
                        gap_text = f"æŒ‡æ¨™ãƒ¢ãƒ‡ãƒ«å·®: {gap_sign}{gap_val:.1f}%"
    
                        # ========== å®Œå…¨ç‰ˆãƒ™ã‚¤ã‚ºåˆæœŸãƒ¢ãƒ‡ãƒ«: ç¶™æ‰¿ï¼‹è£œå®Œï¼ˆå›å¸°ã§æ›´æ–°ã—ãŸä¿‚æ•°ã‚‚åæ˜ ï¼‰ ==========
                        effective = get_effective_coeffs()  # æˆç´„/å¤±æ³¨ã§æ›´æ–°ã—ãŸä¿‚æ•°ï¼ˆæ—¢å­˜+è¿½åŠ é …ç›®ï¼‰ãŒã‚ã‚Œã°ä½¿ç”¨
                        # é€†è»¢ã®éµã¯å‰Šé™¤æ¸ˆã¿ï¼ˆå®šæ€§ã¯å®šæ€§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã®ã¿ï¼‰
                        strength_tags = []
                        passion_text = ""
                        n_strength = 0
                        contract_prob = score_percent
                        ai_completed_factors = []  # AIãŒè£œå®Œã—ãŸåˆ¤å®šè¦å› ï¼ˆè¡¨ç¤ºãƒ»ãƒãƒˆãƒ«ç”¨ï¼‰
    
                        # ãƒ¡ã‚¤ãƒ³å…ˆï¼ˆä¿‚æ•°: æˆç´„/å¤±æ³¨ã§å›å¸°æ›´æ–°ã•ã‚Œã¦ã„ã‚Œã°ãã®å€¤ã€ãªã‘ã‚Œã°æ—¢å®š5ï¼‰
                        # â€» ä¿‚æ•°åˆ†æãƒ»æ›´æ–°ãƒ¢ãƒ¼ãƒ‰ã§å›å¸°åˆ†æã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€æˆç´„/å¤±æ³¨ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è‡ªå‹•çš„ã«ä¿‚æ•°ãŒå†è¨ˆç®—ã•ã‚Œã¾ã™
                        main_bank_eff = effective.get("main_bank", 5)
                        if main_bank == "ãƒ¡ã‚¤ãƒ³å…ˆ":
                            contract_prob += main_bank_eff
                            ai_completed_factors.append({"factor": "ãƒ¡ã‚¤ãƒ³å–å¼•å…ˆ", "effect_percent": int(round(main_bank_eff)), "detail": "å–å¼•è¡Œã¨ã—ã¦å„ªä½"})
    
                        # ç«¶åˆ: ç«¶åˆã‚ã‚Š=è² ã®ä¿‚æ•°ã€ç«¶åˆãªã—=ãƒ—ãƒ©ã‚¹ï¼ˆæˆç´„/å¤±æ³¨ã§å›å¸°æ›´æ–°ã•ã‚Œã¦ã„ã‚Œã°ãã®å€¤ã€ãªã‘ã‚Œã°æ—¢å®šï¼‰
                        # â€» ä¿‚æ•°åˆ†æãƒ»æ›´æ–°ãƒ¢ãƒ¼ãƒ‰ã§å›å¸°åˆ†æã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€æˆç´„/å¤±æ³¨ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è‡ªå‹•çš„ã«ä¿‚æ•°ãŒå†è¨ˆç®—ã•ã‚Œã¾ã™
                        comp_present_eff = effective.get("competitor_present", BAYESIAN_PRIOR_EXTRA["competitor_present"])
                        comp_none_eff = effective.get("competitor_none", 5)
                        comp_effect = comp_present_eff if competitor == "ç«¶åˆã‚ã‚Š" else comp_none_eff
                        contract_prob += comp_effect
                        if competitor == "ç«¶åˆã‚ã‚Š":
                            ai_completed_factors.append({"factor": "ç«¶åˆä»–ç¤¾ã®å­˜åœ¨", "effect_percent": int(round(comp_effect)), "detail": "ä»–ç¤¾ãŒã„ã‚‹å ´åˆã¯æˆç´„ç‡ã‚’ä¸‹ã’ã‚‹è£œæ­£"})
                        else:
                            ai_completed_factors.append({"factor": "ç«¶åˆãªã—", "effect_percent": int(round(comp_effect)), "detail": "ç«¶åˆå„ªä½ã§æˆç´„ç‡ã‚’ä¸Šã’ã‚‹è£œæ­£"})
    
                        # æ¥­ç•Œæ™¯æ°—å‹•å‘: ZåŒ–ï¼ˆ-1,0,1ï¼‰ã€‚ä¿‚æ•°ã¯æ›´æ–°å€¤ or æ—¢å®š
                        _summary = (network_risk_summary or "").lower()
                        if "æ™¯æ°—" in _summary or "å¥½èª¿" in _summary or "æ‹¡å¤§" in _summary or "å …èª¿" in _summary:
                            industry_z = 1.0
                            ind_label = "æ¥­ç•Œå‹•å‘ï¼ˆãƒã‚¸ãƒ†ã‚£ãƒ–ï¼‰"
                        elif "å€’ç”£" in _summary or "æ¸›å°‘" in _summary or "æ‚ªåŒ–" in _summary or "æ‡¸å¿µ" in _summary or "ä½ä¸‹" in _summary:
                            industry_z = -1.0
                            ind_label = "æ¥­ç•Œå‹•å‘ï¼ˆãƒã‚¬ãƒ†ã‚£ãƒ–ï¼‰"
                        else:
                            industry_z = 0.0
                            ind_label = "æ¥­ç•Œå‹•å‘ï¼ˆä¸­ç«‹ï¼‰"
                        ind_coef = effective.get("industry_sentiment_z", BAYESIAN_PRIOR_EXTRA["industry_sentiment_per_z"])
                        ind_effect = ind_coef * industry_z
                        contract_prob += ind_effect
                        if industry_z != 0:
                            ai_completed_factors.append({"factor": ind_label, "effect_percent": int(round(ind_effect)), "detail": "æ¥­ç•Œã®æ™¯æ°—å‹•å‘ã‚’æˆç´„ç‡ã«åæ˜ "})
    
                        # é‡‘åˆ©å·®ã¯ y_pred_adjusted ç®—å‡ºå¾Œã«è¿½åŠ 

                        # å®šæ€§ã‚¹ã‚³ã‚¢: ã‚¿ã‚°ã‚¹ã‚³ã‚¢(0-10)ã¨ç†±æ„(0/1)ã€‚ä¿‚æ•°ã¯ã€Œ1ãƒã‚¤ãƒ³ãƒˆã‚ãŸã‚Šã€ã€Œç†±æ„ã‚ã‚Šã§ã€ã®åŠ¹æœï¼ˆæ›´æ–°å€¤ or æ—¢å®šï¼‰
                        tag_score = min(sum(STRENGTH_TAG_WEIGHTS.get(t, DEFAULT_STRENGTH_WEIGHT) for t in strength_tags), 10)
                        tag_coef = effective.get("qualitative_tag_score", 2.0)   # 1ptã‚ãŸã‚Š%åŠ¹æœ
                        passion_coef = effective.get("qualitative_passion", BAYESIAN_PRIOR_EXTRA["qualitative_passion_bonus"])
                        tag_effect = tag_coef * tag_score
                        passion_effect = passion_coef if passion_text else 0
                        contract_prob += tag_effect + passion_effect
                        if n_strength > 0:
                            ai_completed_factors.append({"factor": "å®šæ€§ã‚¹ã‚³ã‚¢ï¼ˆå¼·ã¿ã‚¿ã‚°ï¼‰", "effect_percent": int(round(tag_effect)), "detail": f"ç‰¹è¨±ãƒ»äººè„ˆç­‰{n_strength}ä»¶ã‚’æ¨™æº–é‡ã¿ã§åŠ ç‚¹"})
                        if passion_effect > 0:
                            ai_completed_factors.append({"factor": "ç†±æ„ãƒ»è£äº‹æƒ…ã®è¨˜è¿°", "effect_percent": int(round(passion_effect)), "detail": "è¨˜è¿°ã‚ã‚Šã§åŠ ç‚¹"})
    
                        # è‡ªå·±è³‡æœ¬æ¯”ç‡ï¼ˆè¿½åŠ é …ç›®ï¼‰: ä¿‚æ•°ã¯ã€Œ1%ã‚ãŸã‚Šã€ã®åŠ¹æœï¼ˆæ›´æ–°å€¤ or 0ï¼‰
                        equity_coef = effective.get("equity_ratio", 0)
                        equity_effect = equity_coef * user_equity_ratio
                        contract_prob += equity_effect
                        if abs(equity_effect) >= 0.5:
                            ai_completed_factors.append({"factor": "è‡ªå·±è³‡æœ¬æ¯”ç‡", "effect_percent": int(round(equity_effect)), "detail": f"è‡ªå·±è³‡æœ¬æ¯”ç‡ {user_equity_ratio:.1f}% ã‚’åæ˜ "})
    
                        contract_prob = max(0, min(100, contract_prob))
    
                        # åˆ©å›ã‚Šäºˆæ¸¬è¨ˆç®— (ç°¡ç•¥åŒ–)
                        YIELD_COEFFS = {
                            "intercept": -132.213, "item10_dep": -5.2e-07, "item11_dep_exp": -5.9e-07,
                            "item12_rent_exp": -3.3e-07, "grade_1_3": 0.103051, "grade_4_6": 0.115129,
                            "grade_watch": 0.309849, "grade_none": 0.25737, "type_general": 0.032238,
                            "source_bank": 0.062498, "nenshu_log": -0.03134, "bank_credit_log": -0.00841,
                            "lease_credit_log": -0.02849, "term_log": -0.63635, "year": 0.067637,
                            "cost_log": -0.3945, "contracts_log": 0.130446
                        }
            
                        # åˆ©å›ã‚Šäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã«ã¯ã€Œåƒå††å˜ä½ã®ç”Ÿã®æ•°å­—ã€ã‚’ä½¿ã† (ç”»åƒã®ä¾‹ã«å¾“ã†)
                        # ãŸã ã—ã€å¯¾æ•°é …ã¯ log1p(åƒå††) ã‚’ä½¿ç”¨
                        y_pred = YIELD_COEFFS["intercept"]
                        y_pred += item10_dep * YIELD_COEFFS["item10_dep"]
                        y_pred += item11_dep_exp * YIELD_COEFFS["item11_dep_exp"]
                        y_pred += item12_rent_exp * YIELD_COEFFS["item12_rent_exp"]
            
                        if "1-3" in grade: y_pred += YIELD_COEFFS["grade_1_3"]
                        elif "4-6" in grade: y_pred += YIELD_COEFFS["grade_4_6"]
                        elif "è¦æ³¨æ„" in grade: y_pred += YIELD_COEFFS["grade_watch"]
                        elif "ç„¡æ ¼ä»˜" in grade: y_pred += YIELD_COEFFS["grade_none"]
            
                        if contract_type == "ä¸€èˆ¬": y_pred += YIELD_COEFFS["type_general"]
                        if deal_source == "éŠ€è¡Œç´¹ä»‹": y_pred += YIELD_COEFFS["source_bank"]
            
                        if nenshu > 0: y_pred += np.log1p(nenshu) * YIELD_COEFFS["nenshu_log"]
                        if bank_credit > 0: y_pred += np.log1p(bank_credit) * YIELD_COEFFS["bank_credit_log"]
                        if lease_credit > 0: y_pred += np.log1p(lease_credit) * YIELD_COEFFS["lease_credit_log"]
                        if lease_term > 0: y_pred += np.log1p(lease_term) * YIELD_COEFFS["term_log"]
                        if contracts > 0: y_pred += np.log1p(contracts) * YIELD_COEFFS["contracts_log"]
            
                        val_cost_log = np.log1p(acquisition_cost) if acquisition_cost > 0 else 0
                        y_pred += val_cost_log * YIELD_COEFFS["cost_log"]
                        y_pred += acceptance_year * YIELD_COEFFS["year"]
            
                        # é‡‘åˆ©ç’°å¢ƒè£œæ­£
                        BASE_DATE = "2025-03"
                        term_years = lease_term / 12
                        base_market_rate = get_market_rate(BASE_DATE, term_years)
                        today_str = datetime.date.today().strftime("%Y-%m")
                        current_market_rate = get_market_rate(today_str, term_years)
                        rate_diff = current_market_rate - base_market_rate
                        y_pred_adjusted = y_pred + rate_diff

                        # é‡‘åˆ©å·®ï¼ˆç«¶åˆæ¯”ï¼‰: ä¿‚æ•°ã¯æ›´æ–°å€¤ or æ—¢å®š
                        competitor_rate_val = st.session_state.get("competitor_rate")
                        if competitor_rate_val is not None and isinstance(competitor_rate_val, (int, float)):
                            rate_diff_pt = float(y_pred_adjusted) - float(competitor_rate_val)
                            rate_z = max(-2, min(2, rate_diff_pt / 5.0))
                            rate_coef = effective.get("rate_diff_z", BAYESIAN_PRIOR_EXTRA["rate_diff_per_z"])
                            rate_effect = rate_coef * (-rate_z)
                            contract_prob += rate_effect
                            ai_completed_factors.append({"factor": "é‡‘åˆ©å·®ï¼ˆç«¶åˆæ¯”ï¼‰", "effect_percent": int(round(rate_effect)), "detail": f"è‡ªç¤¾ãŒç«¶åˆã‚ˆã‚Š{'æœ‰åˆ©' if rate_diff_pt < 0 else 'ä¸åˆ©'}ãªé‡‘åˆ©"})
                        contract_prob = max(0, min(100, contract_prob))

                        # å€Ÿæ‰‹ã‚¹ã‚³ã‚¢ + ç‰©ä»¶ã‚¹ã‚³ã‚¢ â†’ ç·åˆã‚¹ã‚³ã‚¢ï¼ˆåˆ¤å®šã«åæ˜ ï¼‰ã€‚é‡ã¿ã¯å›å¸°æœ€é©åŒ–ã§å¤‰æ›´å¯èƒ½ã€‚
                        w_borrower, w_asset, w_quant, w_qual = get_score_weights()
                        final_score = w_borrower * score_percent + w_asset * asset_score
                        st.session_state['current_image'] = "approve" if final_score >= APPROVAL_LINE else "challenge"
                
                        # [å‰Šé™¤] AIã‚¢ãƒ‰ãƒã‚¤ã‚¹ (1å›ç›®: å…¥åŠ›ã‚¿ãƒ–å´)
                        # ã“ã“ã«ã‚ã£ãŸ ai_question ç”Ÿæˆã¨ messages è¿½åŠ ãƒ­ã‚¸ãƒƒã‚¯ã¯å‰Šé™¤ã—ã€
                        # åˆ†æçµæœã‚¿ãƒ–ã§ã®ã¿å‚ç…§ã™ã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚
                        # ãŸã ã—ã€è£ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã ã‘ã¯ã—ã¦ãŠãå¿…è¦ãŒã‚ã‚‹ãŸã‚ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã¸ã®ä¿å­˜ã¯æ®‹ã—ã¾ã™ã€‚
    
                        # éå»ã®é¡ä¼¼æ¡ˆä»¶ï¼ˆåŒæ¥­ç•Œãƒ»è‡ªå·±è³‡æœ¬æ¯”ç‡ãŒè¿‘ã„ï¼‰ã‚’æœ€å¤§3ä»¶å–å¾—
                        similar_cases = find_similar_past_cases(selected_sub, user_equity_ratio, max_count=3)
                        similar_cases_block = ""
                        if similar_cases:
                            similar_cases_block = "ã€å‚è€ƒï¼šéå»ã®é¡ä¼¼æ¡ˆä»¶ã®çµæœ«ã€‘\n"
                            for i, sc in enumerate(similar_cases, 1):
                                res = sc.get("result") or {}
                                eq = res.get("user_eq")
                                sc_score = res.get("score")
                                status = sc.get("final_status", "æœªç™»éŒ²")
                                eq_str = f"{_equity_ratio_display(eq) or 0:.1f}%" if eq is not None else "â€”"
                                score_str = f"{sc_score:.1f}%" if sc_score is not None else "â€”"
                                similar_cases_block += f"{i}. æ¥­ç•Œ: {sc.get('industry_sub', 'â€”')}ã€è‡ªå·±è³‡æœ¬æ¯”ç‡: {eq_str}ã€ã‚¹ã‚³ã‚¢: {score_str}ã€çµæœ«: {status}\n"
                            similar_cases_block += "\n"
                        instruction_past = "éå»ã«ä¼¼ãŸæ•°å€¤ã§æ‰¿èªã•ã‚ŒãŸï¼ˆã¾ãŸã¯å¦æ±ºã•ã‚ŒãŸï¼‰äº‹ä¾‹ã‚’å‚è€ƒã«ã—ã€ä»Šå›ã®æ¡ˆä»¶ã¨ã®å…±é€šç‚¹ã‚„ç›¸é•ç‚¹ã‚’è¸ã¾ãˆã¦ã€ã‚ˆã‚Šç²¾åº¦ã®é«˜ã„æœ€çµ‚åˆ¤å®šã‚’å‡ºã—ã¦ãã ã•ã„ã€‚\n\n"
    
                        ai_question_text = ""
                        if similar_cases_block:
                            ai_question_text += similar_cases_block + instruction_past
                        # éå»ã®ç«¶åˆãƒ»æˆç´„é‡‘åˆ©ã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦è¿½åŠ ï¼ˆç«¶åˆã«å‹ã¤å¯¾ç­–ã‚’AIã«ä¿ƒã™ï¼‰
                        past_stats = get_stats(selected_sub)
                        if past_stats.get("top_competitors_lost") or (past_stats.get("avg_winning_rate") is not None and past_stats["avg_winning_rate"] > 0):
                            ai_question_text += "ã€éå»ã®ç«¶åˆãƒ»æˆç´„é‡‘åˆ©ã€‘\n"
                            if past_stats.get("top_competitors_lost"):
                                ai_question_text += "ã‚ˆãè² ã‘ã‚‹ç«¶åˆ: " + "ã€".join(past_stats["top_competitors_lost"][:5]) + "ã€‚\n"
                            if past_stats.get("avg_winning_rate") and past_stats["avg_winning_rate"] > 0:
                                ai_question_text += f"åŒæ¥­ç¨®ã®å¹³å‡æˆç´„é‡‘åˆ©: {past_stats['avg_winning_rate']:.2f}%ã€‚\n"
                            ai_question_text += "ä¸Šè¨˜ã‚’è¸ã¾ãˆã€ç«¶åˆã«å‹ã¤ãŸã‚ã®å¯¾ç­–ã‚‚è€ƒæ…®ã—ã¦ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã—ã¦ãã ã•ã„ã€‚\n\n"
                        ai_question_text += "å¯©æŸ»ãŠç–²ã‚Œæ§˜ã§ã™ã€‚æ‰‹å…ƒã®æ±ºç®—æ›¸ã‹ã‚‰ã€ä»¥ä¸‹ã®**3ç‚¹ã ã‘**ç¢ºèªã•ã›ã¦ãã ã•ã„ã€‚\n\n"
                        questions = []
                        if my_hints.get("mandatory"): questions.append(f"ğŸ­ **æ¥­ç•Œç¢ºèª**: {my_hints['mandatory']}")
                        if score_percent < 70: questions.append("ğŸ’¡ **å®Ÿè³ªåˆ©ç›Š**: è²©ç®¡è²»ã®å†…è¨³ã«ã€Œå½¹å“¡å ±é…¬ã€ã¯ååˆ†è¨ˆä¸Šã•ã‚Œã¦ã„ã¾ã™ã‹ï¼Ÿ")
                        elif user_op_margin < bench_op_margin: questions.append("ğŸ“‰ **åˆ©ç›Šç‡è¦å› **: ä»ŠæœŸã®åˆ©ç›Šç‡ä½ä¸‹ã¯ã€ä¸€éæ€§ã§ã™ã‹ï¼Ÿ")
                        if score_percent < 70: questions.append("ğŸ¦ **è³‡é‡‘ç¹°ã‚Š**: å€Ÿå…¥é‡‘æ˜ç´°è¡¨ã§ã€è¿”æ¸ˆãŒã€Œç´„å®šé€šã‚Šã€é€²ã‚“ã§ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                        if my_hints["risks"]: questions.append(f"âš ï¸ **æ¥­ç•Œãƒªã‚¹ã‚¯**: {my_hints['risks'][0]} ã¯ã‚¯ãƒªã‚¢ã—ã¦ã„ã¾ã™ã‹ï¼Ÿ")
                
                        for q in questions[:3]: ai_question_text += f"- {q}\n"
                        ai_question_text += "\nã“ã‚Œã‚‰ãŒã‚¯ãƒªã‚¢ã«ãªã‚Œã°ã€æ‰¿èªç¢ºç‡80%ä»¥ä¸ŠãŒè¦‹è¾¼ã‚ã¾ã™ã€‚"
                        ai_question_text += f"\n\næ¥­ç•Œã®æœ€æ–°ãƒªã‚¹ã‚¯æƒ…å ±ã‚‚å‚ç…§æ¸ˆã¿ã§ã™ã€‚ã“ã‚Œã‚‰ã‚’ç·åˆã—ã¦æœ€çµ‚çš„ãªãƒªã‚¹ã‚¯ã¨æ‰¿èªå¯å¦ã‚’åˆ¤æ–­ã—ã¦ãã ã•ã„ã€‚"
    
                        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã«è¿½åŠ  (è¡¨ç¤ºã¯åˆ†æã‚¿ãƒ–ã®ãƒãƒ£ãƒƒãƒˆæ¬„ã§è¡Œã†)
                        st.session_state.messages = [{"role": "assistant", "content": ai_question_text}]
                        st.session_state.debate_history = [] 
    
                        # è­°è«–çµ‚äº†ãƒ»åˆ¤å®šãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”¨ã«é¡ä¼¼æ¡ˆä»¶ãƒ–ãƒ­ãƒƒã‚¯ã‚’ä¿æŒ
                        similar_past_for_prompt = (similar_cases_block + instruction_past) if similar_cases_block else ""
    
                        # å®šæ€§ãƒ¯ãƒ³ãƒ›ãƒƒãƒˆï¼ˆéå»ãƒ‡ãƒ¼ã‚¿ãƒ»RAGç”¨ï¼‰
                        qualitative_onehot = {tag: 1 for tag in STRENGTH_TAG_OPTIONS if tag in strength_tags}
                        qualitative_onehot.update({tag: 0 for tag in STRENGTH_TAG_OPTIONS if tag not in strength_tags})

                        # å®šæ€§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã®é›†è¨ˆï¼ˆç·åˆÃ—60%ï¼‹å®šæ€§Ã—40%ã§ãƒ©ãƒ³ã‚¯Aã€œEï¼‰
                        qual_correction_items = {}
                        qual_weight_sum = 0
                        qual_weighted_total = 0.0
                        for item in QUALITATIVE_SCORING_CORRECTION_ITEMS:
                            idx = st.session_state.get(f"qual_corr_{item['id']}", 0)
                            opts = item.get("options") or QUALITATIVE_SCORING_LEVELS
                            val = opts[idx - 1][0] if 1 <= idx <= len(opts) else None
                            level_label = opts[idx - 1][1] if 1 <= idx <= len(opts) else None
                            qual_correction_items[item["id"]] = {
                                "value": val,
                                "label": item["label"],
                                "weight": item["weight"],
                                "level_label": level_label,
                            }
                            if val is not None:
                                qual_weight_sum += item["weight"]
                                qual_weighted_total += (val / 4.0) * 100 * (item["weight"] / 100.0)
                        qual_weighted_score = round((qual_weighted_total / qual_weight_sum * 100) if qual_weight_sum > 0 else 0)
                        qual_weighted_score = min(100, max(0, qual_weighted_score))
                        # ãƒ©ãƒ³ã‚¯Aã€œEã¯ç·åˆÃ—é‡ã¿ï¼‹å®šæ€§Ã—é‡ã¿ã«åŸºã¥ãï¼ˆé‡ã¿ã¯å›å¸°æœ€é©åŒ–ã§å¤‰æ›´å¯èƒ½ï¼‰
                        combined_score = round(final_score * w_quant + qual_weighted_score * w_qual)
                        combined_score = min(100, max(0, combined_score))
                        qual_rank = next((r for r in QUALITATIVE_SCORE_RANKS if combined_score >= r["min"]), QUALITATIVE_SCORE_RANKS[-1])
                        qualitative_scoring_correction = None
                        if qual_weight_sum > 0:
                            qualitative_scoring_correction = {
                                "items": qual_correction_items,
                                "weighted_score": qual_weighted_score,
                                "combined_score": combined_score,
                                "rank": qual_rank["label"],
                                "rank_text": qual_rank["text"],
                                "rank_desc": qual_rank["desc"],
                            }

                        # å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ï¼ˆæ¥­ç¨®åˆ¥ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ï¼‰ã®äºˆæ¸¬ï¼ˆç·è³‡ç”£ãƒ»ç´”è³‡ç”£ãŒå…¥åŠ›ã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿ï¼‰
                        scoring_result = None
                        if (total_assets or 0) > 0 and (net_assets is not None) and (net_assets >= 0):
                            try:
                                _scoring_dir = os.path.join(_SCRIPT_DIR, "scoring")
                                if _scoring_dir not in sys.path:
                                    sys.path.insert(0, _SCRIPT_DIR)
                                from scoring.predict_one import predict_one, map_industry_major_to_scoring
                                _base = os.environ.get("LEASE_SCORING_MODELS_DIR", os.path.join(_SCRIPT_DIR, "scoring", "models", "industry_specific"))
                                _industry = map_industry_major_to_scoring(selected_major)
                                scoring_result = predict_one(
                                    revenue=(nenshu or 0) * 1000,
                                    total_assets=(total_assets or 0) * 1000,
                                    equity=(net_assets or 0) * 1000,
                                    operating_profit=(rieki or 0) * 1000,
                                    net_income=(item5_net_income or 0) * 1000,
                                    machinery_equipment=(item6_machine or 0) * 1000,
                                    other_fixed_assets=(item7_other or 0) * 1000,
                                    depreciation=((item10_dep or 0) + (item11_dep_exp or 0)) * 1000,
                                    rent_expense=(item12_rent_exp or 0) * 1000,
                                    industry=_industry,
                                    base_path=_base,
                                )
                            except Exception:
                                scoring_result = None

                        # å­¦ç¿’ãƒ¢ãƒ‡ãƒ«åˆ¤å®šãŒã€Œå¦æ±ºã€ã®ã¨ãã¯ã™ã¹ã¦ã®ã‚¹ã‚³ã‚¢ã‚’50%æ¸›
                        if scoring_result and (scoring_result.get("decision") or "").strip() == "å¦æ±º":
                            final_score = final_score * SCORE_PENALTY_IF_LEARNING_REJECT
                            contract_prob = contract_prob * SCORE_PENALTY_IF_LEARNING_REJECT
                            score_percent = score_percent * SCORE_PENALTY_IF_LEARNING_REJECT
                            score_percent_bench = (score_percent_bench or 0) * SCORE_PENALTY_IF_LEARNING_REJECT
                            score_percent_ind = (score_percent_ind or 0) * SCORE_PENALTY_IF_LEARNING_REJECT
                            # å®šæ€§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã®åˆè¨ˆãƒ»ãƒ©ãƒ³ã‚¯ã‚‚å¦æ±ºå¾Œã®ç·åˆã§å†è¨ˆç®—
                            if qualitative_scoring_correction:
                                combined_score = round(final_score * w_quant + qual_weighted_score * w_qual)
                                combined_score = min(100, max(0, combined_score))
                                qual_rank = next((r for r in QUALITATIVE_SCORE_RANKS if combined_score >= r["min"]), QUALITATIVE_SCORE_RANKS[-1])
                                qualitative_scoring_correction["combined_score"] = combined_score
                                qualitative_scoring_correction["rank"] = qual_rank["label"]
                                qualitative_scoring_correction["rank_text"] = qual_rank["text"]
                                qualitative_scoring_correction["rank_desc"] = qual_rank["desc"]

                        st.session_state['last_result'] = {
                            "score": final_score, "hantei": "æ‰¿èªåœå†…" if final_score >= APPROVAL_LINE else "è¦å¯©è­°",
                            "score_borrower": score_percent, "asset_score": asset_score, "asset_name": asset_name,
                            "contract_prob": contract_prob, "z": z_main,
                            "ai_completed_factors": ai_completed_factors,
                            "comparison": comparison_text,
                            "user_op": user_op_margin, "bench_op": bench_op_margin,
                            "user_eq": user_equity_ratio, "bench_eq": bench_equity_ratio,
                            "hints": my_hints,
                            "pd_percent": pd_percent,
                            "network_risk_summary": network_risk_summary,
                            "similar_past_cases_prompt": similar_past_for_prompt,
                            "strength_tags": strength_tags,
                            "passion_text": passion_text,
                            "qualitative_onehot": qualitative_onehot,
                            "scoring_result": scoring_result,
                            "qualitative_scoring_correction": qualitative_scoring_correction,
                            "financials": {
                                "nenshu": nenshu,
                                "rieki": rieki,
                                "assets": total_assets,
                                "net_assets": net_assets,
                                "gross_profit": item9_gross,
                                "op_profit": rieki,
                                "ord_profit": item4_ord_profit,
                                "net_income": item5_net_income,
                                "machines": item6_machine,
                                "other_assets": item7_other,
                                "bank_credit": bank_credit,
                                "lease_credit": lease_credit,
                                "depreciation": item10_dep,
                            },
                            "yield_pred": y_pred_adjusted, "yield_base": y_pred, "rate_diff": rate_diff,
                            "gap_text": gap_text, "bench_score": score_percent_bench,
                            "ind_score": score_percent_ind, "ind_name": ind_key,
                            "industry_major": selected_major,
                            "industry_sub": selected_sub,
                            "industry_sentiment_z": industry_z,
                        }
                
                        # å¯©æŸ»å§”å“¡ä¼šã‚«ãƒ¼ãƒ‰ãƒãƒˆãƒ«ç”¨ãƒ‡ãƒ¼ã‚¿ï¼ˆåˆ†æã‚¿ãƒ–ã§è¡¨ç¤ºï¼‰
                        hp_card = int(min(999, max(1, net_assets / 1000))) if net_assets else int(min(999, max(1, user_equity_ratio * 5)))
                        atk_card = int(min(99, max(1, user_op_margin * 2)))
                        spd_card = int(min(99, max(1, user_current_ratio / 2)))
                        is_approved = final_score >= APPROVAL_LINE
                        # è£œå®Œè¦å› ã‚’ã‚¹ã‚­ãƒ«ãƒ»ç’°å¢ƒåŠ¹æœã¨ã—ã¦ãƒãƒˆãƒ«ã«æ¸¡ã™
                        env_effects = [f"{f['factor']}: {f['effect_percent']:+.0f}%" for f in ai_completed_factors]
                        st.session_state["battle_data"] = {
                            "hp": hp_card, "atk": atk_card, "spd": spd_card,
                            "is_approved": is_approved,
                            "special_move_name": None, "special_effect": None,
                            "battle_log": [], "dice": None,
                            "score": final_score, "hantei": "æ‰¿èªåœå†…" if is_approved else "è¦å¯©è­°",  # is_approved = (final_score >= APPROVAL_LINE)
                            "environment_effects": env_effects,
                            "ai_completed_factors": ai_completed_factors,
                        }
                        st.session_state["show_battle"] = False  # åˆ¥æ ï¼ˆé–‹ç™ºä¸­ï¼‰ã®ãŸã‚åˆ¤å®šå¾Œã¯ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã¸ç›´è¡Œ

                        # ãƒ­ã‚°ä¿å­˜ (è‡ªå‹•)
                        log_payload = {
                            "industry_major": selected_major,
                            "industry_sub": selected_sub,
                            "customer_type": customer_type,
                            "main_bank": main_bank,
                            "competitor": competitor,
                            "competitor_rate": st.session_state.get("competitor_rate"),
                            "inputs": {
                                "nenshu": nenshu,
                                "gross_profit": item9_gross,
                                "op_profit": rieki,
                                "ord_profit": item4_ord_profit,
                                "net_income": item5_net_income,
                                "machines": item6_machine,
                                "other_assets": item7_other,
                                "rent": item8_rent,
                                "depreciation": item10_dep,
                                "dep_expense": item11_dep_exp,
                                "rent_expense": item12_rent_exp,
                                "bank_credit": bank_credit,
                                "lease_credit": lease_credit,
                                "contracts": contracts,
                                "grade": grade,
                                "contract_type": contract_type,
                                "deal_source": deal_source,
                                "lease_term": lease_term,
                                "acceptance_year": acceptance_year,
                                "acquisition_cost": acquisition_cost,
                                "lease_asset_id": selected_asset_id,
                                "lease_asset_name": asset_name,
                                "lease_asset_score": asset_score,
                                "qualitative": {
                                    "strength_tags": strength_tags,
                                    "passion_text": passion_text,
                                    "onehot": qualitative_onehot,
                                },
                                "qualitative_scoring": qualitative_scoring_correction,
                            },
                            "result": st.session_state['last_result'],
                            "pricing": {
                                "base_rate": 1.2, 
                                "pred_rate": y_pred_adjusted
                            }
                        }
                        # æ¡ˆä»¶ãƒ­ã‚°ã‚’ä¿å­˜ã—ã€æ¡ˆä»¶IDã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿æŒã—ã¦ãŠã
                        case_id = save_case_log(log_payload)
                        if case_id is None:
                            st.error("ãƒ­ã‚°ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                        else:
                            st.session_state["current_case_id"] = case_id
                            # æˆ»ã£ãŸã¨ãã«ã‚¯ãƒªã‚¢ã•ã‚Œãªã„ã‚ˆã†ã€ä»Šå›ã®å…¥åŠ›å€¤ã‚’ã™ã¹ã¦ä¿å­˜ï¼ˆè¨‚æ­£ã§æˆ»ã£ãŸã¨ãã«å¾©å…ƒï¼‰
                            submitted_qual_corr = {f"qual_corr_{item['id']}": st.session_state.get(f"qual_corr_{item['id']}", 0) for item in QUALITATIVE_SCORING_CORRECTION_ITEMS}
                            st.session_state["last_submitted_inputs"] = {
                                "nenshu": nenshu, "item9_gross": item9_gross, "rieki": rieki,
                                "item4_ord_profit": item4_ord_profit, "item5_net_income": item5_net_income,
                                "item10_dep": item10_dep, "item11_dep_exp": item11_dep_exp,
                                "item8_rent": item8_rent, "item12_rent_exp": item12_rent_exp,
                                "item6_machine": item6_machine, "item7_other": item7_other,
                                "net_assets": net_assets, "total_assets": total_assets,
                                "bank_credit": bank_credit, "lease_credit": lease_credit,
                                "contracts": contracts, "lease_term": lease_term,
                                "acquisition_cost": acquisition_cost, "acceptance_year": acceptance_year,
                                "selected_major": selected_major, "selected_sub": selected_sub,
                                "grade": grade, "main_bank": main_bank, "competitor": competitor,
                                "customer_type": customer_type, "contract_type": contract_type,
                                "deal_source": deal_source,
                                "selected_asset_index": st.session_state.get("selected_asset_index", 0),
                                **submitted_qual_corr,
                            }
                            st.session_state["form_restored_from_submit"] = False
                            st.session_state.nav_index = 1  # 1ç•ªç›®ï¼ˆåˆ†æçµæœï¼‰ã«åˆ‡ã‚Šæ›¿ãˆã‚‹
                            st.session_state["_jump_to_analysis"] = True  # åˆ¤å®šç›´å¾Œã®1å›ã ã‘åˆ†æçµæœã«é£›ã¶
                            st.rerun()  # ç”»é¢ã‚’èª­ã¿è¾¼ã¿ç›´ã—ã¦ã€å®Ÿéš›ã«ã‚¿ãƒ–ã‚’ç§»å‹•ã•ã›ã‚‹
                except Exception as e:
                    st.error("åˆ¤å®šé–‹å§‹ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚å…¥åŠ›å†…å®¹ã‚’ç¢ºèªã™ã‚‹ã‹ã€ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
                    import traceback
                    with st.expander("ã‚¨ãƒ©ãƒ¼è©³ç´°", expanded=False):
                        st.code(traceback.format_exc())

        if nav_mode == "ğŸ“Š åˆ†æçµæœ":
            # â”€â”€ ã‚¯ã‚¤ãƒƒã‚¯å†å…¥åŠ›ãƒ‘ãƒãƒ«ï¼ˆå…¨é …ç›®ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            with st.expander("âœï¸ å…¨é …ç›®ç·¨é›†ã—ã¦å†åˆ¤å®š", expanded=False):
                st.caption("ã™ã¹ã¦ã®å…¥åŠ›é …ç›®ã‚’ã“ã“ã‹ã‚‰å¤‰æ›´ã§ãã¾ã™ã€‚ã€ŒğŸ”„ å†åˆ¤å®šã€ã§å³åº§ã«å†è¨ˆç®—ã—ã¾ã™ã€‚")

                # â”€â”€â”€ æ¥­ç¨® â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                st.markdown("#### ğŸ­ æ¥­ç¨®")
                _q_major_keys = list(jsic_data.keys()) if jsic_data else ["D å»ºè¨­æ¥­"]
                _q_cur_major = st.session_state.get("select_major") or st.session_state.get("last_submitted_inputs", {}).get("selected_major", _q_major_keys[0])
                _q_major_idx = _q_major_keys.index(_q_cur_major) if _q_cur_major in _q_major_keys else 0
                _q_major = st.selectbox("å¤§åˆ†é¡", _q_major_keys, index=_q_major_idx, key="_quick_major")
                _q_sub_keys = list(jsic_data[_q_major]["sub"].keys()) if jsic_data and _q_major in jsic_data else ["06 ç·åˆå·¥äº‹æ¥­"]
                _q_cur_sub = st.session_state.get("select_sub") or st.session_state.get("last_submitted_inputs", {}).get("selected_sub", _q_sub_keys[0])
                _q_sub_idx = _q_sub_keys.index(_q_cur_sub) if _q_cur_sub in _q_sub_keys else 0
                _q_sub = st.selectbox("ä¸­åˆ†é¡", _q_sub_keys, index=_q_sub_idx, key="_quick_sub")

                st.divider()

                # â”€â”€â”€ æç›Šè¨ˆç®—æ›¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                st.markdown("#### ğŸ“Š æç›Šè¨ˆç®—æ›¸ P/Lï¼ˆåƒå††ï¼‰")
                _q1, _q2, _q3 = st.columns(3)
                with _q1:
                    _q_nenshu = st.number_input("å£²ä¸Šé«˜", min_value=0, max_value=90_000_000, value=int(st.session_state.get("nenshu", 10000)), step=1000, key="_quick_nenshu")
                with _q2:
                    _q_gross = st.number_input("å£²ä¸Šç·åˆ©ç›Šï¼ˆç²—åˆ©ï¼‰", min_value=-90_000_000, max_value=90_000_000, value=int(st.session_state.get("item9_gross", 10000)), step=1000, key="_quick_gross")
                with _q3:
                    _q_rieki = st.number_input("å–¶æ¥­åˆ©ç›Š", min_value=-90_000_000, max_value=90_000_000, value=int(st.session_state.get("rieki", 10000)), step=1000, key="_quick_rieki")
                _q4, _q5 = st.columns(2)
                with _q4:
                    _q_ord = st.number_input("çµŒå¸¸åˆ©ç›Š", min_value=-90_000_000, max_value=90_000_000, value=int(st.session_state.get("item4_ord_profit", 10000)), step=1000, key="_quick_ord")
                with _q5:
                    _q_net_income = st.number_input("å½“æœŸåˆ©ç›Š", min_value=-90_000_000, max_value=90_000_000, value=int(st.session_state.get("item5_net_income", 10000)), step=1000, key="_quick_net_income")

                st.divider()

                # â”€â”€â”€ è³‡ç”£ãƒ»çµŒè²» â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                st.markdown("#### ğŸ¢ è³‡ç”£ãƒ»çµŒè²»ï¼ˆåƒå††ï¼‰")
                _qA1, _qA2, _qA3 = st.columns(3)
                with _qA1:
                    _q_dep = st.number_input("æ¸›ä¾¡å„Ÿå´è²»ï¼ˆè³‡ç”£ï¼‰", min_value=0, max_value=90_000_000, value=int(st.session_state.get("item10_dep", 10000)), step=1000, key="_quick_dep")
                    _q_dep_exp = st.number_input("æ¸›ä¾¡å„Ÿå´è²»ï¼ˆçµŒè²»ï¼‰", min_value=0, max_value=90_000_000, value=int(st.session_state.get("item11_dep_exp", 10000)), step=1000, key="_quick_dep_exp")
                with _qA2:
                    _q_rent = st.number_input("è³ƒå€Ÿæ–™ï¼ˆè³‡ç”£ï¼‰", min_value=0, max_value=90_000_000, value=int(st.session_state.get("item8_rent", 10000)), step=1000, key="_quick_rent")
                    _q_rent_exp = st.number_input("è³ƒå€Ÿæ–™ï¼ˆçµŒè²»ï¼‰", min_value=0, max_value=90_000_000, value=int(st.session_state.get("item12_rent_exp", 10000)), step=1000, key="_quick_rent_exp")
                with _qA3:
                    _q_machine = st.number_input("æ©Ÿæ¢°è£…ç½®", min_value=0, max_value=90_000_000, value=int(st.session_state.get("item6_machine", 10000)), step=1000, key="_quick_machine")
                    _q_other = st.number_input("ãã®ä»–è³‡ç”£", min_value=0, max_value=90_000_000, value=int(st.session_state.get("item7_other", 10000)), step=1000, key="_quick_other")
                _qB1, _qB2 = st.columns(2)
                with _qB1:
                    _q_net = st.number_input("ç´”è³‡ç”£", min_value=-90_000_000, max_value=90_000_000, value=int(st.session_state.get("net_assets", 10000)), step=1000, key="_quick_net")
                with _qB2:
                    _q_total = st.number_input("ç·è³‡ç”£", min_value=0, max_value=90_000_000, value=int(st.session_state.get("total_assets", 10000)), step=1000, key="_quick_total")

                st.divider()

                # â”€â”€â”€ ä¿¡ç”¨æƒ…å ± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                st.markdown("#### ğŸ’³ ä¿¡ç”¨æƒ…å ±")
                _qC1, _qC2 = st.columns(2)
                with _qC1:
                    _grade_opts = ["â‘ 1-3 (å„ªè‰¯)", "â‘¡4-6 (æ¨™æº–)", "â‘¢è¦æ³¨æ„ä»¥ä¸‹", "â‘£ç„¡æ ¼ä»˜"]
                    _q_cur_grade = st.session_state.get("grade", "â‘¡4-6 (æ¨™æº–)")
                    _q_grade_idx = _grade_opts.index(_q_cur_grade) if _q_cur_grade in _grade_opts else 1
                    _q_grade = st.selectbox("æ ¼ä»˜", _grade_opts, index=_q_grade_idx, key="_quick_grade")
                    _q_bank = st.number_input("éŠ€è¡Œä¸ä¿¡ï¼ˆåƒå††ï¼‰", min_value=0, max_value=90_000_000, value=int(st.session_state.get("bank_credit", 10000)), step=1000, key="_quick_bank")
                with _qC2:
                    _q_lease = st.number_input("ãƒªãƒ¼ã‚¹ä¸ä¿¡ï¼ˆåƒå††ï¼‰", min_value=0, max_value=90_000_000, value=int(st.session_state.get("lease_credit", 10000)), step=1000, key="_quick_lease")
                    _q_contracts = st.number_input("å¥‘ç´„æ•°ï¼ˆä»¶ï¼‰", min_value=0, max_value=200, value=int(st.session_state.get("contracts", 1)), step=1, key="_quick_contracts")

                st.divider()

                # â”€â”€â”€ å¥‘ç´„æ¡ä»¶ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                st.markdown("#### ğŸ“‹ å¥‘ç´„æ¡ä»¶ãƒ»ç‰©ä»¶")
                _qD1, _qD2, _qD3 = st.columns(3)
                with _qD1:
                    _q_ctype = st.radio("é¡§å®¢åŒºåˆ†", ["æ—¢å­˜å…ˆ", "æ–°è¦å…ˆ"], index=0 if st.session_state.get("customer_type", "æ—¢å­˜å…ˆ") == "æ—¢å­˜å…ˆ" else 1, horizontal=True, key="_quick_ctype")
                    _q_contract_type = st.radio("å¥‘ç´„ç¨®é¡", ["ä¸€èˆ¬", "è‡ªå‹•è»Š"], index=0 if st.session_state.get("contract_type", "ä¸€èˆ¬") == "ä¸€èˆ¬" else 1, horizontal=True, key="_quick_contract_type")
                with _qD2:
                    _q_deal_source = st.radio("å•†è«‡ã‚½ãƒ¼ã‚¹", ["éŠ€è¡Œç´¹ä»‹", "ãã®ä»–"], index=0 if st.session_state.get("deal_source", "ãã®ä»–") == "éŠ€è¡Œç´¹ä»‹" else 1, horizontal=True, key="_quick_deal_source")
                    _q_lease_term = st.number_input("å¥‘ç´„æœŸé–“ï¼ˆæœˆï¼‰", min_value=0, max_value=120, value=int(st.session_state.get("lease_term", 60)), step=1, key="_quick_lease_term")
                with _qD3:
                    _q_acceptance_year = st.number_input("æ¤œåå¹´ï¼ˆè¥¿æš¦ï¼‰", min_value=2000, max_value=2100, value=int(st.session_state.get("acceptance_year", 2026)), step=1, key="_quick_acceptance_year")
                    _q_acq = st.number_input("å–å¾—ä¾¡æ ¼ï¼ˆåƒå††ï¼‰", min_value=0, max_value=90_000_000, value=int(st.session_state.get("acquisition_cost", 1000)), step=100, key="_quick_acq")
                if LEASE_ASSETS_LIST:
                    _q_asset_opts = [f"{it.get('name', '')}ï¼ˆ{it.get('score', 0)}ç‚¹ï¼‰" for it in LEASE_ASSETS_LIST]
                    _q_asset_idx = min(st.session_state.get("selected_asset_index", 0), len(_q_asset_opts) - 1)
                    _q_asset_sel = st.selectbox("ãƒªãƒ¼ã‚¹ç‰©ä»¶", range(len(_q_asset_opts)), format_func=lambda i: _q_asset_opts[i], index=_q_asset_idx, key="_quick_asset")
                else:
                    _q_asset_sel = None

                st.divider()

                # â”€â”€â”€ å®šæ€§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                st.markdown("#### ğŸ“ å®šæ€§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°")
                _q_qual = {}
                for _qi, _qitem in enumerate(QUALITATIVE_SCORING_CORRECTION_ITEMS):
                    _qopts = _qitem.get("options") or QUALITATIVE_SCORING_LEVELS
                    _qopts_display = ["æœªé¸æŠ"] + [o[1] for o in _qopts]
                    _qcur = st.session_state.get(f"qual_corr_{_qitem['id']}", 0)
                    _q_qual[_qitem["id"]] = st.selectbox(
                        f"{_qitem['label']}ï¼ˆé‡ã¿{_qitem['weight']}%ï¼‰",
                        range(len(_qopts_display)),
                        format_func=lambda i, d=_qopts_display: d[i],
                        index=_qcur,
                        key=f"_quick_qual_{_qitem['id']}",
                    )

                st.divider()
                if st.button("ğŸ”„ å†åˆ¤å®š", type="primary", use_container_width=True):
                    # æ¥­ç¨®
                    st.session_state["select_major"] = _q_major
                    st.session_state["select_sub"] = _q_sub
                    # P/L
                    st.session_state["nenshu"] = _q_nenshu
                    st.session_state["item9_gross"] = _q_gross
                    st.session_state["rieki"] = _q_rieki
                    st.session_state["item4_ord_profit"] = _q_ord
                    st.session_state["item5_net_income"] = _q_net_income
                    # è³‡ç”£ãƒ»çµŒè²»
                    st.session_state["item10_dep"] = _q_dep
                    st.session_state["item11_dep_exp"] = _q_dep_exp
                    st.session_state["item8_rent"] = _q_rent
                    st.session_state["item12_rent_exp"] = _q_rent_exp
                    st.session_state["item6_machine"] = _q_machine
                    st.session_state["item7_other"] = _q_other
                    st.session_state["net_assets"] = _q_net
                    st.session_state["total_assets"] = _q_total
                    # ä¿¡ç”¨æƒ…å ±
                    st.session_state["grade"] = _q_grade
                    st.session_state["bank_credit"] = _q_bank
                    st.session_state["lease_credit"] = _q_lease
                    st.session_state["contracts"] = _q_contracts
                    # å¥‘ç´„æ¡ä»¶
                    st.session_state["customer_type"] = _q_ctype
                    st.session_state["contract_type"] = _q_contract_type
                    st.session_state["deal_source"] = _q_deal_source
                    st.session_state["lease_term"] = _q_lease_term
                    st.session_state["acceptance_year"] = _q_acceptance_year
                    st.session_state["acquisition_cost"] = _q_acq
                    if _q_asset_sel is not None:
                        st.session_state["selected_asset_index"] = _q_asset_sel
                    # å®šæ€§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
                    for _qid, _qval in _q_qual.items():
                        st.session_state[f"qual_corr_{_qid}"] = _qval
                    # åˆ¤å®šãƒˆãƒªã‚¬ãƒ¼
                    st.session_state["_auto_judge"] = True
                    st.session_state["nav_mode_widget"] = "ğŸ“ å¯©æŸ»å…¥åŠ›"
                    st.rerun()
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

            # --- GLOBAL VARIABLE RECOVERY (Must be first) ---
            selected_major = "D å»ºè¨­æ¥­" # Default
            selected_sub = "06 ç·åˆå·¥äº‹æ¥­" # Default
            score_percent = 0
            user_equity_ratio = 0
            user_op_margin = 0
            if "last_result" in st.session_state:
                res_g = st.session_state["last_result"]
                selected_major = res_g.get("industry_major", "D å»ºè¨­æ¥­")
                selected_sub = res_g.get("industry_sub", "06 ç·åˆå·¥äº‹æ¥­")
                score_percent = res_g.get("score", 0)
                user_equity_ratio = res_g.get("user_eq", 0)
                user_op_margin = res_g.get("user_op", 0)
            # ------------------------------------------------
            if 'last_result' in st.session_state:
                res = st.session_state['last_result']
                # --- å¤‰æ•°å®Œå…¨å¾©å…ƒ (ç”»é¢åˆ†å‰²å¯¾ç­–) ---
                score_percent = res.get("score", 0)
                selected_major = res.get("industry_major", "D å»ºè¨­æ¥­")
                user_equity_ratio = res.get("user_eq", 0)
                user_op_margin = res.get("user_op", 0)
                # --------------------------------
                selected_major = res.get("industry_major", "D å»ºè¨­æ¥­")
                selected_sub = res.get("industry_sub", "06 ç·åˆå·¥äº‹æ¥­")
                hantei = res.get("hantei", "")
                industry_major = res.get("industry_major", "")
                asset_name = res.get("asset_name", "") or ""
                comparison_text = res.get("comparison", "")
                if jsic_data and selected_major in jsic_data:
                    trend_info = jsic_data[selected_major]["sub"].get(selected_sub, "")
                # æ¥­ç•Œãƒˆãƒ¬ãƒ³ãƒ‰æ‹¡å……ï¼ˆãƒãƒƒãƒˆå–å¾—æ¸ˆã¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒã‚ã‚Œã°è¿½åŠ ï¼‰
                trend_extended = get_trend_extended(selected_sub)
                if trend_extended:
                    trend_info = (trend_info or "") + "\n\nã€ãƒãƒƒãƒˆã§è£œè¶³ã€‘\n" + trend_extended[:1500]
                # --------------------------------------
                # ç¾åœ¨ã®æ¡ˆä»¶IDã‚’å–å¾—ï¼ˆå¯©æŸ»ç›´å¾Œãªã‚‰ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«å…¥ã£ã¦ã„ã‚‹æƒ³å®šï¼‰
                current_case_id = st.session_state.get("current_case_id")

                # ==================== ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆï¼ˆãƒ—ãƒ­ä»•æ§˜ï¼‰ ====================
                st.markdown("---")
                # ----- æˆç´„ã«æœ€ã‚‚å¯„ä¸ã—ã¦ã„ã‚‹ä¸Šä½3å› å­ï¼ˆãƒ‡ãƒ¼ã‚¿5ä»¶ä»¥ä¸Šã§è¡¨ç¤ºï¼‰ -----
                _driver_analysis = run_contract_driver_analysis()
                if _driver_analysis and _driver_analysis["closed_count"] >= 5:
                    st.markdown("**ğŸ¯ æˆç´„ã«æœ€ã‚‚å¯„ä¸ã—ã¦ã„ã‚‹ä¸Šä½3ã¤ã®å› å­ï¼ˆãƒ‰ãƒ©ã‚¤ãƒãƒ¼ï¼‰**")
                    d1, d2, d3 = st.columns(3)
                    for idx, col in enumerate([d1, d2, d3]):
                        if idx < len(_driver_analysis["top3_drivers"]):
                            d = _driver_analysis["top3_drivers"][idx]
                            with col:
                                st.markdown(f"""
                                <div style="background:linear-gradient(135deg,#1e3a5f 0%,#334155 100%);color:#fff;padding:0.8rem;border-radius:10px;font-size:0.9rem;">
                                <div style="opacity:0.9;">{idx+1}ä½</div>
                                <div style="font-weight:bold;">{d['label']}</div>
                                <div style="font-size:0.8rem;">ä¿‚æ•° {d['coef']:.3f}ï¼ˆ{d['direction']}ï¼‰</div>
                                </div>
                                """, unsafe_allow_html=True)
                    st.markdown("<div style='height:0.5rem;'></div>", unsafe_allow_html=True)
                # ----- ã‚¿ã‚¤ãƒˆãƒ« + ç”»åƒ -----
                img_path, img_caption = get_dashboard_image_path(hantei, industry_major, selected_sub, asset_name)
                col_title, col_img = st.columns([3, 1])
                with col_title:
                    st.markdown(f"### ğŸ“Š åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ â€” {selected_sub}")
                with col_img:
                    if img_path and os.path.isfile(img_path):
                        st.image(img_path, caption=img_caption, use_container_width=True)
                    else:
                        st.caption("ç”»åƒ: dashboard_images ã«ç”»åƒã‚’é…ç½®ã™ã‚‹ã‹ã€ç’°å¢ƒå¤‰æ•° DASHBOARD_IMAGES_ASSETS ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")

                st.divider()
                # ----- ä¸»è¦KPIï¼ˆç”»é¢æœ€ä¸Šéƒ¨ãƒ»æ¨ªä¸¦ã³ï¼‰æ¥­ç•Œå®Ÿç¸¾ + æœ¬ä»¶ -----
                past_stats = get_stats(selected_sub)
                with st.container():
                    st.markdown("**ä¸»è¦KPI**")
                    kpi1, kpi2, kpi3, kpi4, kpi5, kpi6 = st.columns(6)
                    with kpi1:
                        st.metric("æ¥­ç•Œ æˆç´„ç‡", f"{past_stats.get('close_rate', 0) * 100:.1f}%" if past_stats.get("count") else "â€”", help="åŒæ¥­ç¨®ã®æˆç´„ç‡")
                    with kpi2:
                        st.metric("æ¥­ç•Œ æˆç´„ä»¶æ•°", f"{past_stats.get('closed_count', 0)}ä»¶" if past_stats.get("count") else "â€”", help="åŒæ¥­ç¨®ã®æˆç´„ä»¶æ•°")
                    with kpi3:
                        avg_r = past_stats.get("avg_winning_rate")
                        st.metric("æ¥­ç•Œ å¹³å‡é‡‘åˆ©", f"{avg_r:.2f}%" if avg_r is not None and avg_r > 0 else "â€”", help="åŒæ¥­ç¨®ã®å¹³å‡æˆç´„é‡‘åˆ©")
                    with kpi4:
                        st.metric("æœ¬ä»¶ ã‚¹ã‚³ã‚¢", f"{res['score']:.1f}%", help="ç·åˆæ‰¿èªã‚¹ã‚³ã‚¢")
                    with kpi5:
                        st.metric("æœ¬ä»¶ åˆ¤å®š", res.get("hantei", "â€”"), help="æ‰¿èªåœå†… or è¦å¯©è­°")
                    with kpi6:
                        st.metric("æœ¬ä»¶ å¥‘ç´„æœŸå¾…åº¦", f"{res.get('contract_prob', 0):.1f}%", help="å®šæ€§è£œæ­£å¾Œ")
                    # streamlit-extras: ãƒšãƒ¼ã‚¸å†…ã®å…¨ st.metric ã‚’ã‚«ãƒ¼ãƒ‰é¢¨ã«ï¼ˆãƒã‚¤ãƒ“ãƒ¼ãƒ»ã‚´ãƒ¼ãƒ«ãƒ‰ã®å·¦ã‚¢ã‚¯ã‚»ãƒ³ãƒˆï¼‰
                    if style_metric_cards is not None:
                        style_metric_cards(
                            background_color=CHART_STYLE["bg"],
                            border_size_px=1,
                            border_color=CHART_STYLE["grid"],
                            border_radius_px=8,
                            border_left_color=CHART_STYLE["primary"],
                            box_shadow=True,
                        )
                    st.markdown("<div style='height:0.5rem;'></div>", unsafe_allow_html=True)

                # ----- è¦ç¢ºèªã‚¢ãƒ©ãƒ¼ãƒˆï¼ˆæ‰¿èªãƒ©ã‚¤ãƒ³ç›´ä¸‹ãƒ»æœ¬ç¤¾ã¨å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®åˆ¤å®šå·®ï¼‰ -----
                review_need, review_reasons = get_review_alert(res)
                if review_need and review_reasons:
                    st.warning("âš ï¸ **è¦ç¢ºèª**: " + " / ".join(review_reasons))

                # ----- AIãŒè£œå®Œã—ãŸåˆ¤å®šè¦å› ï¼ˆé€²åŒ–ã™ã‚‹ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ï¼‰ -----
                ai_factors = res.get("ai_completed_factors") or []
                if ai_factors:
                    with st.expander("ğŸ¤– AIãŒè£œå®Œã—ãŸåˆ¤å®šè¦å› ", expanded=True):
                        st.caption("ã‚ãªãŸã®è¨­å®šã—ãŸè²¡å‹™æŒ‡æ¨™ã«åŠ ãˆã€ä»¥ä¸‹ã®è¦å› ã‚’æˆç´„ç‡ï¼ˆå¥‘ç´„æœŸå¾…åº¦ï¼‰ã«åæ˜ ã—ã¾ã—ãŸã€‚")
                        for f in ai_factors:
                            sign = "+" if f.get("effect_percent", 0) >= 0 else ""
                            st.markdown(f"- **{f.get('factor', '')}** â€¦ {sign}{f.get('effect_percent', 0)}% ï¼ˆ{f.get('detail', '')}ï¼‰")

                # ----- å®šæ€§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ï¼ˆç·åˆÃ—60%ï¼‹å®šæ€§Ã—40%ã§ãƒ©ãƒ³ã‚¯Aã€œEï¼‰ -----
                qcorr = res.get("qualitative_scoring_correction")
                with st.expander("ğŸ“‹ å®šæ€§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°", expanded=bool(qcorr)):
                    if qcorr:
                        r = qcorr
                        st.caption("**ãƒ©ãƒ³ã‚¯ï¼ˆAã€œEï¼‰ã¯ ç·åˆÃ—é‡ã¿ï¼‹å®šæ€§Ã—é‡ã¿ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ60%/40%ï¼‰ã«åŸºã¥ãã¾ã™ã€‚**")
                        total_score = res.get("score", 0)  # ç·åˆã‚¹ã‚³ã‚¢ï¼ˆå€Ÿæ‰‹+ç‰©ä»¶ï¼‰
                        qual_score = r.get("weighted_score", 0)
                        combined = r.get("combined_score", 0)
                        c1, c2, c3, c4 = st.columns(4)
                        with c1:
                            st.metric("ç·åˆã‚¹ã‚³ã‚¢", f"{total_score:.1f}", help="å€Ÿæ‰‹ã‚¹ã‚³ã‚¢85%ï¼‹ç‰©ä»¶ã‚¹ã‚³ã‚¢15%")
                        with c2:
                            st.metric("å®šæ€§ã‚¹ã‚³ã‚¢", f"{qual_score} / 100", help="é …ç›®åˆ¥5æ®µéšã®åŠ é‡å¹³å‡")
                        with c3:
                            st.metric("åˆè¨ˆï¼ˆç·åˆÃ—é‡ã¿ï¼‹å®šæ€§Ã—é‡ã¿ï¼‰", f"{combined}", help="ãƒ©ãƒ³ã‚¯ç®—å‡ºã®å…ƒ")
                        with c4:
                            st.metric("ãƒ©ãƒ³ã‚¯", f"{r.get('rank', 'â€”')} {r.get('rank_text', '')}", help=r.get("rank_desc", ""))
                        st.caption(r.get("rank_desc", ""))
                        st.markdown("**é …ç›®åˆ¥**")
                        for item_id, data in (r.get("items") or {}).items():
                            val = data.get("value")
                            if val is not None:
                                label_short = data.get("level_label") or QUALITATIVE_SCORING_LEVEL_LABELS.get(val, f"{int((val or 0)/4*100)}ç‚¹")
                                st.markdown(f"- **{data.get('label', item_id)}**ï¼ˆé‡ã¿{data.get('weight', 0)}%ï¼‰: {label_short}")
                    else:
                        st.info("å¯©æŸ»å…¥åŠ›ã®ã€Œå®šæ€§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã€ã§é …ç›®ã‚’é¸æŠã™ã‚‹ã¨ã€ã“ã“ã«é›†è¨ˆçµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚ãƒ©ãƒ³ã‚¯ã¯ç·åˆÃ—é‡ã¿ï¼‹å®šæ€§Ã—é‡ã¿ã§ç®—å‡ºã€‚å®šæ€§ã‚’1ä»¶ã‚‚é¸ã‚“ã§ã„ãªã„å ´åˆã¯ç·åˆã‚¹ã‚³ã‚¢ã®ã¿ã§åˆ¤å®šã—ã¾ã™ã€‚")

                # ----- å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ï¼ˆæ¥­ç¨®åˆ¥ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ï¼‰ã®äºˆæ¸¬çµæœï¼ˆèåˆæ©Ÿèƒ½ï¼‰ãƒ»å¸¸ã«è¡¨ç¤º -----
                scoring_result = res.get("scoring_result")
                with st.expander("ğŸ“ˆ å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ï¼ˆæ¥­ç¨®åˆ¥ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ï¼‰ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç¢ºç‡", expanded=True):
                    if scoring_result:
                        st.caption("**ã„ãšã‚Œã‚‚ã€Œãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç¢ºç‡ã€ï¼ˆé«˜ã„ï¼ãƒªã‚¹ã‚¯å¤§ï¼‰ã§ã™ã€‚** ä¸Šè¨˜ã®æœ¬ã‚·ã‚¹ãƒ†ãƒ ã€Œå¥‘ç´„æœŸå¾…åº¦ã€ï¼ˆæˆç´„ç‡ï¼‰ã¨ã¯å°ºåº¦ãŒé€†ã§ã™ã€‚æˆç´„ç‡ã«æ›ç®—ã™ã‚‹ãªã‚‰ ç´„ 100% âˆ’ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç¢ºç‡ã€‚ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã¯ã€Œæ¥­ç¨®åˆ¥å›å¸°ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç¢ºç‡ã€ã¨ã€ŒAIã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç¢ºç‡ã€ã®åŠ é‡å¹³å‡ãªã®ã§ã€åŒã˜å°ºåº¦åŒå£«ã®çµ„ã¿åˆã‚ã›ã§ã™ã€‚")
                        sr1, sr2, sr3, sr4 = st.columns(4)
                        with sr1:
                            st.metric("æ—¢å­˜ï¼ˆæ¥­ç¨®åˆ¥å›å¸°ï¼‰ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç¢ºç‡", f"{scoring_result.get('legacy_prob', 0)*100:.2f}%", help="å­¦ç¿’ãƒ¢ãƒ‡ãƒ«å´ã®æ¥­ç¨®åˆ¥å›å¸°")
                        with sr2:
                            st.metric("AIï¼ˆLightGBMï¼‰ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç¢ºç‡", f"{scoring_result.get('ai_prob', 0)*100:.2f}%", help="LightGBMçµ±åˆ")
                        with sr3:
                            st.metric("ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç¢ºç‡", f"{scoring_result.get('hybrid_prob', 0)*100:.2f}%", help="0.3Ã—æ—¢å­˜+0.7Ã—AIï¼ˆåŒå°ºåº¦ï¼‰")
                        with sr4:
                            dec = scoring_result.get("decision", "â€”")
                            st.metric("å­¦ç¿’ãƒ¢ãƒ‡ãƒ«åˆ¤å®š", dec, help="ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç¢ºç‡50%æœªæº€ã§æ‰¿èª")
                        # ã‚°ãƒ©ãƒ•è¡¨ç¤ºï¼ˆTop5è¦å› ã®ã¿ï¼‰
                        st.divider()
                        st.subheader("ğŸ“Š å­¦ç¿’ãƒ¢ãƒ‡ãƒ«åˆ†æã‚°ãƒ©ãƒ•")
                            
                        # Top5è¦å› ã‚°ãƒ©ãƒ•
                        top5 = scoring_result.get("top5_reasons") or []
                        if top5:
                            st.caption("**åˆ¤å®šã«åŠ¹ã„ã¦ã„ã‚‹æŒ‡æ¨™ Top5**")
                            fig_top5 = plot_scoring_top5_factors_plotly(scoring_result)
                            if fig_top5:
                                st.plotly_chart(fig_top5, use_container_width=True, key="plotly_scoring_top5")
                            else:
                                # ã‚°ãƒ©ãƒ•ãŒæã‘ãªã„å ´åˆã¯ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤º
                                _feat_ja = {
                                    "ROA": "ç·è³‡ç”£åˆ©ç›Šç‡ï¼ˆROAï¼‰", "ROE": "è‡ªå·±è³‡æœ¬åˆ©ç›Šç‡ï¼ˆROEï¼‰",
                                    "operating_margin": "å£²ä¸Šé«˜å–¶æ¥­åˆ©ç›Šç‡", "net_margin": "å£²ä¸Šé«˜ç´”åˆ©ç›Šç‡",
                                    "equity_ratio": "è‡ªå·±è³‡æœ¬æ¯”ç‡", "debt_ratio": "è² å‚µæ¯”ç‡", "debt_equity_ratio": "è² å‚µå¯¾è‡ªå·±è³‡æœ¬æ¯”ç‡",
                                    "machinery_ratio": "æ©Ÿæ¢°è¨­å‚™æ¯”ç‡", "fixed_asset_ratio": "å›ºå®šè³‡ç”£æ¯”ç‡",
                                    "fixed_to_equity": "å›ºå®šè³‡ç”£å¯¾ç´”è³‡ç”£æ¯”ç‡", "machinery_equity_coverage": "æ©Ÿæ¢°è¨­å‚™ã®è‡ªå·±è³‡æœ¬ã‚«ãƒãƒ¼ç‡",
                                    "rent_to_revenue": "ãƒªãƒ¼ã‚¹æ–™è² æ‹…ç‡ï¼ˆå¯¾å£²ä¸Šé«˜ï¼‰", "operating_profit_to_rent": "å–¶æ¥­åˆ©ç›Šã®ãƒªãƒ¼ã‚¹æ–™ã‚«ãƒãƒ¼ç‡",
                                    "rent_to_equity": "ãƒªãƒ¼ã‚¹æ–™ã®ç´”è³‡ç”£è² æ‹…ç‡", "lease_dependency": "ãƒªãƒ¼ã‚¹ä¾å­˜åº¦",
                                    "total_fixed_cost_ratio": "ç·å›ºå®šè²»è² æ‹…ç‡", "depreciation_to_revenue": "æ¸›ä¾¡å„Ÿå´è²»ç‡ï¼ˆå¯¾å£²ä¸Šé«˜ï¼‰",
                                    "EBITDA_margin": "EBITDAãƒãƒ¼ã‚¸ãƒ³", "depreciation_rate": "è¨­å‚™å„Ÿå´é€²è¡Œåº¦",
                                    "asset_turnover": "ç·è³‡ç”£å›è»¢ç‡", "fixed_asset_turnover": "å›ºå®šè³‡ç”£å›è»¢ç‡",
                                    "log_revenue": "å£²ä¸Šé«˜ï¼ˆå¯¾æ•°ï¼‰", "log_assets": "ç·è³‡ç”£ï¼ˆå¯¾æ•°ï¼‰",
                                    "is_loss": "èµ¤å­—ãƒ•ãƒ©ã‚°", "is_operating_loss": "å–¶æ¥­èµ¤å­—ãƒ•ãƒ©ã‚°",
                                    "low_equity_ratio": "è‡ªå·±è³‡æœ¬æ¯”ç‡20%æœªæº€", "low_ROA": "ROA2%æœªæº€",
                                    "high_rent_burden": "ãƒªãƒ¼ã‚¹è² æ‹…å¤§", "rent_exceeds_profit": "ãƒªãƒ¼ã‚¹æ–™ï¼å–¶æ¥­åˆ©ç›Š",
                                    "industry_encoded": "æ¥­ç¨®ï¼ˆã‚³ãƒ¼ãƒ‰ï¼‰",
                                }
                                for idx, r in enumerate(top5, 1):
                                    if ":" in r:
                                        _name, _val = r.split(":", 1)
                                        _label = _feat_ja.get(_name.strip(), _name.strip())
                                    else:
                                        _label, _val = r, ""
                                    st.caption(f"#{idx} {_label}: {_val.strip()}")
                    else:
                        st.info(
                            "**ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç¢ºç‡ã‚’å‡ºã™ã«ã¯ã€æ¬¡ã®2ã¤ãŒå¿…è¦ã§ã™ã€‚**\n\n"
                            "1. **ç·è³‡ç”£**ã¨**ç´”è³‡ç”£**ã‚’å…¥åŠ›ã—ã¦ã‹ã‚‰ã€Œåˆ¤å®šé–‹å§‹ã€ã‚’æŠ¼ã™\n\n"
                            "2. **å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ï¼ˆ5å€‹ã®pklãƒ•ã‚¡ã‚¤ãƒ«ï¼‰**ã‚’ç”¨æ„ã™ã‚‹ï¼š\n"
                            "   - åˆ¥ãƒ„ãƒ¼ãƒ«ï¼ˆãƒªãƒ¼ã‚¹ä¸ä¿¡ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ï¼‰ã§ã€Œæ¥­ç¨®åˆ¥ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã€ã‚’å­¦ç¿’ã™ã‚‹ã¨ã€`models/industry_specific/` ãƒ•ã‚©ãƒ«ãƒ€ã« pkl ãŒã§ãã¾ã™\n"
                            "   - ãã®ä¸­èº«ï¼ˆindustry_coefficients.pkl ãªã©5ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ã‚’ã€ã“ã®ã‚¢ãƒ—ãƒªã®ãƒ•ã‚©ãƒ«ãƒ€å†…ã«ã‚ã‚‹\n"
                            "     `lease_logic_sumaho10/scoring/models/industry_specific/` ã«ã‚³ãƒ”ãƒ¼ã—ã¦ãã ã•ã„\n\n"
                            "â€» ãƒ¢ãƒ‡ãƒ«ãŒãªãã¦ã‚‚ã€æœ¬ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¹ã‚³ã‚¢ï¼ˆæˆç´„ç‡ï¼‰ã ã‘ã§å¯©æŸ»ã¯ã§ãã¾ã™ã€‚"
                        )

                st.divider()
                # ----- ã‚«ãƒ¼ãƒ‰: æœ¬ä»¶ã‚¹ã‚³ã‚¢å†…è¨³ãƒ»åˆ©å›ã‚Š -----
                pd_val = res.get("pd_percent")
                if pd_val is None:
                    fin = res.get("financials", {})
                    total_assets = fin.get("assets") or 0
                    net_assets = fin.get("net_assets") or 0
                    machines = fin.get("machines") or 0
                    other_assets = fin.get("other_assets") or 0
                    user_eq = res.get("user_eq", 0)
                    user_op = res.get("user_op", 0)
                    liability_total = total_assets - net_assets if total_assets and net_assets is not None else 0
                    current_approx = max(0, total_assets - machines - other_assets)
                    current_ratio = (current_approx / liability_total * 100) if liability_total > 0 else 100.0
                    pd_val = calculate_pd(user_eq, current_ratio, user_op)

                with st.container():
                    st.markdown("**æœ¬ä»¶ã‚¹ã‚³ã‚¢ãƒ»åˆ©å›ã‚Š**")
                    k1, k2, k3, k4 = st.columns(4)
                    with k1:
                        st.metric("ç·åˆã‚¹ã‚³ã‚¢", f"{res['score']:.1f}%", help="å€Ÿæ‰‹ï¼‹ç‰©ä»¶ã‚’åæ˜ ã—ãŸåˆ¤å®šç”¨ã‚¹ã‚³ã‚¢")
                    with k2:
                        st.metric("åˆ¤å®š", res.get("hantei", "â€”"), help="æ‰¿èªåœå†… or è¦å¯©è­°")
                    with k3:
                        st.metric("å¥‘ç´„æœŸå¾…åº¦", f"{res.get('contract_prob', 0):.1f}%", help="å®šæ€§è£œæ­£å¾Œã®æœŸå¾…åº¦")
                    with k4:
                        if "yield_pred" in res:
                            st.metric("äºˆæ¸¬åˆ©å›ã‚Š", f"{res['yield_pred']:.2f}%", delta=f"{res.get('rate_diff', 0):+.2f}%", help="AIäºˆæ¸¬åˆ©å›ã‚Š")
                        else:
                            st.metric("äºˆæ¸¬åˆ©å›ã‚Š", "â€”", help="åˆ©å›ã‚Šãƒ¢ãƒ‡ãƒ«æœªé©ç”¨")
                    # ----- ç¬¬2è¡Œ: ã‚¹ã‚³ã‚¢å†…è¨³ï¼ˆå€Ÿæ‰‹ãƒ»ç‰©ä»¶èª¬æ˜ + 3ãƒ¢ãƒ‡ãƒ«ï¼‰ -----
                    if "score_borrower" in res and "asset_score" in res:
                        st.caption(f"ğŸ“Œ å€Ÿæ‰‹ {res['score_borrower']:.1f}% Ã— 0.85 ï¼‹ ç‰©ä»¶ã€Œ{res.get('asset_name', '')}ã€{res['asset_score']}ç‚¹ Ã— 0.15 â†’ ç·åˆ {res['score']:.1f}%")
                    cols = st.columns(3)
                    with cols[0]:
                        st.metric("â‘  å…¨ä½“ãƒ¢ãƒ‡ãƒ«", f"{res['score']:.1f}%", help="å…¨æ¥­ç¨®å…±é€šä¿‚æ•°")
                    with cols[1]:
                        ind_label = res.get("ind_name", "å…¨ä½“_æ—¢å­˜å…ˆ")
                        second_label = "â‘¡ æ¥­ç¨®ãƒ¢ãƒ‡ãƒ«" if (ind_label.split("_")[0] != "å…¨ä½“") else "â‘¡ æ¥­ç¨®(å…¨ä½“)"
                        st.metric(second_label, f"{res['ind_score']:.1f}%", delta=f"{res['ind_score']-res['score']:+.1f}%")
                    with cols[2]:
                        st.metric("â‘¢ æŒ‡æ¨™ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯", f"{res['bench_score']:.1f}%", delta=f"{res['bench_score']-res['score']:+.1f}%", delta_color="inverse")

                st.divider()
                with st.container():
                    st.markdown("**ã‚¹ã‚³ã‚¢ã‚²ãƒ¼ã‚¸ãƒ»åˆ¤å®š**")
                    # ----- ç¬¬3è¡Œ: ã‚²ãƒ¼ã‚¸ãƒ»åˆ¤å®šãƒ»æ¥­ç•Œæ¯”è¼ƒï¼ˆãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰å†…ã«çµ±åˆï¼‰ -----
                    g1, g2 = st.columns(2)
                    with g1:
                        st.plotly_chart(plot_gauge_plotly(res['score'], "ç·åˆã‚¹ã‚³ã‚¢"), use_container_width=True, key="gauge_score")
                    with g2:
                        st.success(f"**{res['hantei']}**")
                        industry_key = res["industry_major"]
                        if industry_key in avg_data:
                            avg = avg_data[industry_key]
                            u_sales = res["financials"]["nenshu"]
                            a_sales = avg["nenshu"]
                            u_op_r = res['user_op']
                            a_op_r = (avg["op_profit"]/avg["nenshu"]*100) if avg["nenshu"] > 0 else 0
                            sales_ratio = u_sales / a_sales
                            if sales_ratio >= 1.2: sales_msg = f"å¹³å‡ã®{sales_ratio:.1f}å€è¦æ¨¡"
                            elif sales_ratio <= 0.8: sales_msg = f"å¹³å‡ã‚ˆã‚Šå°è¦æ¨¡({sales_ratio:.1f}å€)"
                            else: sales_msg = "æ¥­ç•Œå¹³å‡ä¸¦ã¿"
                            if u_op_r >= a_op_r + 2.0: prof_msg = f"é«˜åç›Š({u_op_r:.1f}%)"
                            elif u_op_r < a_op_r: prof_msg = f"å¹³å‡ä»¥ä¸‹({u_op_r:.1f}%)"
                            else: prof_msg = f"æ¨™æº–({u_op_r:.1f}%)"
                            st.caption(f"è¦æ¨¡: {sales_msg} / åç›Š: {prof_msg}")

                # ----- å¯©æŸ»ã«æœ‰ç”¨ãª Plotly ã‚°ãƒ©ãƒ•ï¼ˆ4ç¨®ï¼‰ -----
                st.divider()
                with st.expander("ğŸ“Š å¯©æŸ»ã«æœ‰ç”¨ãªã‚°ãƒ©ãƒ•", expanded=True):
                    st.caption("ã‚¹ã‚³ã‚¢å†…è¨³ãƒ»å¥‘ç´„æœŸå¾…åº¦ã®è¦å› ãƒ»éå»åˆ†å¸ƒãƒ»ãƒãƒ©ãƒ³ã‚¹ã‚·ãƒ¼ãƒˆå†…è¨³ã‚’ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã«è¡¨ç¤ºã—ã¾ã™ã€‚")
                    row1_a, row1_b = st.columns(2)
                    with row1_a:
                        st.plotly_chart(plot_score_models_comparison_plotly(res), use_container_width=True, key="plotly_score_models")
                    with row1_b:
                        factors_fig = plot_contract_prob_factors_plotly(res.get("ai_completed_factors") or [])
                        if factors_fig:
                            st.plotly_chart(factors_fig, use_container_width=True, key="plotly_contract_factors")
                        else:
                            st.caption("å¥‘ç´„æœŸå¾…åº¦ã®è¦å› ã¯åˆ¤å®šå®Ÿè¡Œå¾Œã«è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
                    row2_a, row2_b = st.columns(2)
                    with row2_a:
                        hist_fig = plot_past_scores_histogram_plotly(res.get("score"), load_all_cases())
                        if hist_fig:
                            st.plotly_chart(hist_fig, use_container_width=True, key="plotly_past_hist")
                        else:
                            st.caption("éå»æ¡ˆä»¶ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã¨ã‚¹ã‚³ã‚¢åˆ†å¸ƒã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
                    with row2_b:
                        bal_fig = plot_balance_sheet_plotly(res.get("financials"))
                        if bal_fig:
                            st.plotly_chart(bal_fig, use_container_width=True, key="plotly_balance_sheet")
                        else:
                            st.caption("å¯©æŸ»å…¥åŠ›ã§è³‡ç”£ãƒ»è² å‚µã‚’å…¥åŠ›ã™ã‚‹ã¨å†…è¨³ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")

                st.divider()
                with st.container():
                    st.subheader(":round_pushpin: 3Då¤šè§’åˆ†æï¼ˆå›è»¢ãƒ»æ‹¡å¤§å¯èƒ½ï¼‰")
                    current_case_data = {
                         'sales': res['financials']['nenshu'],
                         'op_margin': res['user_op'],
                         'equity_ratio': res['user_eq']
                    }
                    past_cases_log = load_all_cases()
                    fig_3d = plot_3d_analysis(current_case_data, past_cases_log)
                    if fig_3d:
                        st.plotly_chart(fig_3d, use_container_width=True, key="plotly_3d_analysis_result")
                        st.caption("æŒ‡ã§ãªãã‚‹ã¨å›è»¢ã€ãƒ”ãƒ³ãƒã§æ‹¡å¤§ã§ãã¾ã™ã€‚")
                    else:
                        st.warning("è¡¨ç¤ºãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

                st.divider()
                with st.container():
                    st.subheader("ğŸŒ æ¥­ç•Œãƒªã‚¹ã‚¯æƒ…å ±")
                    # ----- æ¥­ç•Œãƒªã‚¹ã‚¯æƒ…å ±ï¼ˆãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç›´ä¸‹ãƒ»ãƒ•ãƒ«å¹…ï¼‰ -----
                    net_summary = res.get("network_risk_summary", "") or ""
                    if net_summary.strip() and "å–å¾—ã§ãã¾ã›ã‚“" not in net_summary and "æ¤œç´¢ã‚¨ãƒ©ãƒ¼" not in net_summary:
                        st.text_area("ãƒãƒƒãƒˆæ¤œç´¢ã§å–å¾—ã—ãŸå€’ç”£ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»ãƒªã‚¹ã‚¯", value=net_summary[:1500] + ("â€¦" if len(net_summary) > 1500 else ""), height=120, disabled=True, label_visibility="collapsed")
                    else:
                        st.caption("åˆ¤å®šé–‹å§‹æ™‚ã«æ¥­ç•Œãƒªã‚¹ã‚¯ã‚’æ¤œç´¢ã—ã¾ã™ã€‚æœªå–å¾—ã®å ´åˆã¯å¯©æŸ»å…¥åŠ›ã§å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

                st.divider()
                with st.container():
                    st.subheader("ğŸ”® å¯©æŸ»çªç ´ã®ãŸã‚ã®AIã‚¢ãƒ‰ãƒã‚¤ã‚¹")
                    col_adv1, col_adv2 = st.columns(2)
                    with col_adv1:
                        st.subheader("ğŸ“‹ é¡ä¼¼æ¡ˆä»¶ã®ã€Œå‹ã¡ãƒ‘ã‚¿ãƒ¼ãƒ³ã€")
                        # -----------------------------------------------------
                        # [SAFETY] Ensure variables are defined for list comprehension
                        if "res" in locals():
                            selected_major = res.get("industry_major", "D å»ºè¨­æ¥­")
                            score_percent = res.get("score", 0)
                        else:
                            if "last_result" in st.session_state:
                                res_safety = st.session_state["last_result"]
                                selected_major = res_safety.get("industry_major", "D å»ºè¨­æ¥­")
                                score_percent = res_safety.get("score", 0)
                            else:
                                selected_major = "D å»ºè¨­æ¥­"
                                score_percent = 0
                        # -----------------------------------------------------
                        similar_success_cases = []
                        if load_all_cases():
                            cases = load_all_cases()
                            # -----------------------------------------------------
                            # [SAFETY] Ensure variables are defined for list comprehension
                            if "res" in locals():
                                selected_major = res.get("industry_major", "D å»ºè¨­æ¥­")
                                score_percent = res.get("score", 0)
                            else:
                                if "last_result" in st.session_state:
                                    res_safety = st.session_state["last_result"]
                                    selected_major = res_safety.get("industry_major", "D å»ºè¨­æ¥­")
                                    score_percent = res_safety.get("score", 0)
                                else:
                                    selected_major = "D å»ºè¨­æ¥­"
                                    score_percent = 0
                            # -----------------------------------------------------
                            similar_success_cases = [
                                c for c in cases 
                                if c.get("industry_major") == selected_major
                                and abs(c.get("result", {}).get("score", 0) - score_percent) < 15
                                and c.get("result", {}).get("score", 0) >= 70
                            ]

                        if similar_success_cases:
                            st.info(f"ã‚¹ã‚³ã‚¢ã‚„æ¥­ç¨®ãŒä¼¼ã¦ã„ã‚‹æ‰¿èªäº‹ä¾‹ãŒ {len(similar_success_cases)} ä»¶è¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚")
                            for i, c in enumerate(similar_success_cases[:3]): 
                                with st.expander(f"äº‹ä¾‹{i+1}: {c.get('industry_sub')} (ã‚¹ã‚³ã‚¢ {c['result']['score']:.0f})"):
                                    summary = c.get("chat_summary", "è©³ç´°ãªã—")
                                    st.write(f"**æ‰¿èªã®æ±ºã‚æ‰‹**: {summary}")
                        else:
                            st.warning("æ¡ä»¶ã®è¿‘ã„æˆåŠŸäº‹ä¾‹ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚")
                            # ãƒã‚¦ãƒã‚¦ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®ä»£æ›¿ææ¡ˆ
                            if "qualitative_appeal" in knowhow_data:
                                st.markdown("**ğŸ’¡ ä¸€èˆ¬çš„ãªå®šæ€§ã‚¢ãƒ”ãƒ¼ãƒ«ã®ãƒ’ãƒ³ãƒˆ:**")
                                for k in knowhow_data["qualitative_appeal"]:
                                    st.caption(f"- **{k['title']}**: {k['content']}")

                    with col_adv2:
                        st.subheader("ğŸ”§ æ±ºç®—æ›¸ãƒ»ã‚¹ã‚­ãƒ¼ãƒ èª¿æ•´ã®ãƒ’ãƒ³ãƒˆ")
                        advice_list = []
                        # ãƒã‚¦ãƒã‚¦ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®å¼•ç”¨ãƒ­ã‚¸ãƒƒã‚¯
                        if knowhow_data:
                            # è²¡å‹™æ”¹å–„
                            if user_equity_ratio < 20 and "financial_improvement" in knowhow_data:
                                k = knowhow_data["financial_improvement"][0] # å½¹å“¡å€Ÿå…¥é‡‘
                                advice_list.append(f"ğŸ’¡ **{k['title']}**: {k['content']}")
                            if user_op_margin < 0 and "financial_improvement" in knowhow_data:
                                k = knowhow_data["financial_improvement"][1] # èµ¤å­—é™¤å¤–
                                advice_list.append(f"ğŸ’¡ **{k['title']}**: {k['content']}")
                            # ã‚¹ã‚­ãƒ¼ãƒ 
                            if score_percent < 60 and "scheme_strategy" in knowhow_data:
                                k = knowhow_data["scheme_strategy"][1] # é€£å¸¯ä¿è¨¼
                                advice_list.append(f"ğŸ›¡ï¸ **{k['title']}**: {k['content']}")
                        # æ¥­ç¨®åˆ¥ãƒã‚¦ãƒã‚¦
                        ind_key = res["industry_major"].split(" ")[1] if " " in res["industry_major"] else res["industry_major"]
                        if "industry_specific" in knowhow_data and ind_key in knowhow_data["industry_specific"]:
                            advice_list.append(f"ğŸ­ **{ind_key}ã®é‰„å‰‡**: {knowhow_data['industry_specific'][ind_key]}")
                        if not advice_list:
                            advice_list.append("ç‰¹æ®µã®æ‡¸å¿µç‚¹ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚å®šæ€§é¢ï¼ˆå°å…¥åŠ¹æœï¼‰ã®å¼·åŒ–ã«é›†ä¸­ã—ã¦ãã ã•ã„ã€‚")
                        for advice in advice_list:
                            st.success(advice)
                        # è©²å½“æ¥­ç¨®ã®è£œåŠ©é‡‘ï¼ˆURLã§å…¬å¼ã‚µã‚¤ãƒˆã«ã™ãé£›ã¹ã‚‹ï¼‰
                        subs_adv = search_subsidies_by_industry(res.get("industry_sub", ""))
                        if subs_adv:
                            with st.expander("ğŸ“ è©²å½“æ¥­ç¨®ã®è£œåŠ©é‡‘ï¼ˆã‚¯ãƒªãƒƒã‚¯ã§å…¬å¼ã‚µã‚¤ãƒˆã¸ï¼‰", expanded=False):
                                for s in subs_adv:
                                    name = s.get("name") or ""
                                    url = (s.get("url") or "").strip()
                                    if url:
                                        st.markdown(f"**{name}**")
                                        try:
                                            st.link_button("ğŸ”— å…¬å¼ã‚µã‚¤ãƒˆã‚’é–‹ã", url, type="secondary")
                                        except Exception:
                                            safe_url = url.replace('"', "%22").replace("'", "%27")
                                            st.markdown(f'<a href="{safe_url}" target="_blank" rel="noopener noreferrer">ğŸ”— å…¬å¼ã‚µã‚¤ãƒˆã‚’é–‹ã</a>', unsafe_allow_html=True)
                                    else:
                                        st.markdown(f"**{name}**")
                                    st.caption((s.get("summary") or "")[:100] + "â€¦")
                                    st.caption(f"ç”³è«‹ç›®å®‰: {s.get('application_period')}")

                    # ======================================================================
                    # ğŸ“š ã“ã®æ¡ˆä»¶ã«ç´ã¥ããƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆè©³ç´°ã¯ã‚¨ã‚­ã‚¹ãƒ‘ãƒ³ãƒ€ãƒ¼ï¼‰
                    # ======================================================================
                    with st.expander("ğŸ“š ã“ã®æ¡ˆä»¶ã«ç´ã¥ããƒ‹ãƒ¥ãƒ¼ã‚¹", expanded=False):
                        if current_case_id:
                            case_news_list = load_case_news(current_case_id)
                            if case_news_list:
                                for idx, news in enumerate(case_news_list):
                                    with st.expander(f"{idx+1}. {news.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜')}"):
                                        st.caption(f"ä¿å­˜æ—¥æ™‚: {news.get('saved_at', 'N/A')}")
                                        if news.get("url"):
                                            st.markdown(f"[è¨˜äº‹URLã‚’é–‹ã]({news['url']})")
                                        content_preview = (news.get("content") or "")[:300]
                                        if content_preview:
                                            st.write(content_preview + ("..." if len(news.get("content", "")) > 300 else ""))
                                        if st.button("ã“ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’AIã«åæ˜ ã™ã‚‹", key=f"use_news_{idx}"):
                                            st.session_state.selected_news_content = {"title": news.get("title", ""), "content": news.get("content", "")}
                                            st.success("ã“ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ã€ä»¥é™ã®AIã‚¢ãƒ‰ãƒã‚¤ã‚¹ãƒ»ãƒ‡ã‚£ãƒ™ãƒ¼ãƒˆã§å‚ç…§ã™ã‚‹ã‚ˆã†ã«è¨­å®šã—ã¾ã—ãŸã€‚")
                            else:
                                st.caption("ã“ã®æ¡ˆä»¶ã«ã¯ã€ã¾ã ç´ã¥ã‘ã‚‰ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                        else:
                            st.caption("æ¡ˆä»¶IDãŒæœªå–å¾—ã®ãŸã‚ã€ç´ã¥ããƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ç‰¹å®šã§ãã¾ã›ã‚“ã€‚")

                st.divider()
                st.markdown("### ğŸ“Š è²¡å‹™ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯åˆ†æ")
                # 1. è²¡å‹™ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆã®æº–å‚™
                # ç°¡æ˜“åå·®å€¤ãƒ­ã‚¸ãƒƒã‚¯ (å¹³å‡=50, æ¨™æº–åå·®=é©å½“ã«ä»®å®š)
                def calc_hensachi(val, mean, is_higher_better=True):
                    if mean == 0: return 50
                    diff = (val - mean) / abs(mean) * 10 * (1 if is_higher_better else -1)
                    return max(20, min(80, 50 + diff))

                radar_metrics = {
                    "åç›Šæ€§": calc_hensachi(res['user_op'], res['bench_op']),
                    "å®‰å…¨æ€§": calc_hensachi(res['user_eq'], res['bench_eq']),
                    "åŠ¹ç‡æ€§": 50, # ä»®
                    "æˆé•·æ€§": 50, # ä»®
                    "è¿”æ¸ˆåŠ›": 50  # ä»®
                }
                radar_bench = {k: 50 for k in radar_metrics.keys()}

                # 2. éå»æ¡ˆä»¶ãƒ‡ãƒ¼ã‚¿å–å¾—
                past_cases = load_all_cases()

                # 3. ã‚°ãƒ©ãƒ•æç”»ã‚¨ãƒªã‚¢ï¼ˆPCã§å¤§ãããªã‚Šã™ããªã„ã‚ˆã†å¹…ã‚’åˆ¶é™ï¼‰
                col_graphs, _ = st.columns([0.65, 0.35])
                with col_graphs:
                    g1, g2 = st.columns(2)
                    with g1:
                        st.plotly_chart(plot_radar_chart_plotly(radar_metrics, radar_bench), use_container_width=True, key="radar_analysis")
                    with g2:
                        # æç›Šåˆ†å²ç‚¹ã‚°ãƒ©ãƒ•
                        sales_k = res["financials"]["nenshu"]
                        gross_k = res["financials"]["gross_profit"] * 1000
                        op_k = res["financials"]["rieki"] * 1000
                        vc = sales_k - gross_k
                        fc = gross_k - op_k
                        bep_fig = plot_break_even_point_plotly(sales_k, vc, fc)
                        if bep_fig:
                            st.plotly_chart(bep_fig, use_container_width=True, key="bep_analysis")
                        else:
                            fallback = plot_break_even_point(sales_k, vc, fc)
                            if fallback:
                                st.pyplot(fallback)

                # ========== ä¸­åˆ†é¡ã”ã¨ã«ãƒãƒƒãƒˆã§æ¥­ç•Œç›®å®‰ã‚’å–å¾—ã—ã¦æ¯”è¼ƒ ==========
                selected_sub = res.get("industry_sub", "")
                bench = dict(benchmarks_data.get(selected_sub, {}))
                try:
                    web_bench = fetch_industry_benchmarks_from_web(selected_sub)
                    for k in _WEB_BENCH_KEYS:
                        if web_bench.get(k) is not None:
                            bench[k] = web_bench[k]
                except Exception:
                    web_bench = {"snippets": [], "op_margin": None, "equity_ratio": None}

                with st.expander("ğŸŒ ä¸­åˆ†é¡ã”ã¨ã«ãƒãƒƒãƒˆã§èª¿ã¹ãŸæ¥­ç•Œç›®å®‰", expanded=False):
                    st.caption(f"æ¥­ç¨®ã€Œ{selected_sub}ã€ã®æ¥­ç•Œç›®å®‰ã§ã™ã€‚çµæœã¯ web_industry_benchmarks.json ã«ä¿å­˜ã•ã‚Œã€æ¯å¹´4æœˆ1æ—¥ã‚’å¢ƒã«1å¹´ã”ã¨ã«å†æ¤œç´¢ã—ã¾ã™ã€‚å–¶æ¥­åˆ©ç›Šç‡ãƒ»è‡ªå·±è³‡æœ¬æ¯”ç‡ãƒ»å£²ä¸Šé«˜ç·åˆ©ç›Šç‡ãƒ»ROAãƒ»æµå‹•æ¯”ç‡ãªã©æŠ½å‡ºã§ããŸæŒ‡æ¨™ã¯ã€ä¸‹ã®ã€Œç®—å‡ºå¯èƒ½æŒ‡æ¨™ã€ã®æ¥­ç•Œç›®å®‰ã«åæ˜ ã—ã¾ã™ã€‚")
                    if web_bench.get("snippets"):
                        for i, s in enumerate(web_bench["snippets"]):
                            st.markdown(f"**[{s['title']}]({s['href']})**")
                            st.caption(s["body"][:200] + ("..." if len(s["body"]) > 200 else ""))
                            st.divider()
                        extracted = [(k, web_bench[k]) for k in _WEB_BENCH_KEYS if web_bench.get(k) is not None]
                        if extracted:
                            u = lambda k: "å›" if k in ("asset_turnover", "fixed_asset_turnover") else "%"
                            parts = [f"{k}: {v:.1f}{u(k)}" for k, v in extracted]
                            st.success("æŠ½å‡ºã—ãŸæ¥­ç•Œç›®å®‰: " + ", ".join(parts[:8]) + (" â€¦" if len(parts) > 8 else ""))
                    else:
                        st.caption("æ¤œç´¢çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¾ãŸã¯æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

                with st.expander("ğŸ“ˆ æ¥­ç•Œãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆæ‹¡å……ï¼‰", expanded=False):
                    st.markdown(trend_info or "æ¥­ç•Œãƒˆãƒ¬ãƒ³ãƒ‰ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                    if st.button("ğŸ“¡ ã“ã®æ¥­ç¨®ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’ãƒãƒƒãƒˆã§æ¤œç´¢ã—ã¦æ‹¡å……", key="btn_extend_trend"):
                        with st.spinner("æ¤œç´¢ä¸­â€¦"):
                            try:
                                fetch_industry_trend_extended(selected_sub, force_refresh=True)
                                st.success("æ‹¡å……ã—ã¾ã—ãŸã€‚è¡¨ç¤ºã‚’æ›´æ–°ã—ã¾ã™ã€‚")
                                st.rerun()
                            except Exception as e:
                                st.error(f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")

                # ========== ç®—å‡ºå¯èƒ½æŒ‡æ¨™ï¼ˆå…¥åŠ›ã‹ã‚‰è¨ˆç®—ã—ãŸæœ‰åŠ¹æŒ‡æ¨™ï¼‰ ==========
                st.markdown("### ğŸ“ˆ ç®—å‡ºå¯èƒ½æŒ‡æ¨™")
                with st.expander("â„¹ï¸ æ¥­ç•Œç›®å®‰ã®å‡ºå…¸", expanded=False):
                    st.caption("æ¥­ç•Œç›®å®‰ã¯ã€ãƒãƒƒãƒˆæ¤œç´¢ã§ä¿å­˜ã—ãŸå€¤ï¼ˆweb_industry_benchmarks.jsonï¼‰ã‚’å„ªå…ˆã—ã€ä¸è¶³åˆ†ã‚’å¤§åˆ†é¡ã®æ¥­ç•Œå¹³å‡ï¼ˆindustry_averages.jsonï¼‰ã§è£œã£ã¦ã„ã¾ã™ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã€Œä»Šã®ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œç´¢ã—ã¦ä¿å­˜ã€ã§æŒ‡æ¨™ã®æ¥­ç•Œç›®å®‰ã‚‚æ¤œç´¢ãƒ»ä¿å­˜ã§ãã¾ã™ã€‚")
                fin = res.get("financials", {})
                # æ¥­ç•Œç›®å®‰ã‚’æ¥­ç•Œå¹³å‡ï¼ˆå¤§åˆ†é¡ï¼‰ã§è£œå¼·ï¼ˆå–ã‚Œã‚‹ã ã‘è¿½åŠ ï¼‰
                bench_ext = dict(bench) if bench else {}
                major = res.get("industry_major")
                if major and avg_data and major in avg_data:
                    avg = avg_data[major]
                    an = avg.get("nenshu") or 0
                    if an > 0:
                        if bench_ext.get("gross_margin") is None:
                            bench_ext["gross_margin"] = (avg.get("gross_profit") or 0) / an * 100
                        if bench_ext.get("ord_margin") is None:
                            bench_ext["ord_margin"] = (avg.get("ord_profit") or 0) / an * 100
                        if bench_ext.get("net_margin") is None:
                            bench_ext["net_margin"] = (avg.get("net_income") or 0) / an * 100
                        if bench_ext.get("dep_ratio") is None:
                            bench_ext["dep_ratio"] = (avg.get("depreciation") or 0) / an * 100
                    total_avg = (avg.get("machines") or 0) + (avg.get("other_assets") or 0) + (avg.get("bank_credit") or 0) + (avg.get("lease_credit") or 0)
                    if total_avg > 0:
                        if bench_ext.get("roa") is None:
                            bench_ext["roa"] = (avg.get("net_income") or 0) / total_avg * 100
                        if bench_ext.get("asset_turnover") is None:
                            bench_ext["asset_turnover"] = an / total_avg
                        if bench_ext.get("fixed_ratio") is None:
                            bench_ext["fixed_ratio"] = ((avg.get("machines") or 0) + (avg.get("other_assets") or 0)) / total_avg * 100
                        if bench_ext.get("debt_ratio") is None:
                            bench_ext["debt_ratio"] = ((avg.get("bank_credit") or 0) + (avg.get("lease_credit") or 0)) / total_avg * 100
                indicators = compute_financial_indicators(fin, bench_ext)
                if indicators:
                    # æ¥­ç•Œç›®å®‰ã‚ˆã‚Šè‰¯ã„ï¼ç·‘ã€æ‚ªã„ï¼èµ¤ï¼ˆLOWER_IS_BETTER_NAMES ã¯ä½ã„æ–¹ãŒè‰¯ã„ï¼‰
                    cell_style = "text-align:center; vertical-align:middle; padding:4px 6px;"
                    rows_html = []
                    for ind in indicators:
                        name = ind["name"]
                        value = ind["value"]
                        unit = ind.get("unit", "%")
                        bench = ind.get("bench")
                        bench_ok = bench is not None and (not isinstance(bench, float) or bench == bench)
                        if bench_ok:
                            diff = value - bench
                            is_good = (diff > 0 and name not in LOWER_IS_BETTER_NAMES) or (diff < 0 and name in LOWER_IS_BETTER_NAMES)
                            color = "#22c55e" if is_good else "#ef4444"
                            row_bg = "background-color:rgba(34,197,94,0.18);" if is_good else "background-color:rgba(239,68,68,0.12);"
                            name_cell = f'<span style="color:{color}; font-weight:600;">{name.replace("&", "&amp;").replace("<", "&lt;")}</span>'
                        else:
                            row_bg = ""
                            name_cell = name.replace("&", "&amp;").replace("<", "&lt;")
                        bench_str = f"{bench:.1f}{unit}" if bench_ok else "â€”"
                        rows_html.append(f"<tr style='{row_bg}'><td style='{cell_style}'>{name_cell}</td><td style='{cell_style}'>{value:.1f}{unit}</td><td style='{cell_style}'>{bench_str}</td></tr>")
                    table_html = (
                        "<table style='border-collapse:collapse; font-size:0.8rem; line-height:1.2; table-layout:fixed; width:100%;'>"
                        "<colgroup><col style='width:52%'><col style='width:24%'><col style='width:24%'></colgroup>"
                        "<thead><tr>"
                        f"<th style='{cell_style} font-weight:600;'>æŒ‡æ¨™</th><th style='{cell_style} font-weight:600;'>è²´ç¤¾</th><th style='{cell_style} font-weight:600;'>æ¥­ç•Œç›®å®‰</th>"
                        "</tr></thead><tbody>"
                        + "".join(rows_html) + "</tbody></table>"
                    )
                    st.markdown(
                        "<div style='max-width:400px; margin:0.25rem 0; overflow-x:auto;'>" + table_html + "</div>",
                        unsafe_allow_html=True,
                    )
                    st.caption("ç·‘ï¼æ¥­ç•Œã‚ˆã‚Šè‰¯ã„ / èµ¤ï¼è¦ç¢ºèª")
                    # æŒ‡æ¨™ã¨æ¥­ç•Œç›®å®‰ã®å·®ã®åˆ†æï¼ˆå›³ï¼‹æ–‡ç« ï¼‹AIã«ã‚ˆã‚‹æŒ‡æ¨™ã®åˆ†æï¼‰
                    summary, detail = analyze_indicators_vs_bench(indicators)
                    st.markdown("#### ğŸ“Š å·®ã®åˆ†æ")
                    col_sum, col_fig = st.columns([1, 1])
                    with col_sum:
                        st.info(summary)
                    fig_gap = plot_indicators_gap_analysis_plotly(indicators)
                    with col_fig:
                        if fig_gap:
                            st.plotly_chart(fig_gap, use_container_width=True, key="indicators_gap")
                    # æŒ‡æ¨™ã®åˆ†æï¼ˆAIï¼‰ï¼šåŒä¸€æ¡ˆä»¶ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒã‚ã‚Œã°è¡¨ç¤ºã€ãªã‘ã‚Œã°ãƒœã‚¿ãƒ³ã§ç”Ÿæˆ
                    _case_id = st.session_state.get("current_case_id")
                    _cached = st.session_state.get("indicator_ai_analysis")
                    _cached_case = st.session_state.get("indicator_ai_analysis_case_id")
                    if _cached and _cached_case == _case_id:
                        st.markdown("##### æŒ‡æ¨™ã®åˆ†æï¼ˆAIï¼‰")
                        st.markdown(_cached)
                    else:
                        st.markdown("##### æŒ‡æ¨™ã®åˆ†æï¼ˆAIï¼‰")
                        if st.button("AIã«æŒ‡æ¨™ã®åˆ†æã‚’ç”Ÿæˆ", key="gen_indicator_ai"):
                            if not is_ai_available():
                                if st.session_state.get("ai_engine") == "gemini":
                                    st.error("Gemini APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
                                else:
                                    st.error("Ollama ãŒèµ·å‹•ã—ã¦ã„ãªã„ã‹ã€Gemini ã«åˆ‡ã‚Šæ›¿ãˆã¦ãã ã•ã„ã€‚")
                            else:
                                ind_list = "\n".join([f"- {x['name']}: è²´ç¤¾ {x['value']:.1f}{x.get('unit','%')} / æ¥­ç•Œç›®å®‰ {x['bench']:.1f}{x.get('unit','%')}" if x.get("bench") is not None else f"- {x['name']}: è²´ç¤¾ {x['value']:.1f}{x.get('unit','%')}" for x in indicators])
                                prompt = f"""ã‚ãªãŸã¯ãƒªãƒ¼ã‚¹å¯©æŸ»ã®ãƒ—ãƒ­ã§ã™ã€‚ä»¥ä¸‹ã®ã€ŒæŒ‡æ¨™ã¨æ¥­ç•Œç›®å®‰ã®å·®ã®åˆ†æã€ã‚’è¸ã¾ãˆã€ã“ã®ä¼æ¥­ã®è²¡å‹™æŒ‡æ¨™ã«ã¤ã„ã¦2ã€œ4æ–‡ã§ç°¡æ½”ã«åˆ†æã—ã¦ãã ã•ã„ã€‚
ãƒ»å¼·ã¿ï¼ˆæ¥­ç•Œç›®å®‰ã‚’ä¸Šå›ã£ã¦ã„ã‚‹ç‚¹ï¼‰ãŒã‚ã‚Œã°è§¦ã‚Œã‚‹ã€‚
ãƒ»æ¥­ç•Œç›®å®‰ã‚’ä¸‹å›ã£ã¦ã„ã‚‹æŒ‡æ¨™ãŒã‚ã‚Œã°ã€ãªãœãã†ãªã£ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã‹ãƒ»æ”¹å–„ã®æ–¹å‘æ€§ã‚’1ã€œ2æ–‡ã§è¿°ã¹ã‚‹ã€‚
ãƒ»å€Ÿå…¥é‡‘ç­‰ä¾å­˜åº¦ãƒ»å›ºå®šæ¯”ç‡ãªã©ã€Œä½ã„æ–¹ãŒè‰¯ã„ã€æŒ‡æ¨™ã®è§£é‡ˆã‚‚å«ã‚ã‚‹ã€‚
æ•°å€¤ã¯æ—¢ã«ã¾ã¨ã‚ã«ã‚ã‚‹ã®ã§ã€é‡è¤‡ã›ãšè¦ç‚¹ã ã‘æ›¸ã„ã¦ãã ã•ã„ã€‚

ã€è¦ç´„ã€‘
{summary}

ã€å·®ã®å†…è¨³ã€‘
{detail}

ã€æŒ‡æ¨™ä¸€è¦§ã€‘
{ind_list}
"""
                                with st.spinner("AIãŒæŒ‡æ¨™ã‚’åˆ†æã—ã¦ã„ã¾ã™..."):
                                    try:
                                        ans = chat_with_retry(model=get_ollama_model(), messages=[{"role": "user", "content": prompt}], timeout_seconds=90)
                                        content = (ans.get("message") or {}).get("content", "")
                                        if content and "APIã‚­ãƒ¼ãŒ" not in content and "ã‚¨ãƒ©ãƒ¼" not in content[:50]:
                                            st.session_state["indicator_ai_analysis"] = content
                                            st.session_state["indicator_ai_analysis_case_id"] = _case_id
                                            st.rerun()
                                        else:
                                            st.error(content or "AIã®å¿œç­”ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                                    except Exception as e:
                                        st.error(f"åˆ†æã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                        else:
                            st.caption("ä¸Šã®ã€ŒAIã«æŒ‡æ¨™ã®åˆ†æã‚’ç”Ÿæˆã€ã‚’æŠ¼ã™ã¨ã€æ¥­ç•Œç›®å®‰ã¨ã®å·®ã‚’è¸ã¾ãˆãŸåˆ†ææ–‡ã‚’AIãŒç”Ÿæˆã—ã¾ã™ã€‚")
                        st.caption("å·¦ï¼è¦ç¢ºèª / å³ï¼è‰¯ã„ã€‚å€Ÿå…¥é‡‘ç­‰ä¾å­˜åº¦ãƒ»æ¸›ä¾¡å„Ÿå´è²»/å£²ä¸Šã¯ä½ã„ã¨ç·‘ã€‚")
                        with st.expander("å·®ã®å†…è¨³ï¼ˆæ•°å€¤ï¼‰", expanded=False):
                            st.markdown(detail)
                        # åˆ©ç›Šæ§‹é€ ï¼ˆã‚¦ã‚©ãƒ¼ã‚¿ãƒ¼ãƒ•ã‚©ãƒ¼ãƒ«ï¼‰
                        nenshu_k = fin.get("nenshu") or 0
                        gross_k = fin.get("gross_profit") or 0
                        op_k = fin.get("rieki") or fin.get("op_profit") or 0
                        ord_k = fin.get("ord_profit") or 0
                        net_k = fin.get("net_income") or 0
                        if nenshu_k > 0:
                            st.markdown("#### åˆ©ç›Šæ§‹é€ ")
                            col_wf, _ = st.columns([0.65, 0.35])
                            with col_wf:
                                st.plotly_chart(plot_waterfall_plotly(nenshu_k, gross_k, op_k, ord_k, net_k), use_container_width=True, key="waterfall_result")
                else:
                    st.caption("æŒ‡æ¨™ã‚’ç®—å‡ºã™ã‚‹ã«ã¯ã€å¯©æŸ»å…¥åŠ›ã§å£²ä¸Šé«˜ãƒ»æç›Šãƒ»è³‡ç”£ãªã©ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

                # AIã®ã¼ã‚„ãï¼ˆãƒãƒƒãƒˆæ¤œç´¢ã—ãŸæ¥­ç•Œæƒ…å ±ã‚’ä½¿ã„AIãŒè‡ªåˆ†ã§ç”Ÿæˆãƒ»ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆï¼‰+ å®šä¾‹ã®æ„šç—´
                st.divider()
                st.subheader("ğŸ¤– AIã®ã¼ã‚„ã")
                u_eq = res.get("user_eq", 0)
                u_op = res.get("user_op", 0)
                comp_text = res.get("comparison", "")
                net_risk = res.get("network_risk_summary", "") or ""
                selected_sub_res = res.get("industry_sub", "")
                byoki_case_id = st.session_state.get("ai_byoki_case_id")
                byoki_text = st.session_state.get("ai_byoki_text")
                if byoki_text and byoki_case_id == current_case_id:
                    st.info("ğŸŸ " + byoki_text)
                    if st.button("ã¼ã‚„ãã‚’å†ç”Ÿæˆï¼ˆæ¥­ç•Œæƒ…å ±ã‚’å†å–å¾—ï¼‰", key="btn_byoki_regenerate"):
                        st.session_state["ai_byoki_text"] = None
                        st.session_state["ai_byoki_case_id"] = None
                        st.rerun()
                else:
                    if st.button("AIã«ã¼ã‚„ãã‚’è¨€ã‚ã›ã‚‹ï¼ˆæ¥­ç•Œæƒ…å ±ã‚’å‚ç…§ï¼‰", key="btn_byoki_generate"):
                        with st.spinner("æ¥­ç•Œæƒ…å ±ã‚’å–å¾—ã—ã¦ã€AIãŒã¼ã‚„ãã‚’è€ƒãˆã¦ã„ã¾ã™â€¦"):
                            text = get_ai_byoki_with_industry(selected_sub_res, u_eq, u_op, comp_text, net_risk)
                            if text:
                                st.session_state["ai_byoki_text"] = text
                                st.session_state["ai_byoki_case_id"] = current_case_id
                                st.rerun()
                            else:
                                st.error("ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚APIã‚­ãƒ¼ãƒ»Ollamaã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                    if not byoki_text:
                        st.caption("ä¸Šã®ãƒœã‚¿ãƒ³ã§ã€ãƒãƒƒãƒˆæ¤œç´¢ã—ãŸæ¥­ç•Œæƒ…å ±ã‚’ã‚‚ã¨ã«AIãŒæ„šç—´ã‚’1ã¤ç”Ÿæˆã—ã¾ã™ã€‚")

                # ----- ã‚«ãƒ¼ãƒ‰ãƒãƒˆãƒ«ï¼ˆåˆ¥æ ãƒ»é–‹ç™ºä¸­ï¼‰ -----
                with st.expander("âš”ï¸ å¯©æŸ»å§”å“¡ä¼šã‚«ãƒ¼ãƒ‰ãƒãƒˆãƒ«ï¼ˆé–‹ç™ºä¸­ï¼‰", expanded=False):
                    st.caption("åˆ¤å®šçµæœã‚’ã‚«ãƒ¼ãƒ‰ãƒãƒˆãƒ«é¢¨ã«æŒ¯ã‚Šè¿”ã‚Šã¾ã™ã€‚ä»•æ§˜ã¯å¤‰æ›´ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
                    if "battle_data" in st.session_state and res:
                        bd = st.session_state["battle_data"]
                        if bd.get("special_move_name") is None:
                            strength_tags = res.get("strength_tags") or []
                            passion_text = res.get("passion_text") or ""
                            name, effect = generate_battle_special_move(strength_tags, passion_text)
                            bd["special_move_name"] = name
                            bd["special_effect"] = effect
                            score = bd.get("score", 0)
                            log_lines = [
                                "ã€å®Ÿæ³ã€‘å¯©æŸ»å§”å“¡ä¼šã€é–‹å»·ã€‚",
                                "æ…é‡æ´¾ã€Œæ•°å€¤ã ã‘è¦‹ã‚‹ã¨å³ã—ã„ãŒã€æ¥­ç•Œç›¸å¯¾ã§è¦‹ã‚‹ã¹ãã ã€‚ã€",
                                f"æ¨é€²æ´¾ã€Œã‚¹ã‚³ã‚¢{score:.0f}%ã€‚é€†è»¢ææ–™ãŒã‚ã‚Œã°ååˆ†æˆ¦ãˆã‚‹ã€‚ã€" if score < 75 else "æ¨é€²æ´¾ã€Œã‚¹ã‚³ã‚¢ã¯ååˆ†åœå†…ã€‚å®šæ€§é¢ã‚’ç¢ºèªã—ã‚ˆã†ã€‚ã€",
                                "ã€è­°äº‹ã€‘å®šæ€§ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ã‚’æ¤œè¨ä¸­â€¦",
                            ]
                            similar_prompt = res.get("similar_past_cases_prompt", "")
                            if similar_prompt and "éå»ã®é¡ä¼¼æ¡ˆä»¶" in similar_prompt:
                                log_lines.append("æ…é‡æ´¾ã€Œéå»ã®é¡ä¼¼æ¡ˆä»¶ã‚’å‚ç…§ã—ãŸã€‚åŒæ§˜ã®ã‚±ãƒ¼ã‚¹ã§ã¯æˆç´„ä¾‹ã‚ã‚Šã€‚ã€")
                            log_lines.append("ã€åˆ¤å®šã€‘æ¡æ±ºã«å…¥ã‚Šã¾ã™ã€‚")
                            bd["battle_log"] = log_lines
                            bd["dice"] = random.randint(1, 6)
                            st.session_state["battle_data"] = bd
                        bd = st.session_state["battle_data"]
                        c1, c2, c3 = st.columns(3)
                        with c1:
                            st.markdown(f"""
                            <div style="background:linear-gradient(135deg,#1e3a5f 0%,#334155 100%);color:#fff;padding:1rem;border-radius:12px;text-align:center;">
                            <div style="font-size:0.85rem;opacity:0.9;">HP</div>
                            <div style="font-size:1.8rem;font-weight:bold;">{bd['hp']}</div>
                            <div style="font-size:0.75rem;">è‡ªå·±è³‡æœ¬</div>
                            </div>
                            """, unsafe_allow_html=True)
                        with c2:
                            st.markdown(f"""
                            <div style="background:linear-gradient(135deg,#b45309 0%,#c2410c 100%);color:#fff;padding:1rem;border-radius:12px;text-align:center;">
                            <div style="font-size:0.85rem;opacity:0.9;">ATK</div>
                            <div style="font-size:1.8rem;font-weight:bold;">{bd['atk']}</div>
                            <div style="font-size:0.75rem;">åˆ©ç›Šç‡</div>
                            </div>
                            """, unsafe_allow_html=True)
                        with c3:
                            st.markdown(f"""
                            <div style="background:linear-gradient(135deg,#0d9488 0%,#0f766e 100%);color:#fff;padding:1rem;border-radius:12px;text-align:center;">
                            <div style="font-size:0.85rem;opacity:0.9;">SPD</div>
                            <div style="font-size:1.8rem;font-weight:bold;">{bd['spd']}</div>
                            <div style="font-size:0.75rem;">æµå‹•æ€§</div>
                            </div>
                            """, unsafe_allow_html=True)
                        st.markdown("**ğŸ´ å¿…æ®ºæŠ€**")
                        st.markdown(f"""
                        <div style="background:#f8fafc;border:2px solid #b45309;border-radius:10px;padding:1rem;">
                        <span style="font-weight:bold;color:#1e3a5f;">{bd.get('special_move_name', 'é€†è»¢ã®æ„æ°—')}</span>
                        <span style="color:#64748b;"> â€¦ </span>
                        <span>{bd.get('special_effect', 'ã‚¹ã‚³ã‚¢+5%')}</span>
                        </div>
                        """, unsafe_allow_html=True)
                        for eff in (bd.get("environment_effects") or []):
                            st.caption(f"â€¢ {eff}")
                        st.markdown("**ğŸ“œ ãƒãƒˆãƒ«å®Ÿæ³**")
                        for line in bd.get("battle_log", []):
                            st.caption(line)
                        dice = bd.get("dice") or 1
                        st.caption(f"ğŸ² é‹å‘½ã®ãƒ€ã‚¤ã‚¹: **{dice}** â†’ {'ã‚„ã‚„æœ‰åˆ©' if dice >= 4 else 'ã‚„ã‚„ä¸åˆ©'}")
                        if bd.get("is_approved"):
                            st.success("ğŸ† WIN â€” æ‰¿èªåœå†…")
                        else:
                            st.info("ğŸ“‹ LOSE â€” è¦å¯©è­°")
                    else:
                        st.caption("åˆ¤å®šã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€ã“ã“ã«ã‚«ãƒ¼ãƒ‰ãƒãƒˆãƒ«ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")

            else:
                st.info('ğŸ‘ˆ å·¦å´ã®ã€Œå¯©æŸ»å…¥åŠ›ã€ã‚¿ãƒ–ã§ãƒ‡ãƒ¼ã‚¿ã‚’å…¥åŠ›ã—ã€å¯©æŸ»ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚')
    with col_right:
        # Ensure selected_sub is up-to-date for chat
        if "last_result" in st.session_state:
            selected_sub = st.session_state["last_result"].get("industry_sub", selected_sub)
        st.header("ğŸ’¬ AIå¯©æŸ»ã‚ªãƒ•ã‚£ã‚µãƒ¼ã«ç›¸è«‡")
        st.caption(f"é¸æŠä¸­ã®æ¥­ç¨®: {selected_sub}")
        
        tab_chat, tab_debate = st.tabs(["ç›¸è«‡ãƒ¢ãƒ¼ãƒ‰", "âš”ï¸ è¨è«–ãƒ¢ãƒ¼ãƒ‰"])

        # ç¾åœ¨ã®AIã‚¨ãƒ³ã‚¸ãƒ³ã¨APIã‚­ãƒ¼çŠ¶æ…‹ã‚’è¡¨ç¤ºï¼ˆGeminiæ™‚ã¯ã€Œæœªè¨­å®šã€ã ã¨å‹•ã‹ãªã„ã®ã§æ˜ç¤ºï¼‰
        _engine = st.session_state.get("ai_engine", "ollama")
        if _engine == "gemini":
            _key_ok = bool(
                (st.session_state.get("gemini_api_key") or "").strip()
                or GEMINI_API_KEY_ENV
                or _get_gemini_key_from_secrets()
            )
            st.caption(f"ğŸ¤– ä½¿ç”¨ä¸­: **Gemini API**ã€€ï½œã€€APIã‚­ãƒ¼: **{'è¨­å®šæ¸ˆã¿' if _key_ok else 'æœªè¨­å®šï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ã§å…¥åŠ›ï¼‰'}**")
            with st.expander("ğŸ”§ Gemini ãƒ‡ãƒãƒƒã‚°ï¼ˆå‹•ã‹ãªã„ã¨ãã«é–‹ãï¼‰", expanded=False):
                _dbg = st.session_state.get("last_gemini_debug", "ã¾ã å‘¼ã³å‡ºã—ã¦ã„ã¾ã›ã‚“")
                st.text(_dbg)
                st.caption("ç›¸è«‡ã§é€ä¿¡å¾Œã€ã“ã“ã«ã€ŒOKã€ã¾ãŸã¯ã‚¨ãƒ©ãƒ¼å†…å®¹ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
        else:
            st.caption("ğŸ¤– ä½¿ç”¨ä¸­: **Ollamaï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ï¼‰**")
        
        with tab_chat:
            # éŸ³å£°å…¥åŠ›ã‹ã‚‰æˆ»ã£ãŸã¨ãã®ãƒ†ã‚­ã‚¹ãƒˆã‚’åæ˜ ï¼ˆURLã® ?voice_text=... ã§æ¸¡ã•ã‚Œã‚‹ï¼‰
            if st.query_params.get("voice_text"):
                st.session_state["consultation_input"] = st.query_params.get("voice_text", "")
                try:
                    st.experimental_set_query_params()
                except Exception:
                    pass
                st.rerun()
            if "messages" not in st.session_state: st.session_state.messages = []
            if "consultation_input" not in st.session_state: st.session_state["consultation_input"] = ""
            # é€ä¿¡æ¸ˆã¿ã®å ´åˆã¯å…¥åŠ›æ¬„ã‚’ç©ºã«ã™ã‚‹ï¼ˆtext_area ä½œæˆå‰ã«ã®ã¿ session_state ã‚’å¤‰æ›´å¯èƒ½ï¼‰
            if "consultation_pending_q" in st.session_state:
                st.session_state["consultation_input"] = ""

            chat_box = st.container(height=400)
            with chat_box:
                for m in st.session_state.messages:
                    if m["role"] != "system":
                        with st.chat_message(m["role"]): st.markdown(m["content"])
            
            # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§APIå¿œç­”å¾…ã¡ä¸­ â†’ ã‚¯ãƒ«ã‚¯ãƒ«è¦‹ã›ã‚‹ãŸã‚ã«ãƒãƒ¼ãƒªãƒ³ã‚°
            # ã‚¹ãƒ¬ãƒƒãƒ‰çµæœã¯ _chat_result_holder ã§å—ã‘å–ã‚‹ï¼ˆsession_state ã¯ã‚¹ãƒ¬ãƒƒãƒ‰ã‹ã‚‰åæ˜ ã•ã‚Œãªã„ãŸã‚ï¼‰
            CHAT_LOADING_TIMEOUT = 125  # ç§’ï¼ˆAPIå´ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚ˆã‚Šå°‘ã—é•·ã‚ï¼‰
            if _chat_result_holder["done"]:
                result = _chat_result_holder["result"]
                _chat_result_holder["result"] = None
                _chat_result_holder["done"] = False
                st.session_state["chat_result"] = result
                st.session_state["chat_loading"] = False
                if st.session_state.get("ai_engine") == "gemini" and result:
                    c = (result.get("message") or {}).get("content", "")
                    st.session_state["last_gemini_debug"] = "OK" if c and "APIã‚­ãƒ¼ãŒ" not in c and "Gemini API ã‚¨ãƒ©ãƒ¼:" not in c else (c[:200] + "..." if len(c or "") > 200 else (c or "ï¼ˆç©ºï¼‰"))
            chat_loading = st.session_state.get("chat_loading", False)
            chat_result = st.session_state.get("chat_result")
            # å¾…æ©Ÿã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼šä¸€å®šæ™‚é–“å¿œç­”ãŒãªã‘ã‚Œã°å¼·åˆ¶è§£é™¤
            loading_started = st.session_state.get("chat_loading_started_at")
            if chat_loading and loading_started is not None and (time.time() - loading_started) > CHAT_LOADING_TIMEOUT:
                st.session_state["chat_loading"] = False
                _chat_result_holder["done"] = True
                _chat_result_holder["result"] = {"message": {"content": "å¿œç­”ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸï¼ˆç´„2åˆ†ï¼‰ã€‚\n\nãƒ»APIã‚­ãƒ¼ãƒ»ãƒãƒƒãƒˆæ¥ç¶šã‚’ç¢ºèªã™ã‚‹ã‹ã€ã‚‚ã†ä¸€åº¦é€ä¿¡ã—ã¦ãã ã•ã„ã€‚\nãƒ»Gemini ã®å ´åˆã¯ç„¡æ–™æ ã®åˆ¶é™ã«é”ã—ã¦ã„ã‚‹å¯èƒ½æ€§ã‚‚ã‚ã‚Šã¾ã™ã€‚"}}
                st.rerun()
            if chat_loading or chat_result is not None:
                with chat_box:
                    for m in st.session_state.messages:
                        if m["role"] != "system":
                            with st.chat_message(m["role"]): st.markdown(m["content"])
                    with st.chat_message("assistant"):
                        if chat_result is not None:
                            content = (chat_result.get("message") or {}).get("content", "")
                            if content and (
                                "APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“" in content
                                or "Gemini API ã‚¨ãƒ©ãƒ¼:" in content
                                or "pip install" in content
                                or "å¿œç­”ãŒè¿”ã‚Šã¾ã›ã‚“ã§ã—ãŸ" in content
                                or "å®‰å…¨ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã§ãƒ–ãƒ­ãƒƒã‚¯" in content
                            ):
                                st.error(content)
                            st.markdown(content or "ï¼ˆå¿œç­”ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼‰")
                            st.session_state.messages.append({"role": "assistant", "content": content or "ï¼ˆå¿œç­”ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼‰"})
                            # ãƒ›ãƒ«ãƒ€ãƒ¼çµŒç”±ã®å¿œç­”ã‚‚ç›¸è«‡ãƒ¡ãƒ¢ã«ä¿å­˜ï¼ˆè©±ã›ã°è©±ã™ã»ã©è“„ç©ï¼‰
                            user_msgs = [m["content"] for m in st.session_state.messages if m.get("role") == "user"]
                            if user_msgs:
                                append_consultation_memory(user_msgs[-1], content or "ï¼ˆå¿œç­”ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼‰")
                            st.session_state["chat_loading"] = False
                            st.session_state["chat_result"] = None
                        else:
                            with st.status("æ€è€ƒä¸­...", state="running", expanded=True):
                                st.markdown("â³ å¿œç­”ã‚’å¾…ã£ã¦ã„ã¾ã™...")
                                if st.button("å¾…æ©Ÿã‚’ã‚„ã‚ã‚‹", key="chat_cancel_loading"):
                                    st.session_state["chat_loading"] = False
                                    _chat_result_holder["done"] = True
                                    _chat_result_holder["result"] = {"message": {"content": "å¾…æ©Ÿã‚’è§£é™¤ã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦é€ä¿¡ã™ã‚‹ã‹ã€APIã‚­ãƒ¼ãƒ»ãƒãƒƒãƒˆæ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"}}
                                    st.rerun()
                            time.sleep(1)
                            st.rerun()

            # å®šæ€§æƒ…å ±ãƒ»ç›¸è«‡å…¥åŠ›ï¼ˆtext_area + éŸ³å£°å…¥åŠ›ãƒœã‚¿ãƒ³ + é€ä¿¡ï¼‰
            st.text_area("ç›¸è«‡å†…å®¹", value=st.session_state.get("consultation_input", ""), key="consultation_input", height=100, placeholder="ç›¸è«‡ã™ã‚‹å†…å®¹ã‚’å…¥åŠ›...ï¼ˆä¸‹ã®ğŸ¤ã§éŸ³å£°å…¥åŠ›ã‚‚ã§ãã¾ã™ï¼‰", label_visibility="collapsed")
            voice_html = """
            <script>
            function startVoiceInput() {
                if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
                    alert('ãŠä½¿ã„ã®ãƒ–ãƒ©ã‚¦ã‚¶ã¯éŸ³å£°å…¥åŠ›ã«å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ã€‚Chrome ãªã©ã§ãŠè©¦ã—ãã ã•ã„ã€‚');
                    return;
                }
                var SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                var rec = new SpeechRecognition();
                rec.lang = 'ja-JP';
                rec.continuous = false;
                rec.interimResults = false;
                rec.onresult = function(e) {
                    var t = e.results[0][0].transcript;
                    var u = window.parent.location.pathname + '?voice_text=' + encodeURIComponent(t);
                    window.parent.location = u;
                };
                rec.onerror = function(e) {
                    if (e.error === 'not-allowed') alert('ãƒã‚¤ã‚¯ã®åˆ©ç”¨ãŒè¨±å¯ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚');
                    else alert('éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: ' + e.error);
                };
                rec.start();
            }
            </script>
            <button type="button" onclick="startVoiceInput()" style="padding: 8px 16px; font-size: 1rem; cursor: pointer; border-radius: 8px; background: #f0f2f6; border: 1px solid #ccc;">
            ğŸ¤ éŸ³å£°å…¥åŠ›
            </button>
            """
            # ã‚³ãƒ¡ãƒ³ãƒˆæ¬„ãŒå³ã§åˆ‡ã‚Œãªã„ã‚ˆã†ã€å…¥åŠ›è¡Œã¯ã‚«ãƒ©ãƒ å¹…ã‚’æŠ‘ãˆã‚‹
            btn_col1, btn_col2 = st.columns([1, 3])
            with btn_col1:
                st.components.v1.html(voice_html, height=50)
            with btn_col2:
                send_clicked = st.button("é€ä¿¡", key="consultation_send", type="primary")
            if send_clicked and (st.session_state.get("consultation_input") or "").strip():
                st.session_state["consultation_pending_q"] = (st.session_state.get("consultation_input") or "").strip()
                st.rerun()

            q = None
            if st.session_state.get("consultation_pending_q"):
                q = st.session_state.pop("consultation_pending_q")
                st.session_state.messages.append({"role": "user", "content": q})
            if q:
                with chat_box:
                    with st.chat_message("user"): st.markdown(q)
                    with st.chat_message("assistant"):
                        if not is_ai_available():
                            if st.session_state.get("ai_engine") == "gemini":
                                st.error("Gemini APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã€ŒAIãƒ¢ãƒ‡ãƒ«è¨­å®šã€ã§å…¥åŠ›ã™ã‚‹ã‹ã€ç’°å¢ƒå¤‰æ•° GEMINI_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
                            else:
                                st.error(f"AIã‚µãƒ¼ãƒãƒ¼ï¼ˆOllamaï¼‰ãŒèµ·å‹•ã—ã¦ã„ã¾ã›ã‚“ã€‚\nã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ `ollama serve` ã‚’å®Ÿè¡Œã™ã‚‹ã‹ã€ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã€ŒGemini APIã€ã«åˆ‡ã‚Šæ›¿ãˆã¦ãã ã•ã„ã€‚")
                        else:
                            _res = st.session_state.get("last_result") or {}
                            comparison_text = _res.get("comparison", "ï¼ˆå¯©æŸ»æœªå®Ÿè¡Œã®ãŸã‚ãƒ‡ãƒ¼ã‚¿ãªã—ï¼‰")
                            trend_info = "ï¼ˆå¯©æŸ»æœªå®Ÿè¡Œã®ãŸã‚ãƒ‡ãƒ¼ã‚¿ãªã—ï¼‰"
                            if jsic_data and _res.get("industry_major") in (jsic_data or {}):
                                trend_info = (jsic_data[_res["industry_major"]].get("sub") or {}).get(_res.get("industry_sub", ""), trend_info)
                            hints_context = ""
                            if 'last_result' in st.session_state:
                                h = st.session_state['last_result'].get('hints', {})
                                if h.get('subsidies'): hints_context += f"\nè£œåŠ©é‡‘å€™è£œ: {', '.join(h['subsidies'])}"
                                if h.get('risks'): hints_context += f"\nãƒªã‚¹ã‚¯ç¢ºèªç‚¹: {', '.join(h['risks'])}"
                            advice_extras = ""
                            if "last_result" in st.session_state:
                                res_adv = st.session_state["last_result"]
                                advice_extras = get_advice_context_extras(res_adv.get("industry_sub", ""), res_adv.get("industry_major", ""))
                            news_context = ""
                            if 'selected_news_content' in st.session_state:
                                news = st.session_state.selected_news_content
                                news_context = f"\n\nã€èª­ã¿è¾¼ã¿æ¸ˆã¿ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆå¿…ãšå†…å®¹ã«è§¦ã‚Œã‚‹ã“ã¨ï¼‰ã€‘\nã‚¿ã‚¤ãƒˆãƒ«: {news['title']}\næœ¬æ–‡:\n{news['content']}"
                            hints_block = ("â–  è£œåŠ©é‡‘ãƒ»ãƒªã‚¹ã‚¯ãƒ’ãƒ³ãƒˆ: " + hints_context) if hints_context else ""
                            advice_block = ("â–  è£œåŠ©é‡‘ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ»ãƒªãƒ¼ã‚¹åˆ¤å®šãƒ»è€ç”¨å¹´æ•°ãƒ»æ¥­ç•Œæ‹¡å……ç­‰:\n" + advice_extras) if advice_extras else ""
                            ind_summary, ind_detail, ind_list = get_indicator_analysis_for_advice(_res)
                            indicator_block = ""
                            if ind_summary or ind_list:
                                indicator_block = "\nâ–  æŒ‡æ¨™ã®åˆ†æï¼ˆè²´ç¤¾ vs æ¥­ç•Œç›®å®‰ï¼‰\n"
                                if ind_summary:
                                    indicator_block += f"è¦ç´„: {ind_summary}\n\n"
                                if ind_list:
                                    indicator_block += "æŒ‡æ¨™ä¸€è¦§:\n" + ind_list + "\n\n"
                                if ind_detail:
                                    indicator_block += "å·®ã®å†…è¨³:\n" + ind_detail[:1500] + "\n"
                            # éå»ã®ç›¸è«‡ãƒ¡ãƒ¢ï¼ˆè©±ã›ã°è©±ã™ã»ã©è“„ç©ï¼‰ã‚’èª­ã¿è¾¼ã¿ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å«ã‚ã‚‹
                            memory_entries = load_consultation_memory(max_entries=15)
                            memory_block = ""
                            if memory_entries:
                                parts = []
                                for e in memory_entries:
                                    u = (e.get("user") or "").strip()
                                    a = (e.get("assistant") or "").strip()
                                    if u or a:
                                        parts.append(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼: {u[:800]}\nAI: {a[:1200]}")
                                if parts:
                                    memory_block = "\n\nã€éå»ã®ç›¸è«‡ã§è©±ã—ãŸã“ã¨ï¼ˆè©±ã›ã°è©±ã™ã»ã©è“„ç©ãƒ»å‚ç…§ã—ã¦ç¶šãã§ç­”ãˆã‚‹ï¼‰ã€‘\n" + "\n---\n".join(parts[-15:]) + "\n"
                            context_prompt = f"""ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªãƒªãƒ¼ã‚¹å¯©æŸ»ã®ãƒ—ãƒ­ã€‚ä»¥ä¸‹ã®ã€Œå‚è€ƒãƒ‡ãƒ¼ã‚¿ã€ã‚’å¿…ãšä½¿ã£ã¦ã€å…·ä½“çš„ã«ç­”ãˆã¦ãã ã•ã„ã€‚æ•°å­—ã‚„ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®å†…å®¹ã‚’å¼•ç”¨ã™ã‚‹ã¨èª¬å¾—åŠ›ãŒå¢—ã—ã¾ã™ã€‚

ã€å‚è€ƒãƒ‡ãƒ¼ã‚¿ã€‘
â–  è²¡å‹™ãƒ»æ¯”è¼ƒ: {comparison_text}
â–  æ¥­ç•Œãƒˆãƒ¬ãƒ³ãƒ‰: {trend_info}
{hints_block}
{advice_block}
{indicator_block}
{news_context}
{memory_block}

ã€ãƒ«ãƒ¼ãƒ«ã€‘
- ä¸Šè¨˜ã®ãƒ‡ãƒ¼ã‚¿ã«è§¦ã‚Œãšã«ä¸€èˆ¬è«–ã ã‘ã§ç­”ãˆãªã„ã“ã¨ã€‚
- ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒã‚ã‚‹å ´åˆã¯ãã®å†…å®¹ã‚„æ¥­ç•Œå‹•å‘ã‚’è¸ã¾ãˆãŸåŠ©è¨€ã‚’ã™ã‚‹ã“ã¨ã€‚
- æŒ‡æ¨™ã®åˆ†æãŒã‚ã‚‹å ´åˆï¼š**æ¥­ç•Œç›®å®‰ã‚’ä¸Šå›ã£ã¦ã„ã‚‹æŒ‡æ¨™ã¯è‰¯ã„ã“ã¨ãªã®ã§è¤’ã‚ã‚‹ã€‚æ¥­ç•Œç›®å®‰ã‚’ä¸‹å›ã£ã¦ã„ã‚‹æŒ‡æ¨™ã«ã¤ã„ã¦ã ã‘**ã€Œãªãœä¸‹å›ã£ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã‹ã€ã€Œã©ã†æ”¹å–„ã™ã‚‹ã¨ã‚ˆã„ã‹ã€ã‚’ç°¡æ½”ã«ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã™ã‚‹ã“ã¨ã€‚ä¸Šå›ã£ã¦ã„ã‚‹ã®ã«ã€Œæ”¹å–„ãŒå¿…è¦ã€ã€Œãƒ€ãƒ¡ã€ãªã©ã¨è¨€ã‚ãªã„ã“ã¨ã€‚æ”¹å–„ã®ãŸã‚ã®å…·ä½“çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆæ•°å€¤ç›®æ¨™ãƒ»ç¢ºèªã™ã¹ãæ›¸é¡ãƒ»äº¤æ¸‰ã®ãƒã‚¤ãƒ³ãƒˆç­‰ï¼‰ãŒã‚ã‚Œã°è¿°ã¹ã‚‹ã“ã¨ã€‚
- éå»ã®ç›¸è«‡ãƒ¡ãƒ¢ãŒã‚ã‚‹å ´åˆã¯ã€ãã®æµã‚Œã‚’è¸ã¾ãˆã¦ã€Œç¶šãã€ã¨ã—ã¦ä¸€è²«ã—ãŸåŠ©è¨€ã‚’ã™ã‚‹ã“ã¨ã€‚
- 2ã€œ5æ–‡ã§ç°¡æ½”ã«ã€ã—ã‹ã—å…·ä½“çš„ã«ã€‚

ã€ç›¸è«‡å†…å®¹ã€‘
{q}"""
                            _engine = st.session_state.get("ai_engine", "ollama")
                            _model = get_ollama_model()
                            _api_key = (st.session_state.get("gemini_api_key") or "").strip() or GEMINI_API_KEY_ENV or _get_gemini_key_from_secrets()
                            _gemini_model = st.session_state.get("gemini_model", GEMINI_MODEL_DEFAULT)
                            # ã‚¹ãƒ¬ãƒƒãƒ‰ã§ã¯ãªããƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã§åŒæœŸçš„ã«å‘¼ã¶ï¼ˆrerunã§ã‚¹ãƒ¬ãƒƒãƒ‰ãŒæ¶ˆãˆã‚‹ãŸã‚å¿œç­”ãŒè¿”ã‚‰ãªããªã‚‹å•é¡Œã‚’å›é¿ï¼‰
                            with st.spinner("æ€è€ƒä¸­..."):
                                ans = _chat_for_thread(_engine, _model, [{"role": "user", "content": context_prompt}], timeout_seconds=120, api_key=_api_key, gemini_model=_gemini_model)
                            content = (ans.get("message") or {}).get("content", "") or "ï¼ˆå¿œç­”ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼‰"
                            if content and (
                                "APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“" in content
                                or "Gemini API ã‚¨ãƒ©ãƒ¼:" in content
                                or "pip install" in content
                                or "å¿œç­”ãŒè¿”ã‚Šã¾ã›ã‚“ã§ã—ãŸ" in content
                                or "å®‰å…¨ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã§ãƒ–ãƒ­ãƒƒã‚¯" in content
                            ):
                                st.error(content)
                            else:
                                st.markdown(content)
                            st.session_state.messages.append({"role": "assistant", "content": content})
                            # ç›¸è«‡1å¾€å¾©ã‚’ãƒ¡ãƒ¢ã«ä¿å­˜ï¼ˆè©±ã›ã°è©±ã™ã»ã©ä»¥å¾Œã®ç›¸è«‡ã§æ´»ç”¨ï¼‰
                            append_consultation_memory(q, content)
                            if st.session_state.get("ai_engine") == "gemini" and content and "APIã‚­ãƒ¼ãŒ" not in content and "Gemini API ã‚¨ãƒ©ãƒ¼:" not in content:
                                st.session_state["last_gemini_debug"] = "OK"
                            elif st.session_state.get("ai_engine") == "gemini":
                                st.session_state["last_gemini_debug"] = (content[:200] + "...") if len(content or "") > 200 else (content or "ï¼ˆç©ºï¼‰")

        with tab_debate:
            # å¯©æŸ»å§”å“¡ä¼šãƒ¢ãƒ¼ãƒ‰ï¼š3ãƒšãƒ«ã‚½ãƒŠï¼ˆæ…é‡æ´¾ãƒ»æ¨é€²æ´¾ãƒ»å¯©åˆ¤ï¼‰ã®æ€§æ ¼å®šç¾©
            PERSONA_CON = """ã‚ãªãŸã¯ã€Œæ…é‡æ´¾ï¼ˆå®ˆã‚Šï¼‰ã€ã®ãƒ™ãƒ†ãƒ©ãƒ³å¯©æŸ»éƒ¨é•·ã§ã™ã€‚
ãƒ»è²¡å‹™ã®æ¬ ç‚¹ã€æ¥­ç•Œãƒªã‚¹ã‚¯ã€å€’ç”£ç¢ºç‡ã®ä¸å®‰ã‚’å¾¹åº•çš„ã«çªãã€å³ã—ã„æ¡ä»¶ã‚’å‡ºã™ç«‹å ´ã§ã™ã€‚
ãƒ»ç™ºè¨€ã«ã¯å¿…ãšã€ãƒãƒƒãƒˆæ¤œç´¢çµæœã€‘ã¾ãŸã¯ã€è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã€‘ã®å…·ä½“çš„ãªæ•°å€¤ãƒ»äº‹å®Ÿã‚’å¼•ç”¨ã—ã€æ ¹æ‹ ã‚’ç¤ºã—ã¦ãã ã•ã„ã€‚ä¸€èˆ¬è«–ã®ã¿ã®ä¸»å¼µã¯ç¦æ­¢ã§ã™ã€‚"""
            PERSONA_PRO = """ã‚ãªãŸã¯ã€Œæ¨é€²æ´¾ï¼ˆæ”»ã‚ï¼‰ã€ã®å–¶æ¥­æ‹…å½“ã§ã™ã€‚
ãƒ»ä¼æ¥­ã®æƒ…ç†±ãƒ»å°†æ¥æ€§ãƒ»ãƒãƒƒãƒˆã§è¦‹ã¤ã‘ãŸå¥½ææ–™ã‚’å¼·èª¿ã—ã€å‰å‘ããªæ”¯æ´ã‚’ä¸»å¼µã™ã‚‹ç«‹å ´ã§ã™ã€‚
ãƒ»ç™ºè¨€ã«ã¯å¿…ãšã€ãƒãƒƒãƒˆæ¤œç´¢çµæœã€‘ã¾ãŸã¯ã€è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã€‘ã®å…·ä½“çš„ãªæ•°å€¤ãƒ»å¥½ææ–™ã‚’å¼•ç”¨ã—ã€æ ¹æ‹ ã‚’ç¤ºã—ã¦ãã ã•ã„ã€‚ä¸€èˆ¬è«–ã®ã¿ã®ä¸»å¼µã¯ç¦æ­¢ã§ã™ã€‚"""
            PERSONA_JUDGE = """ã‚ãªãŸã¯ã€Œå¯©åˆ¤ï¼ˆæ±ºè£è€…ï¼‰ã€ã§ã™ã€‚
ãƒ»æ¨é€²æ´¾ã¨æ…é‡æ´¾ã®è­°è«–ã‚’å†·é™ã«ç·æ‹¬ã—ã€æœ€çµ‚çš„ãªã€Œæ‰¿èªç¢ºç‡(%)ã€ã¨ã€Œå…·ä½“çš„ãªèè³‡æ¡ä»¶ã€ã‚’ç®—å‡ºã™ã‚‹ç«‹å ´ã§ã™ã€‚
ãƒ»ãƒãƒƒãƒˆæ¤œç´¢çµæœã‚„è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãæ ¹æ‹ ã‚’è¸ã¾ãˆã€ä¸¡è«–ã‚’å¼•ç”¨ã—ã¤ã¤çµè«–ã‚’å‡ºã—ã¦ãã ã•ã„ã€‚"""

            st.info("å¯©æŸ»å§”å“¡ä¼šãƒ¢ãƒ¼ãƒ‰ï¼šæ…é‡æ´¾ãƒ»æ¨é€²æ´¾ãƒ»å¯©åˆ¤ã®3ãƒšãƒ«ã‚½ãƒŠã§ãƒ‡ã‚£ãƒ™ãƒ¼ãƒˆã—ã€æœ€çµ‚æ±ºè£ã‚’å‡ºã—ã¾ã™ã€‚")
            if 'debate_history' not in st.session_state: st.session_state.debate_history = []
            
            # è­°è«–ãƒ­ã‚°ã®è¡¨ç¤º
            for m in st.session_state.debate_history:
                avatar = "ğŸ™†â€â™‚ï¸" if m["role"] == "Pro" else "ğŸ™…â€â™‚ï¸"
                if m["role"] == "User": avatar = "ğŸ‘¤"
                role_name = "æ¨é€²æ´¾" if m["role"] == "Pro" else ("æ…é‡æ´¾" if m["role"] == "Con" else "ã‚ãªãŸ")
                
                with st.chat_message(m["role"], avatar=avatar):
                    st.markdown(f"**{role_name}**: {m['content']}")
            
            # è­°è«–é€²è¡Œãƒœã‚¿ãƒ³
            col_btn1, col_btn2 = st.columns([1, 1])
            with col_btn1:
                if st.button("âš”ï¸ è­°è«–ã‚’é–‹å§‹ / é€²è¡Œ (1ã‚¿ãƒ¼ãƒ³é€²ã‚ã‚‹)", use_container_width=True):
                    if 'last_result' not in st.session_state:
                        st.error("å…ˆã«å¯©æŸ»ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
                    else:
                        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæº–å‚™
                        res = st.session_state['last_result']
                        selected_major = res.get("industry_major", "D å»ºè¨­æ¥­")
                        selected_sub = res.get("industry_sub", "06 ç·åˆå·¥äº‹æ¥­")
                        comparison_text = res.get("comparison", "")
                        if jsic_data and selected_major in jsic_data:
                            trend_info = jsic_data[selected_major]["sub"].get(selected_sub, "")
                        trend_extended_d = get_trend_extended(selected_sub)
                        if trend_extended_d:
                            trend_info = (trend_info or "") + "\n\nã€æ‹¡å……ã€‘\n" + trend_extended_d[:1500]
                        # --------------------------------------
                        score = res['score']
                        risk_context = ""
                        for b in bankruptcy_data:
                            risk_context += f"- {b['type']}: {b['signal']} ({b['check_point']})\n"
                        history_text = "\n".join([f"{m['role']}: {m['content']}" for m in st.session_state.debate_history])

                        # ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®åæ˜ 
                        news_context = ""
                        if 'selected_news_content' in st.session_state:
                            news = st.session_state.selected_news_content
                            news_context = f"\n\nã€å‚è€ƒãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹: {news['title']}ã€‘\n{news['content']}"
                        advice_extras_debate = get_advice_context_extras(selected_sub, selected_major)
                        advice_debate_block = ("è£œåŠ©é‡‘ãƒ»ãƒªãƒ¼ã‚¹ãƒ»æ¥­ç•Œæ‹¡å……: " + advice_extras_debate[:800]) if advice_extras_debate else ""
                        
                        # ãƒ­ãƒ¼ãƒ«æ±ºå®š & ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆï¼ˆåŒä¸€ãƒ¢ãƒ‡ãƒ«ã§ãƒšãƒ«ã‚½ãƒŠåˆ‡ã‚Šæ›¿ãˆï¼‰
                        if not st.session_state.debate_history:
                            next_role = "Pro"
                            prompt = f"""{PERSONA_PRO}

ã€è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã€‘ï¼ˆå¿…ãšå¼•ç”¨ã™ã‚‹ã“ã¨ï¼‰
æ¥­ç¨®: {selected_sub}
ã‚¹ã‚³ã‚¢: {score:.1f}ç‚¹ (æ‰¿èªãƒ©ã‚¤ãƒ³70ç‚¹)
è²¡å‹™è©•ä¾¡: {comparison_text}

ã€ãƒãƒƒãƒˆæ¤œç´¢çµæœãƒ»æ¥­ç•Œææ–™ã€‘
{advice_debate_block}
{news_context if news_context else "ï¼ˆãƒ‹ãƒ¥ãƒ¼ã‚¹æœªèª­ã¿è¾¼ã¿ï¼‰"}

ã€æŒ‡ç¤ºã€‘
- ä¸Šè¨˜ã®ã€Œè²¡å‹™ãƒ‡ãƒ¼ã‚¿ã€ã¨ã€Œãƒãƒƒãƒˆæ¤œç´¢çµæœã€ã®ã„ãšã‚Œã‹ã‹ã‚‰å¿…ãš1ã¤ä»¥ä¸Šå…·ä½“çš„ã«å¼•ç”¨ã—ã€æ ¹æ‹ ã‚’ç¤ºã—ãŸã†ãˆã§ä¸»å¼µã™ã‚‹ã“ã¨ã€‚
- ä¼æ¥­ã®æƒ…ç†±ãƒ»å°†æ¥æ€§ãƒ»å¥½ææ–™ã‚’å¼·èª¿ã—ã€å‰å‘ããªæ”¯æ´ã‚’ä¸»å¼µã›ã‚ˆã€‚
- 140æ–‡å­—ä»¥å†…ã€‚
"""
                        else:
                            last_role = st.session_state.debate_history[-1]["role"]
                            if last_role == "User":
                                prev_ai = "Con" 
                                for m in reversed(st.session_state.debate_history[:-1]):
                                    if m["role"] in ["Pro", "Con"]:
                                        prev_ai = m["role"]
                                        break
                                next_role = "Con" if prev_ai == "Pro" else "Pro"
                            else:
                                next_role = "Con" if last_role == "Pro" else "Pro"
                            
                            if next_role == "Con":
                                advice_con_block = ("ã€è£œåŠ©é‡‘ãƒ»ãƒªãƒ¼ã‚¹åˆ¤å®šç­‰ã€‘" + advice_extras_debate[:500]) if advice_extras_debate else ""
                                prompt = f"""{PERSONA_CON}

ã€è²¡å‹™ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒªã‚¹ã‚¯æŒ‡æ¨™ã€‘ï¼ˆå¿…ãšå¼•ç”¨ã™ã‚‹ã“ã¨ï¼‰
ã‚¹ã‚³ã‚¢: {score:.1f}ç‚¹ã€è²¡å‹™è©•ä¾¡: {comparison_text}
ã€å€’ç”£ãƒªã‚¹ã‚¯DBã€‘
{risk_context}

ã€ãƒãƒƒãƒˆæ¤œç´¢çµæœãƒ»æ¥­ç•Œãƒªã‚¹ã‚¯ã€‘
{news_context if news_context else "ï¼ˆãªã—ï¼‰"}
{advice_con_block}

ã€ã“ã‚Œã¾ã§ã®è­°è«–ã€‘
{history_text}

ã€æŒ‡ç¤ºã€‘
- ä¸Šè¨˜ã®ã€Œè²¡å‹™ãƒ‡ãƒ¼ã‚¿ã€ã¾ãŸã¯ã€Œãƒãƒƒãƒˆæ¤œç´¢çµæœã€ã‹ã‚‰å¿…ãš1ã¤ä»¥ä¸Šå…·ä½“çš„ã«å¼•ç”¨ã—ã€æ ¹æ‹ ã‚’ç¤ºã—ãŸã†ãˆã§åè«–ã™ã‚‹ã“ã¨ã€‚
- è²¡å‹™ã®æ¬ ç‚¹ãƒ»æ¥­ç•Œãƒªã‚¹ã‚¯ãƒ»å€’ç”£ç¢ºç‡ã®ä¸å®‰ã‚’çªãã€å³ã—ã„æ¡ä»¶ã‚’å‡ºã›ã€‚
- 140æ–‡å­—ä»¥å†…ã€‚
"""
                            else:  # Pro
                                advice_pro_block = ("ã€è£œåŠ©é‡‘ãƒ»ãƒªãƒ¼ã‚¹ç­‰ã€‘" + advice_extras_debate[:500]) if advice_extras_debate else ""
                                prompt = f"""{PERSONA_PRO}

ã€è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã€‘ï¼ˆå¿…ãšå¼•ç”¨ã™ã‚‹ã“ã¨ï¼‰
è²¡å‹™è©•ä¾¡: {comparison_text}
ã‚¹ã‚³ã‚¢: {score:.1f}ç‚¹

ã€ãƒãƒƒãƒˆæ¤œç´¢çµæœãƒ»å¥½ææ–™ã€‘
{news_context if news_context else "æ¥­ç•Œã®æˆé•·æ€§ã€ç¤¾é•·ã®è¦šæ‚Ÿ"}
{advice_pro_block}

ã€ã“ã‚Œã¾ã§ã®è­°è«–ã€‘
{history_text}

ã€æŒ‡ç¤ºã€‘
- ä¸Šè¨˜ã®ã€Œè²¡å‹™ãƒ‡ãƒ¼ã‚¿ã€ã¾ãŸã¯ã€Œãƒãƒƒãƒˆæ¤œç´¢çµæœã€ã‹ã‚‰å¿…ãš1ã¤ä»¥ä¸Šå…·ä½“çš„ã«å¼•ç”¨ã—ã€æ ¹æ‹ ã‚’ç¤ºã—ãŸã†ãˆã§æ…é‡æ´¾ã«åè«–ã›ã‚ˆã€‚
- ä¼æ¥­ã®æƒ…ç†±ãƒ»å°†æ¥æ€§ãƒ»å¥½ææ–™ã‚’å¼·èª¿ã—ã€å‰å‘ããªæ”¯æ´ã‚’ä¸»å¼µã›ã‚ˆã€‚
- 140æ–‡å­—ä»¥å†…ã€‚
"""
        
                        # AIæ€è€ƒä¸­...
                        if not is_ai_available():
                            if st.session_state.get("ai_engine") == "gemini":
                                st.error("Gemini APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã€ŒAIãƒ¢ãƒ‡ãƒ«è¨­å®šã€ã§å…¥åŠ›ã™ã‚‹ã‹ã€ç’°å¢ƒå¤‰æ•° GEMINI_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
                            else:
                                st.error(f"AIã‚µãƒ¼ãƒãƒ¼ï¼ˆOllamaï¼‰ãŒèµ·å‹•ã—ã¦ã„ã¾ã›ã‚“ã€‚\nã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ `ollama serve` ã‚’å®Ÿè¡Œã™ã‚‹ã‹ã€ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã€ŒGemini APIã€ã«åˆ‡ã‚Šæ›¿ãˆã¦ãã ã•ã„ã€‚")
                        else:
                            with st.spinner(f"{next_role}ãŒæ€è€ƒä¸­..."): 
                                try:
                                    # è¨è«–ãƒ¢ãƒ¼ãƒ‰ã§ã¯ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã¨ãƒªãƒˆãƒ©ã‚¤ã‚’ã‚„ã‚„å³ã—ã‚ã«è¨­å®š
                                    ans = chat_with_retry(
                                        model=get_ollama_model(),
                                        messages=[{"role": "user", "content": prompt}],
                                        retries=1,
                                        timeout_seconds=120,
                                    )
                            
                                    if not ans or 'message' not in ans:
                                        st.error("AIã‹ã‚‰ã®å¿œç­”ãŒä¸æ­£ã§ã™ã€‚")
                                    else:
                                        msg_content = ans['message']['content']
                                        if msg_content and (
                                            "APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“" in msg_content
                                            or "Gemini API ã‚¨ãƒ©ãƒ¼:" in msg_content
                                            or "pip install" in msg_content
                                            or "å¿œç­”ãŒè¿”ã‚Šã¾ã›ã‚“ã§ã—ãŸ" in msg_content
                                            or "å®‰å…¨ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã§ãƒ–ãƒ­ãƒƒã‚¯" in msg_content
                                        ):
                                            st.error(msg_content)
                                        st.session_state.debate_history.append({"role": next_role, "content": msg_content})
                                except Exception as e:
                                    st.error(f"AIã‚¨ãƒ©ãƒ¼è©³ç´°: {e}")
                            
                            # å³åº§ã«å†æç”»
                            st.rerun()
            
            # çµ‚äº†åˆ¤å®šãƒœã‚¿ãƒ³ï¼ˆå¯©åˆ¤ãƒšãƒ«ã‚½ãƒŠã§æ±ºè£ï¼‰
            with col_btn2:
                if len(st.session_state.debate_history) >= 4:
                    res_judge = st.session_state.get("last_result") or {}
                    selected_sub_judge = res_judge.get("industry_sub", "")
                    if st.button("ğŸ è­°è«–çµ‚äº†ãƒ»åˆ¤å®š", type="primary", use_container_width=True):
                        with st.spinner("å¯©åˆ¤ãŒæ±ºè£ä¸­..."):
                            history_text = "\n".join([f"{m['role']}: {m['content']}" for m in st.session_state.debate_history])
                            pd_val = res_judge.get("pd_percent")
                            net_risk = res_judge.get("network_risk_summary", "")
                            pd_str = f"{pd_val:.1f}%" if pd_val is not None else "ï¼ˆæœªç®—å‡ºï¼‰"
                            comparison_judge = res_judge.get("comparison", "")
                            similar_block = res_judge.get("similar_past_cases_prompt", "") or ""
                            judge_prompt = ""
                            if similar_block:
                                judge_prompt += similar_block
                            past_stats_judge = get_stats(selected_sub_judge)
                            if past_stats_judge.get("top_competitors_lost") or (past_stats_judge.get("avg_winning_rate") is not None and past_stats_judge.get("avg_winning_rate", 0) > 0):
                                judge_prompt += "\nã€éå»ã®ç«¶åˆãƒ»æˆç´„é‡‘åˆ©ã€‘\n"
                                if past_stats_judge.get("top_competitors_lost"):
                                    judge_prompt += "ã‚ˆãè² ã‘ã‚‹ç«¶åˆ: " + "ã€".join(past_stats_judge["top_competitors_lost"][:5]) + "\n"
                                if past_stats_judge.get("avg_winning_rate") and past_stats_judge["avg_winning_rate"] > 0:
                                    judge_prompt += f"åŒæ¥­ç¨®ã®å¹³å‡æˆç´„é‡‘åˆ©: {past_stats_judge['avg_winning_rate']:.2f}%\n"
                                judge_prompt += "ä¸Šè¨˜ã‚’è¸ã¾ãˆã€èè³‡æ¡ä»¶ã«ã¯ç«¶åˆã«å‹ã¤ãŸã‚ã®å¯¾ç­–ã‚‚åæ˜ ã—ã¦ãã ã•ã„ã€‚\n\n"
                            judge_prompt += f"""{PERSONA_JUDGE}

ã€è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã€‘ï¼ˆæ ¹æ‹ ã¨ã—ã¦å¼•ç”¨ã™ã‚‹ã“ã¨ï¼‰
è²¡å‹™è©•ä¾¡: {comparison_judge}

ã€ãƒãƒƒãƒˆæ¤œç´¢çµæœã€‘
ã€æ¥­ç•Œã®æœ€æ–°ãƒªã‚¹ã‚¯æƒ…å ±ã€‘
{net_risk if net_risk else "ï¼ˆæœªå–å¾—ï¼‰"}

ã€è­°è«–ãƒ­ã‚°ï¼ˆæ¨é€²æ´¾ãƒ»æ…é‡æ´¾ã®ç™ºè¨€ï¼‰ã€‘
{history_text}

ã€æŒ‡ç¤ºã€‘
- ä¸Šè¨˜ã®è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã¨ãƒãƒƒãƒˆæ¤œç´¢çµæœã‚’æ ¹æ‹ ã«ã€æ¨é€²æ´¾ã¨æ…é‡æ´¾ã®è­°è«–ã‚’å†·é™ã«ç·æ‹¬ã—ã¦ãã ã•ã„ã€‚
- æœ€çµ‚çš„ãªã€Œæ‰¿èªç¢ºç‡(%)ã€ã¨ã€Œå…·ä½“çš„ãªèè³‡æ¡ä»¶ã€ã‚’ç®—å‡ºã—ã€ç†ç”±ã‚’ç°¡æ½”ã«è¿°ã¹ã¦ãã ã•ã„ã€‚

å‡ºåŠ›å½¢å¼ï¼ˆå¿…ãšå®ˆã‚‹ã“ã¨ï¼‰:
æ‰¿èªç¢ºç‡: XX%
èè³‡æ¡ä»¶: ï¼ˆé‡‘åˆ©ãƒ»æ‹…ä¿ãƒ»æœŸé–“ãªã©å…·ä½“çš„ã«ï¼‰
ç†ç”±: (80æ–‡å­—ä»¥å†…)
"""
                            if not is_ai_available():
                                if st.session_state.get("ai_engine") == "gemini":
                                    st.error("Gemini APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã€ŒAIãƒ¢ãƒ‡ãƒ«è¨­å®šã€ã§å…¥åŠ›ã™ã‚‹ã‹ã€ç’°å¢ƒå¤‰æ•° GEMINI_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
                                else:
                                    st.error("Ollama ãŒèµ·å‹•ã—ã¦ã„ã¾ã›ã‚“ã€‚`ollama serve` ã‚’å®Ÿè¡Œã™ã‚‹ã‹ã€ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã€ŒGemini APIã€ã«åˆ‡ã‚Šæ›¿ãˆã¦ãã ã•ã„ã€‚")
                            else:
                                ans = chat_with_retry(
                                    model=get_ollama_model(),
                                    messages=[{"role": "user", "content": judge_prompt}],
                                    retries=1,
                                    timeout_seconds=120,
                                )
                                result_text = ans['message']['content']
                                
                                st.success("âœ… **ãƒ‡ã‚£ãƒ™ãƒ¼ãƒˆçµæœ**")
                                st.write(result_text)
                                
                                save_debate_log({
                                    "industry": selected_sub_judge,
                                    "history": st.session_state.debate_history,
                                    "result": result_text
                                })
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ä»‹å…¥ï¼ˆãƒãƒ£ãƒƒãƒˆå…¥åŠ›ï¼‰
            if user_input := st.chat_input("è­°è«–ã«ä»‹å…¥ã™ã‚‹ï¼ˆå›ç­”ãƒ»æŒ‡ç¤ºï¼‰", key="debate_input"):
                st.session_state.debate_history.append({"role": "User", "content": user_input})
                st.rerun()

        st.divider()

    with menu_tabs[1]:  # æƒ…å ±æ¤œç´¢
        st.subheader("ğŸ” æƒ…å ±æ¤œç´¢")
        info_cat = st.radio("ã‚«ãƒ†ã‚´ãƒª", ["æ¥­ç¨®æƒ…å ±", "è£œåŠ©é‡‘", "ãƒªãƒ¼ã‚¹æƒ…å ±"], horizontal=True, key="info_search_cat", label_visibility="collapsed")
        if info_cat == "æ¥­ç¨®æƒ…å ±":
            st.markdown("**æ¥­ç¨®åˆ¥ã®æ¥­ç•Œç›®å®‰ãƒ»ãƒˆãƒ¬ãƒ³ãƒ‰**")
            sub_keys = sorted(benchmarks_data.keys()) if benchmarks_data else []
            if sub_keys:
                search_sub = st.selectbox("æ¥­ç¨®ã‚’é¸æŠ", sub_keys, key="info_industry_sub")
                bench = benchmarks_data.get(search_sub, {})
                if bench:
                    st.caption("å–¶æ¥­åˆ©ç›Šç‡ãƒ»è‡ªå·±è³‡æœ¬æ¯”ç‡ãƒ»å£²ä¸Šé«˜ç·åˆ©ç›Šç‡ãƒ»ROAãƒ»æµå‹•æ¯”ç‡ãªã©ã®ç›®å®‰ï¼ˆæ¥­ç•Œå¹³å‡ï¼‰")
                    for k, v in list(bench.items())[:10]:
                        if v is not None and isinstance(v, (int, float)): st.write(f"- {k}: {v}")
                trend_ext = get_trend_extended(search_sub)
                if trend_ext:
                    with st.expander("ãƒãƒƒãƒˆã§å–å¾—ã—ãŸãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»æ‹¡å……æƒ…å ±", expanded=False):
                        st.text(trend_ext[:2000])
            else:
                st.caption("æ¥­ç¨®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        elif info_cat == "è£œåŠ©é‡‘":
            st.markdown("**æ¥­ç¨®åˆ¥ è£œåŠ©é‡‘**")
            sub_keys = sorted(benchmarks_data.keys()) if benchmarks_data else []
            if sub_keys:
                search_sub = st.selectbox("æ¥­ç¨®ã‚’é¸æŠ", sub_keys, key="info_subsidy_sub")
                subs_list = search_subsidies_by_industry(search_sub)
                if subs_list:
                    for s in subs_list:
                        name, url = s.get("name", ""), (s.get("url") or "").strip()
                        st.markdown(f"**{name}**")
                        if url:
                            try: st.link_button("ğŸ”— å…¬å¼ã‚µã‚¤ãƒˆ", url, type="secondary")
                            except Exception: st.markdown(f'<a href="{url}" target="_blank">ğŸ”— å…¬å¼ã‚µã‚¤ãƒˆ</a>', unsafe_allow_html=True)
                        st.caption((s.get("summary") or "")[:120] + "â€¦")
                else:
                    st.caption("è©²å½“ã™ã‚‹è£œåŠ©é‡‘ã®ç™»éŒ²ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            else:
                st.caption("æ¥­ç¨®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            st.markdown("**ãƒªãƒ¼ã‚¹æƒ…å ±**")
            with st.expander("è€ç”¨å¹´æ•°ã‚’è¨­å‚™ã§èª¿ã¹ã‚‹", expanded=False):
                nta_url = (useful_life_data or {}).get("nta_useful_life_url") or "https://www.keisan.nta.go.jp/r5yokuaru/aoiroshinkoku/hitsuyokeihi/genkashokyakuhi/taiyonensuhyo.html"
                st.link_button("ğŸ“‹ å›½ç¨åºã®è€ç”¨å¹´æ•°è¡¨", nta_url, type="secondary")
                eq_key = st.text_input("è¨­å‚™åã§æ¤œç´¢", placeholder="ä¾‹: å·¥ä½œæ©Ÿæ¢°", key="info_equip")
                if eq_key:
                    for e in (search_equipment_by_keyword(eq_key) or []):
                        st.write(f"**{e.get('name')}** â€¦ {e.get('years')}å¹´")
            with st.expander("ãƒªãƒ¼ã‚¹åˆ¤å®šãƒ•ãƒ­ãƒ¼ãƒ»å¥‘ç´„å½¢æ…‹", expanded=False):
                st.markdown(get_lease_classification_text() or "lease_classification.json ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")
            with st.expander("ãƒªãƒ¼ã‚¹ç‰©ä»¶ãƒªã‚¹ãƒˆ", expanded=False):
                if LEASE_ASSETS_LIST:
                    for it in LEASE_ASSETS_LIST:
                        st.caption(f"**{it.get('name','')}** {it.get('score',0)}ç‚¹ â€” {it.get('note','')}")
                else:
                    st.caption("lease_assets.json ã‚’é…ç½®ã—ã¦ãã ã•ã„ã€‚")

    with menu_tabs[2]:  # ã‚°ãƒ©ãƒ•
        st.subheader("ğŸ“ˆ ã‚°ãƒ©ãƒ•")
        if "last_result" in st.session_state:
            res = st.session_state["last_result"]
            current_case_data = {"sales": res["financials"]["nenshu"], "op_margin": res["user_op"], "equity_ratio": res["user_eq"]}
            fig_3d = plot_3d_analysis(current_case_data, load_all_cases())
            if fig_3d:
                st.plotly_chart(fig_3d, use_container_width=True, key="plotly_3d_graph_tab")
                st.caption("æŒ‡ã§ãªãã‚‹ã¨å›è»¢ãƒ»ãƒ”ãƒ³ãƒã§æ‹¡å¤§ã§ãã¾ã™ã€‚")
            st.divider()
            fin = res.get("financials", {})
            if fin.get("nenshu", 0) > 0:
                col_wf2, _ = st.columns([0.65, 0.35])
                with col_wf2:
                    st.plotly_chart(plot_waterfall_plotly(fin.get("nenshu", 0), fin.get("gross_profit", 0), fin.get("op_profit", 0), fin.get("ord_profit", 0), fin.get("net_income", 0)), use_container_width=True, key="waterfall_tab")
        else:
            st.info("ğŸ‘ˆ ã€Œæ–°è¦å¯©æŸ»ã€ã§ãƒ‡ãƒ¼ã‚¿ã‚’å…¥åŠ›ã—ã€åˆ¤å®šé–‹å§‹ã™ã‚‹ã¨ã‚°ãƒ©ãƒ•ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")

    with menu_tabs[3]:  # å±¥æ­´åˆ†æ
        st.subheader("ğŸ“‹ å±¥æ­´åˆ†æ")
        all_cases = load_all_cases()
        if not all_cases:
            st.warning("ç™»éŒ²ã•ã‚ŒãŸæ¡ˆä»¶ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            pending = [c for c in all_cases if c.get("final_status") == "æœªç™»éŒ²"]
            if not pending:
                st.success("å…¨ã¦ã®æ¡ˆä»¶ãŒç™»éŒ²æ¸ˆã¿ã§ã™ã€‚")
            for i, case in enumerate(reversed(pending[-5:])):
                hist_case_id = case.get("id", "")
                with st.expander(f"{case.get('timestamp', '')[:16]} - {case.get('industry_sub')} (ã‚¹ã‚³ã‚¢: {case.get('result', {}).get('score', 0):.0f})"):
                    c1, c2 = st.columns(2)
                    with c1:
                        st.write("**åˆ¤å®š**:", case.get("result", {}).get("hantei", ""))
                        st.caption((case.get("chat_summary", "")[:100] + "...") if case.get("chat_summary") else "ã‚µãƒãƒªãªã—")
                    with c2:
                        if st.button("ğŸ—‘ï¸ å‰Šé™¤", key=f"del_hist_{hist_case_id}", type="secondary", help="ã“ã®æœªç™»éŒ²æ¡ˆä»¶ã‚’å‰Šé™¤"):
                            all_cases = [c for c in load_all_cases() if c.get("id") != hist_case_id]
                            save_all_cases(all_cases)
                            st.success("å‰Šé™¤ã—ã¾ã—ãŸ")
                            time.sleep(0.5)
                            st.rerun()
                        with st.form(f"hist_status_{i}"):
                            res_status = st.radio("çµæœ", ["æˆç´„", "å¤±æ³¨"], horizontal=True)
                            final_rate = st.number_input("ç²å¾—ãƒ¬ãƒ¼ãƒˆ (%)", value=0.0, step=0.01, format="%.2f")
                            lost_reason = st.text_input("å¤±æ³¨ç†ç”±", placeholder="ä¾‹: é‡‘åˆ©ã§ä»–ç¤¾ã«")
                            loan_condition_options = ["é‡‘èæ©Ÿé–¢ã¨å”èª¿", "æœ¬ä»¶é™åº¦", "æ¬¡å›æ ¼ä»˜ã¾ã§æœ¬ä»¶é™åº¦", "ãã®ä»–"]
                            loan_conditions_hist = st.multiselect("èè³‡æ¡ä»¶", loan_condition_options, key=f"hist_loan_{i}")
                            competitor_name_hist = st.text_input("ç«¶åˆä»–ç¤¾æƒ…å ±", placeholder="ä¾‹: ã€‡ã€‡éŠ€è¡Œã€ã€‡ã€‡ãƒªãƒ¼ã‚¹", key=f"hist_comp_{i}")
                            competitor_rate_hist = st.number_input("ä»–ç¤¾æç¤ºé‡‘åˆ© (%)", value=0.0, step=0.01, format="%.2f", key=f"hist_rate_{i}")
                            if st.form_submit_button("ç™»éŒ²"):
                                for c in all_cases:
                                    if c.get("id") == case.get("id"):
                                        c["final_status"] = res_status
                                        c["final_rate"] = final_rate
                                        if res_status == "å¤±æ³¨":
                                            c["lost_reason"] = lost_reason
                                        c["loan_conditions"] = loan_conditions_hist
                                        c["competitor_name"] = competitor_name_hist.strip() if competitor_name_hist else ""
                                        c["competitor_rate"] = competitor_rate_hist if competitor_rate_hist else None
                                        break
                                if save_all_cases(all_cases):
                                    st.success("ç™»éŒ²ã—ã¾ã—ãŸ")
                                    st.rerun()
                                else:
                                    st.error("ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        with st.expander("ğŸ”§ ä¿‚æ•°åˆ†æãƒ»æ›´æ–° (Î²)", expanded=False):
            st.caption("è“„ç©ãƒ‡ãƒ¼ã‚¿ã§æ–°ã—ã„å¯©æŸ»ãƒ¢ãƒ‡ãƒ«ï¼ˆä¿‚æ•°ï¼‰ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¾ã™ã€‚")
            all_logs = load_all_cases()
            if not all_logs or len([x for x in all_logs if x.get("final_status") in ["æˆç´„", "å¤±æ³¨"]]) < 5:
                st.warning("æˆç´„/å¤±æ³¨ãŒ5ä»¶ä»¥ä¸Šç™»éŒ²ã•ã‚Œã‚‹ã¨åˆ†æã§ãã¾ã™ã€‚")
            else:
                st.info("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã€Œä¿‚æ•°åˆ†æãƒ»æ›´æ–° (Î²)ã€ãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆã‚‹ã¨å›å¸°åˆ†æã‚’å®Ÿè¡Œã§ãã¾ã™ã€‚")

    with menu_tabs[4]:  # è¨­å®š
        st.subheader("âš™ï¸ è¨­å®š")
        st.radio("AIã‚¨ãƒ³ã‚¸ãƒ³", ["Ollamaï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ï¼‰", "Gemini APIï¼ˆGoogleï¼‰"], key="settings_engine_display", index=0 if st.session_state.get("ai_engine") == "ollama" else 1, disabled=True)
        st.caption("AIãƒ¢ãƒ‡ãƒ«è¨­å®šã¯å·¦ã‚µã‚¤ãƒ‰ãƒãƒ¼ã€ŒğŸ¤– AIãƒ¢ãƒ‡ãƒ«è¨­å®šã€ã§å¤‰æ›´ã§ãã¾ã™ã€‚")
        st.divider()
        st.markdown("**ã‚­ãƒ£ãƒƒã‚·ãƒ¥**")
        if st.button("ğŸ—‘ï¸ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢", key="settings_clear_cache"):
            st.cache_data.clear()
            st.success("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")
            st.rerun()
        st.divider()
        st.markdown("**ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªã‚¢**")
        st.caption("éå»å¯©æŸ»æ¡ˆä»¶ãƒ‡ãƒ¼ã‚¿ï¼ˆpast_cases.jsonlï¼‰ã‚’ã™ã¹ã¦å‰Šé™¤ã—ã¾ã™ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ç¢ºèªå¾Œã«å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚")
        if st.button("ğŸ—‘ï¸ å…¨æ¡ˆä»¶ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢", key="settings_clear_data", type="secondary"):
            st.session_state.confirm_delete = True
            st.rerun()
